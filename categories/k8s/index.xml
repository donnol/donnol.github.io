<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>K8s on 我的简单博客</title><link>https://donnol.github.io/categories/k8s/</link><description>Recent content in K8s on 我的简单博客</description><generator>Hugo -- gohugo.io</generator><language>en</language><lastBuildDate>Fri, 13 May 2022 00:00:00 +0000</lastBuildDate><atom:link href="https://donnol.github.io/categories/k8s/index.xml" rel="self" type="application/rss+xml"/><item><title>k8s是怎么维持pod的运行的呢？</title><link>https://donnol.github.io/posts/2022/05/k8s_how_to_keep_pods/</link><pubDate>Fri, 13 May 2022 00:00:00 +0000</pubDate><guid>https://donnol.github.io/posts/2022/05/k8s_how_to_keep_pods/</guid><description>k8s是怎么维持pod的运行的呢？ # 当接收了yaml配置的信息后，是怎么维持pod根据声明一直运行的呢？
让我们沿着命令执行的过程来一睹为快：kubectl apply -f pod.yaml.
源码位置：cmd/kubectl/kubectl.go -&amp;gt; staging/src/k8s.io/kubectl/pkg/cmd/cmd.go -&amp;gt; staging/src/k8s.io/kubectl/pkg/cmd/apply/apply.go
最终的执行方法：
func (o *ApplyOptions) Run() error { // 预处理 if o.PreProcessorFn != nil { klog.V(4).Infof(&amp;#34;Running apply pre-processor function&amp;#34;) if err := o.PreProcessorFn(); err != nil { return err } } // Enforce CLI specified namespace on server request. if o.EnforceNamespace { o.VisitedNamespaces.Insert(o.Namespace) } // Generates the objects using the resource builder if they have not // already been stored by calling &amp;#34;SetObjects()&amp;#34; in the pre-processor.</description></item><item><title>k8s</title><link>https://donnol.github.io/posts/2021/12/k8s/</link><pubDate>Fri, 10 Dec 2021 00:00:00 +0000</pubDate><guid>https://donnol.github.io/posts/2021/12/k8s/</guid><description>What # docker 带来容器之风，以致容器多不胜数。如何编排和管理众多容器，使得它们同心协力办好事情，即成为了当下最大的课题。
为此，k8s 应运而生。
容器，通讯，存储，配置。
Why # 为编排和管理数量众多的容器。
How # Install # k8s: 集群搭建所需资源 # One or more machines running one of:
Ubuntu 16.04+
Debian 9+
CentOS 7+
Red Hat Enterprise Linux (RHEL) 7+
Fedora 25+
HypriotOS v1.0.1+
Flatcar Container Linux (tested with 2512.3.0)
2 GB or more of RAM per machine (any less will leave little room for your apps).
2 CPUs or more.
Full network connectivity between all machines in the cluster (public or private network is fine).</description></item></channel></rss>