[{"id":0,"href":"/posts/2023/12/dbeaver%E6%89%8B%E5%8A%A8%E5%AF%BC%E5%85%A5%E9%A9%B1%E5%8A%A8/","title":"dbeaver手动导入驱动","section":"12","content":"因为直接下载dbeaver的时候，是没有带上驱动文件的，所以需要在使用时下载。\n但是，如果刚好安装的环境是无法通网的，那么就需要手动传入驱动并安装。\n做法如下：\n现在本地有网环境下载驱动文件 用dbeaver下载mysql的驱动，会存放在目录：C:\\Users\\{用户名}\\AppData\\Roaming\\DBeaverData\\drivers\\maven\\maven-central\\mysql.\nNOTE: 注意替换{用户名}为你本机实际名称。\n把下好的文件传入到无网机器上，同样放到以上目录。\n打开dbeaver，数据库-\u0026gt;驱动管理器，添加驱动\n选中MySQL，然后点击编辑；在弹出框里切到库，将已有内容全部删掉，再点击添加文件夹，然后选择上面驱动存放的目录，即可确定保存。\n如此，即可手动导入驱动文件。\n"},{"id":1,"href":"/posts/2023/10/mysql_count_distinct_with_over/","title":"Mysql 8.0.33在使用窗口函数的同时不能用count(distinct *)","section":"10","content":"Mysql 8.0.33在使用窗口函数的同时不能用count(distinct *)\n比如，我想在窗口函数里使用字段apply_unit_id分组，然后求project_id列不重复值的数量：\nselect distinct apply_unit_id, count(distinct project_id) over (partition by apply_unit_id) from weia join weiag on weiag.apply_id = weia.id ; 此时报错：SQL 错误 [1235] [42000]: This version of MySQL doesn't yet support '\u0026lt;window function\u0026gt;(DISTINCT ..)'\n怎么办呢？ # 使用 dense_rank()间接计算：\nselect distinct apply_unit_id, dense_rank() over (partition by apply_unit_id order by project_id) + dense_rank() over (partition by apply_unit_id order by project_id desc) - 1 from weia join weiag on weiag.apply_id = weia.id ; dense_rank() # Returns the rank of the current row within its partition, without gaps.\n\u0026ndash; 返回当前行在其分区内的排名，没有间隙。\n而 rank()\nReturns the rank of the current row within its partition, with gaps.\n\u0026ndash; 返回当前行在其分区内的排名，带有间隙。\n那么，这里的间隙是什么意思呢？\nmysql\u0026gt; SELECT val, ROW_NUMBER() OVER w AS \u0026#39;row_number\u0026#39;, RANK() OVER w AS \u0026#39;rank\u0026#39;, DENSE_RANK() OVER w AS \u0026#39;dense_rank\u0026#39; FROM numbers WINDOW w AS (ORDER BY val); +------+------------+------+------------+ | val | row_number | rank | dense_rank | +------+------------+------+------------+ | 1 | 1 | 1 | 1 | | 1 | 2 | 1 | 1 | | 2 | 3 | 3 | 2 | | 3 | 4 | 4 | 3 | | 3 | 5 | 4 | 3 | | 3 | 6 | 4 | 3 | | 4 | 7 | 7 | 4 | | 4 | 8 | 7 | 4 | | 5 | 9 | 9 | 5 | +------+------------+------+------------+ 上面的例子比较了row_number(), rank(), dense_rank()三种函数的效果，从中可以看出：\nrow_number(): 从1开始单调递增，不会出现重复值 rank(): 会存在相同排名，值在增大时会出现空隙，比如在1存在两个时，会从1跳到3 dense_rank(): 会存在相同排名，值在增大时不会出现空隙，即使1存在两个时，后面的排名值也不会跳跃 "},{"id":2,"href":"/posts/2023/10/wezterm/","title":"Wezterm极简配置文件","section":"10","content":"Wezterm极简配置文件\n-- Pull in the wezterm API local wezterm = require \u0026#39;wezterm\u0026#39; -- This table will hold the configuration. local config = {} -- In newer versions of wezterm, use the config_builder which will -- help provide clearer error messages if wezterm.config_builder then config = wezterm.config_builder() end -- This is where you actually apply your config choices -- For example, changing the color scheme: config.color_scheme = \u0026#39;AdventureTime\u0026#39; -- config.color_scheme = \u0026#39;Batman\u0026#39; config.enable_tab_bar = true config.hide_tab_bar_if_only_one_tab = false config.show_tab_index_in_tab_bar = false config.tab_bar_at_bottom = true config.tab_max_width = 25 -- Font -- config.font = wezterm.font_with_fallback { \u0026#39;JetBrains Mono\u0026#39; } config.font_size = 14 config.freetype_load_target = \u0026#34;Light\u0026#34; -- Possible alternatives are `HorizontalLcd`, `Light`, `Mono`, `Normal`, `VerticalLcd`. config.mouse_bindings = { -- Paste on right-click { event = { Down = { streak = 1, button = \u0026#39;Right\u0026#39; } }, mods = \u0026#39;NONE\u0026#39;, action = wezterm.action { PasteFrom = \u0026#39;Clipboard\u0026#39; } }, -- Change the default click behavior so that it only selects { event = { Up = { streak = 1, button = \u0026#39;Left\u0026#39; } }, mods = \u0026#39;NONE\u0026#39;, action = wezterm.action { CompleteSelection = \u0026#39;PrimarySelection\u0026#39; } }, -- CTRL-Click open hyperlinks { event = { Up = { streak = 1, button = \u0026#39;Left\u0026#39; } }, mods = \u0026#39;CTRL\u0026#39;, action = \u0026#39;OpenLinkAtMouseCursor\u0026#39; } } -- and finally, return the configuration to wezterm return config "},{"id":3,"href":"/posts/2023/09/%E9%9B%AA%E8%8A%B1id-%E6%97%B6%E9%92%9F%E5%9B%9E%E9%80%80%E9%97%AE%E9%A2%98/","title":"雪花id的时钟回退问题","section":"09","content":"雪花id由64位二进制组成，转成字符串则长为19. 它依赖于系统时钟，如果出现时钟回退，会导致已经在用的id再次被生成。\n怎么办呢？\n记录上次生成时间，在本次生成时比较时间，如果当前时间比上次生成时间要小，则认为时钟回拨，直接报错。也可以一直重试，直到当前时间不小于上次生成时间。\n采用历史时间则天然的不存在时间回拨问题。但是在超高并发情况下，历史的时间很快用完，时间一直保持在最新时间的话，这个时候还是会出现时间回拨。\nGo1.9开始，使用单调时钟: time.Now(), time.Since(), time.Until().\n// # Monotonic Clocks\n//\n// Operating systems provide both a “wall clock,” which is subject to\n// changes for clock synchronization, and a “monotonic clock,” which is\n// not. The general rule is that the wall clock is for telling time and\n// the monotonic clock is for measuring time. Rather than split the API,\n// in this package the Time returned by time.Now contains both a wall\n// clock reading and a monotonic clock reading; later time-telling\n// operations use the wall clock reading, but later time-measuring\n// operations, specifically comparisons and subtractions, use the\n// monotonic clock reading.\n//\n// For example, this code always computes a positive elapsed time of\n// approximately 20 milliseconds, even if the wall clock is changed during\n// the operation being timed:\n//\n//\tstart := time.Now()\n//\t\u0026hellip; operation that takes 20 milliseconds \u0026hellip;\n//\tt := time.Now()\n//\telapsed := t.Sub(start)\n//\n// Other idioms, such as time.Since(start), time.Until(deadline), and\n// time.Now().Before(deadline), are similarly robust against wall clock\n// resets.\nR1\nR2\n"},{"id":4,"href":"/posts/2023/09/go_escape_analysis/","title":"Go escape analysis","section":"09","content":" The meaning of escapes to the heap is variables needs to be shared across the function stack frames [between main() and Println()] \u0026hellip;\n\u0026hellip; So globally access variables must be moved to heap as it requires runtime. So the output line 11:2 shows the same as the data variable moved to the heap memory.\nFrom\n"},{"id":5,"href":"/posts/2023/09/do/","title":"What are you preparing to do?","section":"09","content":"他想做的事情，与你想他做的事情，与你在做的事情。\n这些事情之间是否存在交集，如果一点都没有，那不就是事与愿违了吗？\n"},{"id":6,"href":"/posts/2023/09/mysql/","title":"查找并杀掉运行中事务","section":"09","content":" 查找并杀掉运行中事务 # -- 获取线程id然后杀掉 SELECT * FROM information_schema.innodb_trx; kill 36272; kill 36275; kill 35971; kill 35972; -- 其它 select * from performance_schema.events_statements_current; show processlist; 查看锁使用情况 # SELECT object_name, index_name, lock_type, lock_mode, lock_data FROM performance_schema.data_locks; "},{"id":7,"href":"/posts/2023/09/goenv/","title":"Vscode go cannot find GOROOT directory","section":"09","content":"今天发现在windows上的vscode一直提示找不到go：go: cannot find GOROOT directory: c:\\msys64\\mingw64\\lib\\go。\n强制设置了go.goroot也不行，直到查看了GOENV文件（C:\\Users\\xxx\\AppData\\Roaming\\go\\env）之后，才发现里面有一行：GOROOT=c:\\msys64\\mingw64\\lib\\go，可能是当时在msys2安装go的时候加上的。\n去掉它就恢复正常了。\n$ go env set GOENV=C:\\Users\\xxx\\AppData\\Roaming\\go\\env set GOHOSTARCH=amd64 set GOHOSTOS=windows set GOMODCACHE=C:\\Users\\xxx\\go\\pkg\\mod set GOOS=windows set GOPATH=C:\\Users\\xxx\\go set GOPRIVATE= set GOPROXY=https://goproxy.cn,https://goproxy.io,direct set GOROOT=C:\\Program Files\\Go 应该是这样的，如果用go env -w 来设置goroot，那么这个值就会保存到GOENV对应的文件里，如果是$env:GOROOT=xxx的方式来设置则不会修改GOENV文件里的内容。这时候，如果vscode是优先从GOENV文件来获取GOROOT的话，就可能会导致与实际的GOROOT不一致。\n所以，如果再遇到以上错误，除了echo $env:GOROOT 看一下环境变量值之外，也要看一下GOENV文件。\n"},{"id":8,"href":"/posts/2023/09/%E7%B3%BB%E7%BB%9F%E9%97%B4%E9%80%9A%E8%BF%87%E7%BD%91%E7%BB%9C%E4%BA%A4%E4%BA%92%E4%BB%A5%E5%AE%8C%E6%88%90%E4%BA%8B%E5%8A%A1/","title":"不同系统之间通过网络对接","section":"09","content":"不同系统之间通过网络对接\n数据库事件 # 可以用个事件表来做，在事务执行过程中添加事件(确保事务完成时事件也存在)。\n在事务提交之后，先尝试做一次事件，如果成功了就把事件状态置为成功；如果失败了也没关系，另外开定时器来扫表进行重试执行。 \u0026ndash; 此时不影响正常业务执行\n在事件处理事务里的网络请求里加入超时控制，确保事件不会执行太久，导致接口过慢。\n网络请求支持幂等，防止事件处理事务请求成功了，但是事务挂了导致状态未变更，这种情况下会重复请求多次。\nskip locked实现 # -- 条件字段必须有索引(status, [name, status])，排序字段必须是主键(id)，此时刚好是所要锁定的行 start transaction; -- select * from w_event we where status in (1) order by create_time asc limit 1 for update skip locked; -- 引入create_time作为排序字段时，会将符合条件的行都锁住，`limit 1`不起作用 select * from w_event we where status in (1) order by id asc limit 1 for update skip locked; -- 使用主键字段作排序时，`limit 1`则起作用 select * from w_event we where name = \u0026#39;测试\u0026#39; and status in (1) order by id asc limit 1 for update skip locked; -- 如果有多个字段作为条件，需要建立组合索引 SELECT object_name, index_name, lock_type, lock_mode, lock_data FROM performance_schema.data_locks; -- 查看上锁情况 select * from w_event we where status in (2) order by id asc limit 1 for update skip locked; select * from w_event we where status in (3) order by id asc limit 1 for update skip locked; commit; 可打开两个线程来验证上述事务执行，可以看到，当满足条件的记录有两条或以上时，当事务1查到记录1后，事务1未提交时，事务2不会拿到记录1，而是会拿到记录2. 也就实现了有锁则获取下一批数据的效果。\n消息队列 # 选择Kafka等消息队列，在事务执行完成后，发送消息到消息队列，然后消费端处理该消息。\n如果消息发送时失败了呢？\n监听binlog # 通过监听binlog\u0026ndash;此时事务必定是已完成了，将消息推送到消息队列。如果推送失败，binlog offset不变，下次依然会继续推送该消息，从而确保推送消息到队列会做到。\n怎么知道这次该从哪个binlog offset开始读起呢？\nrelay log # The source\u0026rsquo;s binary log is written to a local relay log on the replica before it is processed. The replica also records information about the current position with the source\u0026rsquo;s binary log and the local relay log. See Section 17.2.4, “Relay Log and Replication Metadata Repositories”.\nreplication-implementation\nThe replica\u0026rsquo;s connection metadata repository contains information that the replication I/O (receiver) thread needs to connect to the replication source server and retrieve transactions from the source\u0026rsquo;s binary log. The metadata in this repository includes the connection configuration, the replication user account details, the SSL settings for the connection, and the file name and position where the replication receiver thread is currently reading from the source\u0026rsquo;s binary log.\nThe replica\u0026rsquo;s applier metadata repository contains information that the replication SQL (applier) thread needs to read and apply transactions from the replica\u0026rsquo;s relay log. The metadata in this repository includes the file name and position up to which the replication applier thread has executed the transactions in the relay log, and the equivalent position in the source\u0026rsquo;s binary log. It also includes metadata for the process of applying transactions, such as the number of worker threads and the PRIVILEGE_CHECKS_USER account for the channel.\nThe connection metadata repository is written to the slave_master_info table in the mysql system schema, and the applier metadata repository is written to the slave_relay_log_info table in the mysql system schema. A warning message is issued if mysqld is unable to initialize the tables for the replication metadata repositories, but the replica is allowed to continue starting. This situation is most likely to occur when upgrading from a version of MySQL that does not support the use of tables for the repositories to one in which they are supported.\nReplication Metadata Repositories\n-- connection metadata repository, 记录已读到的binlog文件和位置信息 select Number_of_lines , Master_log_name , Master_log_pos from mysql.slave_master_info; -- applier metadata repository, 记录已处理的relaylog文件和位置信息 select Number_of_lines , Relay_log_name , Relay_log_pos from mysql.slave_relay_log_info; 先写队列，事务发生在消费消息时 # 接口请求来到时，均是先把数据写入消息队列，然后在消费端进行事务处理，如果写入消息队列失败则直接返回错误，让用户稍后重试。\n基于消息队列的持久特性，确保消息被消费一次。\n附 # binlog读取 # -- 选项解析： -- IN \u0026#39;log_name\u0026#39; 指定要查询的binlog文件名(不指定就是第一个binlog文件) -- FROM pos 指定从哪个pos起始点开始查起(不指定就是从整个文件首个pos点开始算) -- LIMIT [offset,] 偏移量(不指定就是0) -- row_count 查询总条数(不指定就是所有行) show binlog events [IN \u0026#39;log_name\u0026#39;] [FROM pos] [LIMIT [offset,] row_count]; "},{"id":9,"href":"/posts/2023/09/your_life/","title":"do","section":"09","content":"你在做的事情，是在重复已知的东西，还是在探索未知的东西。\n这决定了所能达到的高度。\n"},{"id":10,"href":"/posts/2023/09/go_empty_struct/","title":"Go Empty Struct","section":"09","content":"package main import ( \u0026#34;fmt\u0026#34; \u0026#34;unsafe\u0026#34; ) func main() { type A struct{} type B struct{} // 结构体里的字段都是`Empty Struct`时，占用空间为0 type S struct { A A B B } var s S fmt.Println(unsafe.Sizeof(s)) // prints 0 // 如果是指针，占用空间为8 fmt.Println(unsafe.Sizeof(\u0026amp;s)) // prints 8 var x [1000000000]struct{} // 可以同时存储A和B类型元素 x[0] = A{} x[1] = B{} fmt.Println(unsafe.Sizeof(x)) // prints 0 // 地址一样 fmt.Printf(\u0026#34;%p, %p\u0026#34;, \u0026amp;x[0], \u0026amp;x[1]) // 0x54e3a0, 0x54e3a0 } See also\n"},{"id":11,"href":"/posts/2023/07/jupyter/","title":"Jupyter notebook","section":"07","content":"Install: pip install --user jupyter.\nInstall plugin: jupyter install matplotlib.\nInstall rust tools: cargo install evcxr_jupyter \u0026amp;\u0026amp; evcxr_jupyter --install.\nInstall plugin: jupyter install plotters.\nStart: jupyter notebook --port 35222.\n"},{"id":12,"href":"/posts/2023/07/vscode_traslate/","title":"Vscode Translate","section":"07","content":"试了几个vscode的翻译插件，包括Google Translate, Comment Translate, Translate Var。\n来自intellsmi的Comment Translate最终脱颖而出。\n它支持Google, Bing, Baidu等翻译工具。\n设置：选择翻译工具Bing，再设置源语言和目标语言。\n使用：选中单词即会自动翻译，非常方便。\n"},{"id":13,"href":"/posts/2023/07/windows_restart_remote_service/","title":"Windows restart remote service","section":"07","content":"Windows如何方便的重启远程服务器里的服务，在不使用远程连接的情况下？\n注意：服务(名称：service-name)已在远程机器上创建。\n在本机新建映射网络驱动器.\n打开映射好的文件夹，在其中添加bat和ps1文件:\nrestart.bat:\n@echo off for %%i in (service-name) do ( echo the service \u0026#39;%%i\u0026#39; is being starting... sc query %%i net stop %%i net start %%i sc query %%i echo service \u0026#39;%%i\u0026#39; started. ) pause restart.ps1:\n$Username = \u0026#39;Name\u0026#39; $Password = \u0026#39;Password\u0026#39; $pass = ConvertTo-SecureString -AsPlainText $Password -Force $Cred = New-Object System.Management.Automation.PSCredential -ArgumentList $Username,$pass Invoke-Command -ComputerName [Remote-IP] -ScriptBlock { Get-Service WinRM } -credential $Cred Invoke-Command -ComputerName [Remote-IP] -credential $Cred -ScriptBlock { E:\\win-dms4\\restart.bat } # 此处指定上述bat文件在远程机器上的决对路径 Read-Host -Prompt \u0026#34;Press Enter to exit\u0026#34; 完成后，只要在本机打开映射的文件夹，使用PowerShell执行restart.ps1脚本，即可快速重启指定服务。\n"},{"id":14,"href":"/posts/2023/07/error/","title":"错误的定义和返回","section":"07","content":"错误的定义和返回\n错误的定义 # 错误粒度：太细则既多又杂，太宽则毫无意义。\n个人觉得一般需要的错误有以下：正常、参数错误、业务错误、内部错误、返回错误。业务错误又有：无权限、处理超时、无记录、已经存在。\n可参照 GRPC的实现。\nCode Number Description OK 0 Not an error; returned on success. CANCELLED 1 The operation was cancelled, typically by the caller. UNKNOWN 2 Unknown error. For example, this error may be returned when a Status value received from another address space belongs to an error space that is not known in this address space. Also errors raised by APIs that do not return enough error information may be converted to this error. INVALID_ARGUMENT 3 The client specified an invalid argument. Note that this differs from FAILED_PRECONDITION. INVALID_ARGUMENT indicates arguments that are problematic regardless of the state of the system (e.g., a malformed file name). DEADLINE_EXCEEDED 4 The deadline expired before the operation could complete. For operations that change the state of the system, this error may be returned even if the operation has completed successfully. For example, a successful response from a server could have been delayed long NOT_FOUND 5 Some requested entity (e.g., file or directory) was not found. Note to server developers: if a request is denied for an entire class of users, such as gradual feature rollout or undocumented allowlist, NOT_FOUND may be used. If a request is denied for some users within a class of users, such as user-based access control, PERMISSION_DENIED must be used. ALREADY_EXISTS 6 The entity that a client attempted to create (e.g., file or directory) already exists. PERMISSION_DENIED 7 The caller does not have permission to execute the specified operation. PERMISSION_DENIED must not be used for rejections caused by exhausting some resource (use RESOURCE_EXHAUSTED instead for those errors). PERMISSION_DENIED must not be used if the caller can not be identified (use UNAUTHENTICATED instead for those errors). This error code does not imply the request is valid or the requested entity exists or satisfies other pre-conditions. RESOURCE_EXHAUSTED 8 Some resource has been exhausted, perhaps a per-user quota, or perhaps the entire file system is out of space. FAILED_PRECONDITION 9 The operation was rejected because the system is not in a state required for the operation\u0026rsquo;s execution. For example, the directory to be deleted is non-empty, an rmdir operation is applied to a non-directory, etc. Service implementors can use the following guidelines to decide between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE: (a) Use UNAVAILABLE if the client can retry just the failing call. (b) Use ABORTED if the client should retry at a higher level (e.g., when a client-specified test-and-set fails, indicating the client should restart a read-modify-write sequence). (c) Use FAILED_PRECONDITION if the client should not retry until the system state has been explicitly fixed. E.g., if an \u0026ldquo;rmdir\u0026rdquo; fails because the directory is non-empty, FAILED_PRECONDITION should be returned since the client should not retry unless the files are deleted from the directory. ABORTED 10 The operation was aborted, typically due to a concurrency issue such as a sequencer check failure or transaction abort. See the guidelines above for deciding between FAILED_PRECONDITION, ABORTED, and UNAVAILABLE. OUT_OF_RANGE 11 The operation was attempted past the valid range. E.g., seeking or reading past end-of-file. Unlike INVALID_ARGUMENT, this error indicates a problem that may be fixed if the system state changes. For example, a 32-bit file system will generate INVALID_ARGUMENT if asked to read at an offset that is not in the range [0,2^32-1], but it will generate OUT_OF_RANGE if asked to read from an offset past the current file size. There is a fair bit of overlap between FAILED_PRECONDITION and OUT_OF_RANGE. We recommend using OUT_OF_RANGE (the more specific error) when it applies so that callers who are iterating through a space can easily look for an OUT_OF_RANGE error to detect when they are done. UNIMPLEMENTED 12 The operation is not implemented or is not supported/enabled in this service. INTERNAL 13 Internal errors. This means that some invariants expected by the underlying system have been broken. This error code is reserved for serious errors. UNAVAILABLE 14 The service is currently unavailable. This is most likely a transient condition, which can be corrected by retrying with a backoff. Note that it is not always safe to retry non-idempotent operations. DATA_LOSS 15 Unrecoverable data loss or corruption. UNAUTHENTICATED 16 The request does not have valid authentication credentials for the operation. 实现时，错误码范围控制在0~255，将0~35留作预定义错误码，36~255留作自定义错误码。\n除特殊情况需要自定义错误码外，均使用预定义错误码。\n错误的返回 # 在开发测试环境里，除了返回错误粒度外，还需附上具体的错误信息，如堆栈等，方便调试；\n在预发布正式环境里，只返回错误粒度，隐藏具体的错误信息，防止被别有用心者利用。\n无论开发测试、预发布正式环境，一律将错误打印到日志，日志带有追踪标识等信息。\n接口一律返回追踪标识，后续根据该标识即可在日志文件里查询到请求的所有日志。\n"},{"id":15,"href":"/posts/2023/07/prometheus/","title":"Prometheus start failed","section":"07","content":" Question # prometheus start failed:\n... ts=2023-07-06T01:34:43.871Z caller=repair.go:57 level=info component=tsdb msg=\u0026#34;Found healthy block\u0026#34; mint=1688493607159 maxt=1688515200000 ulid=01H4J6TB6NCBZFNR9XZ1R2P67H ts=2023-07-06T01:34:43.871Z caller=repair.go:57 level=info component=tsdb msg=\u0026#34;Found healthy block\u0026#34; mint=1688529607159 maxt=1688536800000 ulid=01H4JDM4YR6J3TJVBY6P6EGZS4 ts=2023-07-06T01:34:43.872Z caller=repair.go:57 level=info component=tsdb msg=\u0026#34;Found healthy block\u0026#34; mint=1688536807159 maxt=1688544000000 ulid=01H4JMFGKWY1MAM7GBFDQ89FRV ts=2023-07-06T01:34:43.872Z caller=main.go:696 level=info msg=\u0026#34;Stopping scrape discovery manager...\u0026#34; ts=2023-07-06T01:34:43.872Z caller=main.go:710 level=info msg=\u0026#34;Stopping notify discovery manager...\u0026#34; ts=2023-07-06T01:34:43.872Z caller=main.go:732 level=info msg=\u0026#34;Stopping scrape manager...\u0026#34; ts=2023-07-06T01:34:43.872Z caller=manager.go:946 level=info component=\u0026#34;rule manager\u0026#34; msg=\u0026#34;Stopping rule manager...\u0026#34; ts=2023-07-06T01:34:43.872Z caller=manager.go:956 level=info component=\u0026#34;rule manager\u0026#34; msg=\u0026#34;Rule manager stopped\u0026#34; ts=2023-07-06T01:34:43.872Z caller=notifier.go:601 level=info component=notifier msg=\u0026#34;Stopping notification manager...\u0026#34; ts=2023-07-06T01:34:43.872Z caller=main.go:726 level=info msg=\u0026#34;Scrape manager stopped\u0026#34; ts=2023-07-06T01:34:43.872Z caller=main.go:692 level=info msg=\u0026#34;Scrape discovery manager stopped\u0026#34; ts=2023-07-06T01:34:43.872Z caller=main.go:907 level=info msg=\u0026#34;Notifier manager stopped\u0026#34; ts=2023-07-06T01:34:43.872Z caller=main.go:706 level=info msg=\u0026#34;Notify discovery manager stopped\u0026#34; ts=2023-07-06T01:34:43.872Z caller=tls_config.go:195 level=info component=web msg=\u0026#34;TLS is disabled.\u0026#34; http2=false ts=2023-07-06T01:34:43.872Z caller=main.go:916 level=error err=\u0026#34;opening storage failed: get segment range: segments are not sequential\u0026#34; Answer # rm -rf /var/lib/prometheus/metrics2/ Path is from prometheus -h | grep '--storage.tsdb.path'.\n"},{"id":16,"href":"/posts/2023/07/compare_order/","title":"Compare and Order","section":"07","content":"比，争。\n比较，争先。\n拿他与她比，让他与她争。\n做黄雀，做渔翁。\n不比，不争。\n不付出无收获？\n丛林社会，谈何付出，谈何收获。\n有付出也无收获。\n"},{"id":17,"href":"/posts/2023/06/sklearn/","title":"ml sklearn","section":"06","content":" 尝试 # $ pip install scikit-learn $ python3.10 \u0026gt;\u0026gt;\u0026gt; from sklearn.datasets import load_iris \u0026gt;\u0026gt;\u0026gt; from sklearn.linear_model import LogisticRegression \u0026gt;\u0026gt;\u0026gt; data, y = load_iris(return_X_y=True) \u0026gt;\u0026gt;\u0026gt; clf = LogisticRegression(random_state=0, max_iter=1000).fit(data, y) \u0026gt;\u0026gt;\u0026gt; clf.predict(data[:2, :]) \u0026gt;\u0026gt;\u0026gt; clf.predict_proba(data[:2, :]) \u0026gt;\u0026gt;\u0026gt; clf.score(data, y) 查找操作记录 # cat ~/.python_history.\n模型、策略、优化算法 # 模型是输入输出函数：Y = F(X).\n策略是拟合过程的损失函数：L(Y, F(X)), 可以是均方误差、对数损失函数、交叉熵损失函数。\n优化算法：确定模型和损失函数后，可以加速计算的方法，比如：随机梯度下降法、牛顿法、拟牛顿法。\n"},{"id":18,"href":"/posts/2023/06/route/","title":"windows route","section":"06","content":" Windows通过route命令配置路由 # route add 192.168.0.0 mask 255.255.0.0 192.168.66.254 -p 192.168.0.0: 目标主机的网络地址\nmask 255.255.0.0: 掩码，与目标网络地址对应\n192.168.66.254: 网关地址\nLinux通过ip route命令配置路由 # NOTE: ip route是route命令的升级版本，但route命令仍在大量使用。\n# 设置192.168.4.0网段的网关为192.168.166.1,数据走wlan0接口 # /24 is the network prefix. The network prefix is the number of enabled bits in the subnet mask. # 24位子网掩码 ip route add 192.168.4.0/24 via 192.168.166.1 dev wlan0 # 255.255.255.0为子网掩码 # 3*8(255即是8位二进制) ip route add 192.168.0.0/255.255.255.0 dev eth0 子网掩码 # ip地址包含了网络地址和主机地址两部分，怎么区分呢？\n这是就需要用到子网掩码了，它是一个与ip地址同位数、连续的数，可以用位数24表示，也可以用地址255.255.255.0表示。\n两个地址经过位与运算后，ip中没被掩盖的部分即是网络地址，被掩盖的部分即是主机地址。\n"},{"id":19,"href":"/posts/2023/06/wsl2/","title":"wsl2初始化Mysql数据库速度非常慢","section":"06","content":" wsl2版本 # \u0026gt; wsl.exe -v WSL version: 1.2.5.0 Kernel version: 5.15.90.1 WSLg version: 1.0.51 MSRDC version: 1.2.3770 Direct3D version: 1.608.2-61064218 DXCore version: 10.0.25131.1002-220531-1700.rs-onecore-base2-hyp Windows version: 10.0.19045.3031 使用过程中，因为磁盘空间问题，把子系统安装位置从C盘转移到了其它盘。\n操作 # 把sql目录里的*.sql文件逐一导入到8.0.33版本的Mysql。\n尽管sql文件不多也不大，但是整个过程非常慢。其中一个有一千个左右的INSERT IGNORE语句，更是用了将近12分钟才完成。\n怎么办？ # 改为通过网络访问本机的数据库。\n端口 # 一文中提到：\n根据我的观察, 如果Windows本地启动了指定端口, 这时WSL2中虽然可以使用相同的端口, 但是localhost:port 将指向Windows的服务, WSL的服务将会被覆盖!\n当然了, 如果我们配置了端口转发, 转发的IP是WSL的地址, 而不是localhost, 那么WSL将会覆盖Windows的服务!\n而我的观察是，\n我发现本地起了数据库服务之后，在wsl2里起数据库服务（mysql服务，端口都是3306）的情况下，是不会报端口重复绑定错误的。\n但是如果我在wsl2里先起一个服务，绑定端口14222后，再在主机起相同服务，想绑定相同端口时，则会报错端口已被绑定。\n如果我是先在主机起上述服务，然后再在wsl2起该服务，则能正常启动。那在主机访问localhost:[port]时会访问到哪个呢？此时访问到的是主机的服务。\n所以端口是否占用会不会还跟服务起的顺序有关呢？\n暂时未看到有确切的描述。\n但是，经过上面的实验，可以认为：\n先在主机起服务，再在wsl2起服务绑定相同端口时，服务可正常启动；在主机访问`localhost:[port]`时访问的是主机的服务；在wsl2里访问的则是wsl2的服务，除非手动指定主机IP。 而如果先在wsl2里起了服务，再在主机起服务（绑定相同端口: 14222），则会报错端口已被绑定。 但是，如果在wsl2里先起的mysql服务，再在主机起，则不会报错，所以还跟端口值有关？ "},{"id":20,"href":"/posts/2023/05/flutter_widget_element/","title":"flutter Widget Element","section":"05","content":" Element # abstract class Element extends DiagnosticableTree implements BuildContext package:flutter/src/widgets/framework.dart\nAn instantiation of a [Widget] at a particular location in the tree. \u0026ndash; 在树里的特定位置上的一个Widget的实例。\nWidgets describe how to configure a subtree but the same widget can be used to configure multiple subtrees simultaneously because widgets are immutable. An [Element] represents the use of a widget to configure a specific location in the tree. Over time, the widget associated with a given element can change, for example, if the parent widget rebuilds and creates a new widget for this location. \u0026ndash; Widget描述了如何配置一棵子树，但同一个Widget可以被用来配置多棵相似的子树，因为Widget是不可变的。一个Element代表了一个Widget配置在树里的特定位置的使用。随着时间变化，每个Widget与一个可以改变的Element关联。\nElements form a tree. Most elements have a unique child, but some widgets (e.g., subclasses of [RenderObjectElement]) can have multiple children.\nWidget # abstract class Widget extends DiagnosticableTree package:flutter/src/widgets/framework.dart\nDescribes the configuration for an [Element]. \u0026ndash; 对Element的配置。\nWidgets are the central class hierarchy in the Flutter framework. A widget is an immutable description of part of a user interface. Widgets can be inflated into elements, which manage the underlying render tree. \u0026ndash; 一个Widget是一个不可变的描述。\nWidgets themselves have no mutable state (all their fields must be final). If you wish to associate mutable state with a widget, consider using a [StatefulWidget], which creates a [State] object (via [StatefulWidget.createState]) whenever it is inflated into an element and incorporated into the tree. \u0026ndash; Widget自身没有可变状态，它们的所有字段都必须是final的。如果你想让Widget关联可变状态，考虑使用一个StatefulWidget，无论它什么时候被放入到一个element里，它都会创建一个State对象。\nRenderObject # abstract class RenderObject extends AbstractNode with DiagnosticableTreeMixin implements HitTestTarget package:flutter/src/rendering/object.dart\nAn object in the render tree.\nThe [RenderObject] class hierarchy is the core of the rendering library\u0026rsquo;s reason for being. \u0026ndash; 渲染库的核心\nwww.youtube.com/watch?v=zmbmrw07qBc\n[RenderObject]s have a [parent], and have a slot called [parentData] in which the parent [RenderObject] can store child-specific data, for example, the child position. The [RenderObject] class also implements the basic layout and paint protocols.\nThe [RenderObject] class, however, does not define a child model (e.g. whether a node has zero, one, or more children). It also doesn\u0026rsquo;t define a coordinate system (e.g. whether children are positioned in Cartesian coordinates, in polar coordinates, etc) or a specific layout protocol (e.g. whether the layout is width-in-height-out, or constraint-in-size-out, or whether the parent sets the size and position of the child before or after the child lays out, etc; or indeed whether the children are allowed to read their parent\u0026rsquo;s [parentData] slot). \u0026ndash; 不会定义一个子模型。不会定义一个协作系统。不干实事，只作约束。\nThe [RenderBox] subclass introduces the opinion that the layout system uses Cartesian coordinates.\n"},{"id":21,"href":"/posts/2023/05/mysqlrouter/","title":"mysqlrouter使用","section":"05","content":" What # mysqlrouter是一个代理，可以将查询转发到配置好的数据库服务里。\nWhy # 在办公室网络环境下基于win10 wsl2开发应用时，需要连接到主机所在局域网的其它机器上的数据库服务。\n也就是说，存在机器：wsl2、主机、其它机器。\nwsl2通过NAT网络模式与主机互通，并且wsl2可以访问外网。\n但是wsl2不能访问到其它机器上的数据库服务，不知道是不是办公室网络环境存在限制。\n为了使得wsl2能访问到其它机器上的数据库服务成立，在主机启动mysqlrouter充当代理，然后wsl2通过访问代理来访问其它机器。\nInstall # 可以使用mysql installer选择安装。\n简单模式 # 配置文件（mysqlrouter.conf）：\n[DEFAULT] logging_folder = D:/Data/mysqlrouter/log plugin_folder = C:/Program Files/MySQL/MySQL Router 8.0/lib # 这里是插件所在目录，必须是mysqlrouter安装路径下的目录，否则报错找不到插件 config_folder = D:/Data/mysqlrouter/etc # 启动配置默认查找目录，会在目录里寻找mysqlrouter.conf文件 runtime_folder = D:/Data/mysqlrouter/run data_folder = D:/Data/mysqlrouter/data [logger] level = DEBUG [routing:primary] bind_address=172.20.96.1 # 主机ip地址 bind_port=6446 # 主机监听端口 destinations = 172.17.39.239:3306 # 目标机器，也就是实际执行查询的数据库服务所在机器的地址 mode = read-write connect_timeout = 10 启动：mysqlrouter -c D:\\Data\\mysqlrouter\\etc\\mysqlrouter.conf\n关闭防火墙或者配置规则允许端口通过。\n在wsl2机器上访问：mysql -h 172.20.96.1 -P 6446 -uroot -p，即可访问到172.17.39.239:3306机器上的数据库服务。\n问题 # 报错：Error: Loading plugin... 找不到指定的程序。\nmysqlrouter -c D:\\Data\\mysqlrouter\\etc\\mysqlrouter.conf Error: Loading plugin for config-section \u0026#39;[routing:primary]\u0026#39; failed: D:/Data/mysqlrouter/lib/routing.dll: 找不到指定的程序。 PS D:\\Project\u0026gt; PS D:\\Project\u0026gt; mysqlrouter_plugin_info D:/Data/mysqlrouter/lib/routing.dll routing [ERROR] Could not load plugin file \u0026#39;D:/Data/mysqlrouter/lib/routing.dll\u0026#39;: 找不到指定的程序。 解决：需要将plugin_folder配置的值改为mysqlrouter安装路径下的目录。\n其它代理 # 如果只是针对mysql，则使用mysqlrouter即可，但如果还有其它服务，则还不够。\ngoproxy # 这时，可以使用 goproxy。\n注意，这个项目的源码不是最新的（直接使用基于源码构建出来的proxy会有与文档不一致的表现），需要去 下载最新的二进制执行文件.\n解压后执行，即可启动代理，如下述命令将启动一个代理，其监听本地33080端口，并将请求转发到172.17.39.239:3306目标机器：\n.\\proxy.exe tcp -p \u0026#34;:33080\u0026#34; -T tcp -P \u0026#34;172.17.39.239:3306\u0026#34; 访问sqlserver # 通过代理(不同的端口)连接172.17.39.239机器上的sqlserver:\n.\\proxy.exe tcp -p \u0026#34;:33081\u0026#34; -T tcp -P \u0026#34;172.17.39.239:1433\u0026#34; 加密 # 如果要生成密钥，必须在linux环境下使用proxy keygen生成密钥(在windows环境里会报错)。\n自定义tcp代理 # 地址.\n下载源码：git clone git@github.com:donnol/do.git\n安装: go install ./cmd/letgo\n使用: letgo proxy \u0026ndash;remoteAddr=\u0026ldquo;172.17.39.239:3306\u0026rdquo;\n默认监听端口54388，将收到的数据转发到指定的地址：172.17.39.239:3306。\n可通过监听不同的端口转发数据到不同的地址。\n"},{"id":22,"href":"/posts/2023/04/nats/","title":"NATS","section":"04","content":" 是什么？ # Home, Github\nNATS 是一个简单、安全和高性能的通信系统，适用于数字系统、服务和设备。\nNATS 是一种允许以消息形式分段的数据交换的基础架构。\n基于主题 # 发布者将消息发到主题；订阅者订阅主题，在有消息到来时消费该消息。\n主题命名规则：\n基本字符：a to z, A to Z and 0 to 9 (区分大小写，不能包含空白字符).\n特殊字符: . (分割符，分割不同部分，每部分视为一个token)； * 和 \u0026gt; (通配符，*表示匹配一个token，\u0026gt;表示匹配一或多个token).\n保留主题名称: 以 $ 开头的用在系统内部 (如：$SYS, $JS, $KV \u0026hellip;)\n发布-订阅 # Core NATS: 一个主题，存在一个发布者，多个订阅者。\n消息会复制到多个订阅者。\n请求-响应 # A request is sent, and the application either waits on the response with a certain timeout, or receives a response asynchronously.\n\u0026ndash; 请求发出后，应用要不等待响应超时，要不就异步收到一个响应。\nTODO:\nQueue groups # if more subscribers are added to the same queue name, they become a queue group, and only one randomly chosen subscriber of the queue group will consume a message each time a message is received by the queue group.\n如果多个订阅者被添加到同一个队列里，它们就成为一个队列组；当消息来时，只会随机选择一个订阅者来消费这条消息。\n消息生产后会由任意一个订阅者消费。(分区)\n为什么？ # QOS # At most once QoS: Core NATS offers an at most once quality of service. If a subscriber is not listening on the subject (no subject match), or is not active when the message is sent, the message is not received. This is the same level of guarantee that TCP/IP provides. Core NATS is a fire-and-forget messaging system. It will only hold messages in memory and will never write messages directly to disk. \u0026ndash; 最多一次：如果订阅者没有监听subject，或者当消息被发送时不可用，它将接收不到该消息。这也是TCP/IP提供的同等保证。因为core NATS只会将消息存储在内存里，而不会存储到硬盘里。\nAt-least / exactly once QoS: If you need higher qualities of service (at least once and exactly once), or functionalities such as persistent streaming, de-coupled flow control, and Key/Value Store, you can use NATS JetStream, which is built in to the NATS server (but needs to be enabled). Of course, you can also always build additional reliability into your client applications yourself with proven and scalable reference designs such as acks and sequence numbers. \u0026ndash; 最少一次或刚好一次：使用JetStream模式。它会将消息存储到硬盘里，从而确保消息不会丢失。如果订阅者在消息发送时刚好离线了，在它恢复后，它将会继续消费该条消息。\n持久化 # jet stream.\nJetStream was created to solve the problems identified with streaming in technology today - complexity, fragility, and a lack of scalability. \u0026ndash; 解决一些流的问题：复杂、碎片、扩展。\n内嵌NATS服务到应用里 # 单一进程里启动NATS服务。\n"},{"id":23,"href":"/posts/2023/01/go_generic_join/","title":"Go Generic Join","section":"01","content":"// NestedJoin like nested loop join func NestedJoin[J, K, R any]( left []J, right []K, match func(J, K) bool, mapper func(J, K) R, ) []R { var r = make([]R, 0, len(left)) for _, j := range left { for _, k := range right { if !match(j, k) { continue } r = append(r, mapper(j, k)) } } return r } // HashJoin like hash join func HashJoin[K comparable, LE, RE, R any]( left []LE, right []RE, lk func(item LE) K, rk func(item RE) K, mapper func(LE, RE) R, ) []R { var r = make([]R, 0, len(left)) rm := KeyBy(right, rk) for _, le := range left { k := lk(le) re := rm[k] r = append(r, mapper(le, re)) } return r } Code From\n"},{"id":24,"href":"/posts/2022/07/jump_table/","title":"Jump Table","section":"07","content":" What\u0026rsquo;s Jump Table? # A jump table can be either an array of pointers to functions or an array of machine code jump instructions. If you have a relatively static set of functions (such as system calls or virtual functions for a class) then you can create this table once and call the functions using a simple index into the array. This would mean retrieving the pointer and calling a function or jumping to the machine code depending on the type of table used.\nThe benefits of doing this in embedded programming are:\nIndexes are more memory efficient than machine code or pointers, so there is a potential for memory savings in constrained environments. For any particular function the index will remain stable and changing the function merely requires swapping out the function pointer. If does cost you a tiny bit of performance for accessing the table, but this is no worse than any other virtual function call. From Stackoverflow\nTry # // 跳表 // 创建后，不会改变的函数指针数组；后续可以根据数组索引来直接找到相应函数并执行 // 至于，为什么要这样干，是因为数组索引查找更高效 // 初始化 var ( funcArray = [...]func(){ func() { fmt.Println(0) }, func() { fmt.Println(1) }, // more ... } ) func main() { // 使用 funcArray[0]() funcArray[1]() // more ... } Playground\n"},{"id":25,"href":"/posts/2022/07/number_calculate/","title":"数字计算之分摊","section":"07","content":"背景：分多次把一批货全部出清。\n要求：需要确保这批货多次出清跟一次出清收的钱一样。\n现有三个数字(可整数，可小数)：a b c，其中：a 为数量，b 为价格，c 为折扣。\n则总额为: t, t = a*b*c\n假设分三次，每次数量为：a1 a2 a3，则有：a = a1 + a2 + a3\n直接计算： 第 1 次.\na1*b*c 第 2 次.\na2*b*c 第 3 次.\na3*b*c (a1+a2+a3)bc 不就等于 abc 了吗？\n但是，如果考虑到小数乘法计算时的精度，比如：1.22*2.33 相乘后再取精度（保留两位小数），不就会导致数量误差了吗？\n那如果取精度导致结果误差，那我不取精度，直接用所有小数位数来计算呢。\n虽说可以，但小数位数是有可能非常多的，占用的空间也是一笔不小的开销。\n引入中间量(可称为\u0026rsquo;余额\u0026rsquo;): x y z x = a y = x*b z = y*c 第 1 次.\nx1 = (x-a1) y1 = (y-y*a1/x) z1 = (z-z*a1/x) t1 = z*a1/x 第 2 次.\nx2 = (x1-a2) y2 = (y1-y1*a2/x1) z2 = (z1-z1*a2/x1) t2 = z1*a2/x1 第 3 次.\nx3 = (x2-a3) y3 = (y2-y2*a3/x2) z3 = (z2-z2*a3/x2) t3 = z2*a3/x2 求证：t = t1 + t2 + t3 ?\na*b*c = (a*b*c*a1/a) + ((a*b*c - a*b*c*a1/a)*a2/(a-a1)) + ((a*b*c - a*b*c*a1/a) - (a*b*c - a*b*c*a1/a)*a2/(a-a1))*a3/(a-a1-a2) a*b*c = (a*b*c*a1/a) + ((a*b*c - a*b*c*a1/a)*a2/(a-a1)) + ((a*b*c - a*b*c*a1/a) - (a*b*c - a*b*c*a1/a)*a2/(a-a1)) a*b*c = (a*b*c*a1/a) + ((a*b*c - a*b*c*a1/a)*a2/(a-a1)) + -- (a*b*c - a*b*c*a1/a)*(1 - a2/(a-a1)) (a*b*c - a*b*c*a1/a)*(a3/(a2+a3)) a*b*c = (a*b*c*a1/a) + (a*b*c - a*b*c*a1/a)*a2/(a2+a3) + (a*b*c - a*b*c*a1/a)*(a3/(a2+a3)) a*b*c = (a*b*c*a1/a) + (a*b*c - a*b*c*a1/a) a*b*c = a*b*c "},{"id":26,"href":"/posts/2022/05/generic/","title":"泛型","section":"05","content":" 泛型 # 是什么？ # Type parameter, 类型参数。func Add[T Number](x, y T) (r T)，其中的T就是类型参数，它被接口Number所约束。\ntype Number interface { int | float32 } 调用方除了可自行决定参数值之外，还可以自行决定参数类型。Add[int](1, 2)，在调用时指定T的类型为int，同时传入参数值1,2必须是int类型。\n这样使得代码更灵活，更有扩展性，同时更安全。\nGo泛型 # 为什么？ # 静态语言，类型固定，比如这个函数：func Add(x, y int) int就要求参数和结果都必须是整型。\n那如果后来又需要一个浮点数的加法呢？\n那使用interface{}不也可以吗？\n试看：\n// 准确的描述出了参数和返回值的类型，非常方便 func Add(x, y int) int // 但也限制了Add函数的参数类型--只能接收`int` // Add(0.1, 0.2) // can\u0026#39;t do that // 那怎么办呢？再写一个针对float64的呗 func AddFloat64(x, y float64) float64 AddFloat64(0.1, 0.2) // it\u0026#39;s ok // 如果还要支持其它类型呢？再加一个吗，每多一种类型，就多加一个。。。 func AddInt8(x, y int8) int8 func AddInt32(x, y int32) int32 func AddFloat32(x, y float32) float32 // more... // emm. // how about interface{}? func AddAny(x, y interface{}) interface{} { switch x.(type) { case int: case int8: case int32: case float32: case float64: // more... default: panic(\u0026#34;not support type\u0026#34;) } } // interface{}表示可以接收任意类型的值，并且返回任意类型的值 // 换言之，参数的类型和返回值的类型没有必然联系--从签名看来，它们可以一样，也可以不一样 // 所以，使用interface{}不够安全。 func AddGeneric1[T any](x, y T) T // 看起来跟AddAny差不多，但是参数类型和返回值类型必然是相同的 // 但any并不一定支持+运算符，所以需要用更细粒度的约束 type Number interface { ~int|~int8|~int32|~float32|~float64 } func AddGeneric2[T Number](x, y T) T // 通过Number约束，确保类型参数可加 // 泛型的存在，使得函数的类型集比any小，比int大；使得返回值和参数的类型能够动态联系。 func Map[T, E any](list []T, f func(T) E) []E { r := make([]E, len(list)) for i := range list { r[i] = f(list[i]) } return r } 一点不足 # 泛型虽然出来了，但是类型推断依然不够强大，1.21有望做出 改进和 提升。\n// 第三个参数initial其实在函数实现里并没使用到，但是为了在调用时可以省略类型参数，所以需要这样一个参数 // 但其实，如果类型推断足够强大的话，是可以从Finder约束的NewScanObjAndFields方法推断出R类型的 func FindAll[S Storer, F Finder[R], R any](db S, finder F, initial R) (r []R, err error) { query, args := finder.Query() rows, err := db.QueryContext(context.TODO(), query, args...) // sql里select了n列 if err != nil { return } defer rows.Close() colTypes, err := rows.ColumnTypes() if err != nil { return } for rows.Next() { obj, fields := finder.NewScanObjAndFields(colTypes) // fields也必须有n个元素 if err = rows.Scan(fields...); err != nil { return } // PrintFields(fields) r = append(r, *obj) } if err = rows.Err(); err != nil { return } return } // 调用时需要该无用参数 r, err := do.FindAll(tdb, finder, (UserForDB{})) // 这个才是我们想要的函数签名 func FindAll1[S do.Storer, F do.Finder[R], R any](db S, finder F) (r []R, err error) // 但是现在无法推断出R的类型，除非显式标明类型参数 FindAll1(tdb, finder1) // Error: cannot infer R (/home/jd/Project/jd/tools/db/find.go:37:38) // 显然，如果把类型参数写出来，是非常啰嗦的 FindAll1[*sql.DB, *finderOfUser, UserForDB](tdb, \u0026amp;finderOfUser{}) type Finder[R any] interface { Query() (query string, args []any) NewScanObjAndFields(colTypes []*sql.ColumnType) (r *R, fields []any) } type Storer interface { *sql.DB | *sql.Tx | *sql.Conn QueryContext(ctx context.Context, query string, args ...any) (*sql.Rows, error) } 应用 # hash join:\nfunc HashJoin[K comparable, LE, RE, R any]( // 左表和右表 left []LE, right []RE, // 左关联函数和右关联函数，它们返回同类型键 lk func(item LE) K, rk func(item RE) K, // 接收左表元素和右表元素，返回新元素 mapper func(LE, RE) R, ) []R { var r = make([]R, 0, len(left)) // 先对右表做映射 rm := KeyBy(right, rk) for _, le := range left { k := lk(le) re := rm[k] // 将关联元素做处理 r = append(r, mapper(le, re)) } return r } // KeyValueBy slice to map, key value specified by iteratee func KeyValueBy[K comparable, E, V any](collection []E, iteratee func(item E) (K, V)) map[K]V { result := make(map[K]V, len(collection)) for i := range collection { k, r := iteratee(collection[i]) result[k] = r } return result } // KeyBy slice to map, key specified by iteratee, value is slice element func KeyBy[K comparable, E any](collection []E, iteratee func(item E) K) map[K]E { return KeyValueBy(collection, func(item E) (K, E) { return iteratee(item), item }) } ts的泛型 # keyof的存在，ts的泛型更为强大：\n// Cond出现的字段必须分别在L和R均出现 export type Cond\u0026lt;L, R\u0026gt; = { l: keyof L r: keyof R } export function leftJoin\u0026lt;L, R, LR\u0026gt;( left: L[], right: R[], cond: Cond\u0026lt;L, R\u0026gt;, f: (l: L, r: R) =\u0026gt; LR, ): LR[] { let rm = new Map() right.forEach((value: R, index: number, array: R[]) =\u0026gt; { let rv = getProperty(value, cond.r) rm.set(rv, value) }) let res = new Array(left.length) left.forEach((value: L, index: number, array: L[]) =\u0026gt; { let lv = getProperty(value, cond.l) let rv = rm.get(lv) let lr = f(value, rv) res.push(lr) }) return res } export function getProperty\u0026lt;T, K extends keyof T\u0026gt;(o: T, propertyName: K): T[K] { return o[propertyName]; // o[propertyName] is of type T[K] } const users = [ { id: 1, name: \u0026#34;jd\u0026#34;, }, { id: 2, name: \u0026#34;jk\u0026#34;, }, ] const articles = [ { id: 1, userId: 1, name: \u0026#34;join\u0026#34; }, { id: 2, userId: 2, name: \u0026#34;join 2\u0026#34; }, ] let res = leftJoin(users, articles, { l: \u0026#34;id\u0026#34;, r: \u0026#34;userId\u0026#34; }, (l, r) =\u0026gt; { return { id: r.id, name: r.name, userId: l.id, userName: l.name, } }) console.log(\u0026#34;res: \u0026#34;, res) "},{"id":27,"href":"/posts/2022/05/find_go_version_the_app_use/","title":"Find out which Go version built your binary","section":"05","content":" 根据二进制文件找出应用构建时使用的Go版本 # 使用 dlv:\ndlv exec ./app \u0026gt; p runtime.buildVerion 或者，在代码里调用runtime.Version():\nfunc main() { fmt.Println(\u0026#34;go version:\u0026#34;, runtime.Version()) } 参照\n"},{"id":28,"href":"/posts/2022/05/k8s_how_to_keep_pods/","title":"k8s是怎么维持pod的运行的呢？","section":"05","content":" k8s是怎么维持pod的运行的呢？ # 当接收了yaml配置的信息后，是怎么维持pod根据声明一直运行的呢？\n让我们沿着命令执行的过程来一睹为快：kubectl apply -f pod.yaml.\n源码位置：cmd/kubectl/kubectl.go -\u0026gt; staging/src/k8s.io/kubectl/pkg/cmd/cmd.go -\u0026gt; staging/src/k8s.io/kubectl/pkg/cmd/apply/apply.go\n最终的执行方法：\nfunc (o *ApplyOptions) Run() error { // 预处理 if o.PreProcessorFn != nil { klog.V(4).Infof(\u0026#34;Running apply pre-processor function\u0026#34;) if err := o.PreProcessorFn(); err != nil { return err } } // Enforce CLI specified namespace on server request. if o.EnforceNamespace { o.VisitedNamespaces.Insert(o.Namespace) } // Generates the objects using the resource builder if they have not // already been stored by calling \u0026#34;SetObjects()\u0026#34; in the pre-processor. errs := []error{} infos, err := o.GetObjects() if err != nil { errs = append(errs, err) } if len(infos) == 0 \u0026amp;\u0026amp; len(errs) == 0 { return fmt.Errorf(\u0026#34;no objects passed to apply\u0026#34;) } // Iterate through all objects, applying each one. for _, info := range infos { if err := o.applyOneObject(info); err != nil { errs = append(errs, err) } } // If any errors occurred during apply, then return error (or // aggregate of errors). if len(errs) == 1 { return errs[0] } if len(errs) \u0026gt; 1 { return utilerrors.NewAggregate(errs) } if o.PostProcessorFn != nil { klog.V(4).Infof(\u0026#34;Running apply post-processor function\u0026#34;) if err := o.PostProcessorFn(); err != nil { return err } } return nil } // applyOneObject里会调用以下方法 func (m *Helper) Patch(namespace, name string, pt types.PatchType, data []byte, options *metav1.PatchOptions) (runtime.Object, error) { if options == nil { options = \u0026amp;metav1.PatchOptions{} } if m.ServerDryRun { options.DryRun = []string{metav1.DryRunAll} } if m.FieldManager != \u0026#34;\u0026#34; { options.FieldManager = m.FieldManager } if m.FieldValidation != \u0026#34;\u0026#34; { options.FieldValidation = m.FieldValidation } return m.RESTClient.Patch(pt). NamespaceIfScoped(namespace, m.NamespaceScoped). Resource(m.Resource). Name(name). SubResource(m.Subresource). VersionedParams(options, metav1.ParameterCodec). Body(data). Do(context.TODO()). // 调用api，把apply请求发到主节点，记录信息到etcd之后，再创建出相应的pod Get() } // 那么，接收并处理这个Patch请求的代码在哪里呢？ // NewStreamWatcher creates a StreamWatcher from the given decoder. func NewStreamWatcher(d Decoder, r Reporter) *StreamWatcher { sw := \u0026amp;StreamWatcher{ source: d, reporter: r, // It\u0026#39;s easy for a consumer to add buffering via an extra // goroutine/channel, but impossible for them to remove it, // so nonbuffered is better. result: make(chan Event), // If the watcher is externally stopped there is no receiver anymore // and the send operations on the result channel, especially the // error reporting might block forever. // Therefore a dedicated stop channel is used to resolve this blocking. done: make(chan struct{}), } go sw.receive() // 接收请求，然后通过chan发送出去，再由其它代码来处理？ return sw } // TODO: apimachinery共享库\n"},{"id":29,"href":"/posts/2022/05/go_enum/","title":"Go enum","section":"05","content":" Go enum # Go是没有内置枚举类型的，那么，当需要使用枚举时，该怎么办呢？\n枚举说白了，就是一连串互斥的值，每个值代表一样事物或一个类型。\n比如，现在需要一个颜色枚举，可以这样定义：\nconst ( Red = \u0026#34;Red\u0026#34; // 红色 Blue = \u0026#34;Blue\u0026#34; // 蓝色 Green = \u0026#34;Green\u0026#34; // 绿色 ) 也有这样定义的：\ntype Color string // 定义一个特定类型 // 枚举常量均声明为该类型 const ( Red Color = \u0026#34;Red\u0026#34; // 红色 Blue Color = \u0026#34;Blue\u0026#34; // 蓝色 Green Color = \u0026#34;Green\u0026#34; // 绿色 ) 这样做的好处是可以通过这个类型来更明显的标记出枚举字段来：\ntype Car struct { Name string Color Color // 颜色字段声明为Color类型，在阅读代码的时候就能知道这个字段正常的可选值范围 } 但是，上面的做法都需要面临一个问题，就是我需要一个返回全部枚举值的集合时，需要这样做：\nfunc All() []Color { return []Color{ Red, Blue, Green, } } func (color Color) Name() string { switch color { case Red: return \u0026#34;红色\u0026#34; case Blue: return \u0026#34;蓝色\u0026#34; case Green: return \u0026#34;绿色\u0026#34; } return \u0026#34;\u0026#34; } 当在定义处新增值时，All和Name也要同步添加，对于开发人员来说，非常容易遗漏。\n考虑到枚举值必然是不同的，那在Go里什么东西是必然不同的呢？首先想到的是结构体的字段。\ntype Color int var ColorEnumObj struct { Enum[int] // 初始化时将每个字段的内容收集起来存到这里 Blue EnumField[Color] `enum:\u0026#34;1,blue,蓝色\u0026#34;` Green EnumField[Color] `enum:\u0026#34;2,green,绿色\u0026#34;` Red EnumField[Color] `enum:\u0026#34;3,red,红色\u0026#34;` } 通过反射拿到enum标签里的内容，并相应的给字段赋值。\nfunc init() { panicIf(Init[int](\u0026amp;ColorEnumObj)) } 使用：\nvar ( _ = ColorEnumObj.Blue.Value() _ = ColorEnumObj.Green.Value() _ = ColorEnumObj.Red.Value() _ = ColorEnumObj.Blue.Name() _ = ColorEnumObj.Green.Name() _ = ColorEnumObj.Red.Name() _ = ColorEnumObj.Blue.ZhName() _ = ColorEnumObj.Green.ZhName() _ = ColorEnumObj.Red.ZhName() ) "},{"id":30,"href":"/posts/2022/04/go1.18_comparable/","title":"Go1.18 comparable","section":"04","content":" Go 1.18 预定义接口类型 # 先看一个提案: proposal: spec: permit values to have type \u0026ldquo;comparable\u0026rdquo; \u0026ndash; 允许值拥有comparable类型，我的理解是，现在的comparable只能用作泛型里的类型参数的约束，不能像普通类型那样使用，如下：\ntype Set[E comparable] []E // 可以用做类型参数的约束 // 使用go1.18编译，报错：interface is (or embeds) comparable var A comparable // 变量不可以使用`comparable`类型 那么，结合例子就能更好地理解这个提案了。\n这个提案的主要目的就是让例子里的var A comparable成立，也就是允许comparable作为变量的类型，跟其它普通的接口类型(var E error)一样。\n// proposal: spec: permit values to have type \u0026#34;comparable\u0026#34; // As part of adding generics, Go 1.18 introduces a new predeclared interface type comparable. That interface type is implemented by any non-interface type that is comparable, and by any interface type that is or embeds comparable. Comparable non-interface types are numeric, string, boolean, pointer, and channel types, structs all of whose field types are comparable, and arrays whose element types are comparable. Slice, map, and function types are not comparable. // -- 作为泛型的一部分，Go1.18引入了一个新的预定义接口类型：`comparable`。这个接口类型由任何可比较的非接口类型实现，和任何是`comparable`或内嵌了`comparable`的接口类型实现。可比较的非接口类型有：数值、字符串、布尔、指针、字段类型均是可比较的管道或结构体类型、元素是可比较的数组类型。切片、映射、函数类型均是不可比较的。 // In Go, interface types are comparable in the sense that they can be compared with the == and != operators. However, interface types do not in general implement the predeclared interface type comparable. An interface type only implements comparable if it is or embeds comparable. // 在Go里面，接口类型是可比较的意味着它们可以用`==`和`!=`操作符进行比较。但是，接口类型一般来说没有实现预定义接口类型`comparable`。一个接口类型只有它是或内嵌了`comparable`时才实现了`comparable`。 // Developing this distinction between the predeclared type comparable and the general language notion of comparable has been confusing; see #50646. The distinction makes it hard to write certain kinds of generic code; see #51257. // 出现的两个问题：[怎么在文档里说明哪些接口实现它了呢？](https://github.com/golang/go/issues/50646), [any是任意类型的意思，那必然比comparable大吧](https://github.com/golang/go/issues/51257) // 突然想到：如果我要把一个变量表示为不可比较的，怎么样可以用`comparable`来表示呢，`!comparable`? // For a specific example, you can today write a generic Set type of some specific (comparable) element type and write functions that work on sets of any element type: // // type Set[E comparable] map[E]bool // func Union[E comparable](s1, s2 Set[E]) Set[E] { ... } // // But there is no way today to instantiate this Set type to create a general set that works for any (comparable) value. That is, you can\u0026#39;t write Set[any], because any does not satisfy the constraint comparable. You can get a very similar effect by writing map[any]bool, but then all the functions like Union have to be written anew for this new version. // We can reduce this kind of problem by permitting comparable to be an ordinary type. It then becomes possible to write Set[comparable]. // As an ordinary type, comparable would be an interface type that is implemented by any comparable type. // 作为一个普通类型，`comparable`是一个可以被任意`comparable`类型实现的接口类型。 // Any comparable non-interface type could be assigned to a variable of type comparable. // -- 任何可比较的非接口类型可以被分配到类型为`comparable`的变量。 // A value of an interface type that is or embeds comparable could be assigned to a variable of type comparable. // -- 接口类型是或内嵌了`comparable`的值可以被分配到类型为`comparable`的变量。 // A type assertion to comparable, as in x.(comparable), would succeed if the dynamic type of x is a comparable type. // 类型断言，如`x.(comparable)`，当x的动态类型是一个`comparable`类型时可以成功。 // Similarly for a type switch case comparable. // 对`type switch`来说类似。 type C interface { comparable } var c C func main() { var A comparable var a int if v, ok := a.(comparable); ok { } switch a.(type) { case comparable: } } 反射的Comparable # func ReflectComparable(v interface{}) bool { typ := reflect.TypeOf(v) // Comparable reports whether values of this type are comparable. // Even if Comparable returns true, the comparison may still panic. // For example, values of interface type are comparable, // but the comparison will panic if their dynamic type is not comparable. // -- 即使返回true，也有可能panic。 // 比如：接口类型的值是可比较的，但如果它们的动态类型是不可比较的，就会panic return typ.Comparable() } go/types的Comparable # func TypesComparable() bool { t := types.NewChan(types.SendOnly, \u0026amp;types.Basic{}) return types.Comparable(t) } 更新 # 使comparable仅在类型集里没有任何一个不可比较类型时正确，否则依然在编译时可通过，但运行时panic\nfunc Comparable[T comparable](t1, t2 T) bool { return t1 == t2 } type IC interface { Name() string } type ComparableStruct struct { name string } func (cs ComparableStruct) Name() string { return cs.name } type NotComparableStruct struct { name string m map[int]string } func (ncs NotComparableStruct) Name() string { return ncs.name } func main() { var a IC = ComparableStruct{name: \u0026#34;jd\u0026#34;} var b IC = NotComparableStruct{name: \u0026#34;jd\u0026#34;, m: make(map[int]string)} _, _ = a, b // 现在提案没实现，所以普通接口并未实现comparable，会编译报错: IC does not implement comparable // 如果提案通过，将会是编译通过，执行panic // Comparable(a, b) } 更新（2022-11-18） # 临近1.20发布之时，新的提案来了\n情况 # 这个提案会兼容泛型加入前已有的规则。也就是能用==，但是有可能在运行时panic。\ntype M struct{ f any } // 注意看，f字段的类型为any fmt.Println(M{f: 1} == M{f: 2}) // 可编译通过，运行时正常执行：false fmt.Println(M{f: []int{1}} == M{f: []int{2}}) // 可编译通过，运行时panic：panic: runtime error: comparing uncomparable type []int 跑来看看\nIf we want any to satisfy comparable, then constraint satisfaction can\u0026rsquo;t be the same as interface implementation. A non-comparable type T (say []int) implements any, but T does not implement comparable (T is not in comparable\u0026rsquo;s type set). Therefore any cannot possibly implement comparable (the implements relation is transitive - we cannot change that). So if we want any to satisfy the comparable constraint, then constraint satisfaction can\u0026rsquo;t be the same as interface implementation.\n\u0026ndash; 如果想要any满足comparable，约束满足就不能跟接口实现一样。 \u0026ndash; 这里用[]int类型举例，它是不可比较的（其实它可以与nil比较，不过也仅能与nil比较），它实现了any，但它没有实现comparable。所以按照这样下去，any是不能实现comparable的。 \u0026ndash; 那么，如果我们想要any满足comparable约束，约束满足就不能跟接口实现一样。\n提议 # We change the spec to use a different rule for constraint satisfaction than for interface implementation: we want spec-comparable types to satisfy comparable; i.e., we want to be able to use any type for which == is defined even if it may not be strictly comparable.\n\u0026ndash; 修改spec规范，对于约束满足使用跟接口实现不同的规则。约定spec-comparable类型满足comparable。\nWith this change, constraint satisfaction matches interface implementation but also contains an exception for spec-comparable types. This exception permits the use of interfaces as type arguments which require strict comparability.\n\u0026ndash; 这样修改之后，约束满足除了会有一个关于spec-comparable类型的异常外，基本上匹配接口实现。这个异常允许使用接口作为泛型的类型参数，这个类型参数要求strict-comparability(严格的可比较)。\n关于spec-comparable和strict-comparable:\nFor clarity, in the following we use the term strictly comparable for the types in comparable, and spec-comparable for types of comparable operands. Strictly comparable types are spec-comparable, but not the other way around. Types that are not spec-comparable are simply not comparable.\n\u0026ndash; 在comparable里的类型即是strictly comparable的，支持比较符（==，!=）的类型是spec-comparable。 很明显，Strictly comparable类型一定是spec-comparable，但反过来就不一定。不是spec-comparable的类型就一定不是comparable(不能满足comparable约束)。\n关于satisfy:\nWe also add a new paragraph defining what \u0026ldquo;satisfy\u0026rdquo; means:\nA type T satisfies a constraint interface C if\nT implements C; or C can be written in the form interface{ comparable; E }, where E is a basic interface and T is comparable and implements E.\n\u0026ndash; 如果说类型T满足约束C： \u0026ndash; T实现了C；或者 \u0026ndash; C可以被写为以下格式：interface{ comparable: E}，其中E是一个基础接口(只有方法，没有type set)并且T满足comparable约束并实现了E。\n编译时静态检查 # 那如何在编译时确保某类型是可比较的呢？\n如果要在编译时确保某个类型是可比较的，可以 这样：\n// we want to ensure that T is strictly comparable type T struct { x int } // define a helper function with a type parameter P constrained by T // and use that type parameter with isComparable // -- 把该类型T作为约束使用，并且对应的类型参数用于实例化一个使用了comparable约束的泛型函数 func TisComparable[P T]() { _ = isComparable[P] } func isComparable[_ comparable]() {} "},{"id":31,"href":"/posts/2022/03/kmp/","title":"KMP","section":"03","content":"KMP字符串匹配算法\n精确匹配\n状态机\n给定一个pattern，查找其在另一字符串s出现的最早位置。（找不到则返回-1）\nfunc index(s string, pattern string) int { return -1 } 状态推移\nfunc index(s string, pattern string) int { n := len(s) m := len(pattern) // 根据pattern构造dp var dp [n][m]int // 在s上应用dp，判断pattern位置 return -1 } "},{"id":32,"href":"/posts/2022/02/%E9%9C%9C%E4%B9%8B%E5%93%80%E4%BC%A4/","title":"霜之哀伤","section":"02","content":"当有人说要在屋里开个窗，一定惹得大伙不开心，无人同意；若要在屋里凿个洞，就有人来协调，愿意开窗了。\n看到了吗？这里面有提议的人，有反对的人，有开始反对后面协调的人。看似只有这几种人，实则还有一种人，哪边人多站哪边。恶则落井下石，善则“好言相劝”。\n一盆散沙，就算反对，也难以“碍事”。聪明人早就明白这个道理。只要能裹挟着一群人，与自己利益捆绑，那么就能为己所用。至于“所用”是何物，自然无关紧要，只要“为己”即可。\n同样地，要击溃捆绑，自然需要强大的力量，也就是另一群人。\n"},{"id":33,"href":"/posts/2022/02/goroutine_vs_tokio/","title":"goroutine vs tokio","section":"02","content":" Reddit讨论贴\nGo uses a different strategy for blocking systemcalls. It does not run them on a threadpool - it moves all the other goroutines that are queued to run on the current thread to a new worker thread, then runs the blocking systemcall on the current thread. This minimizes context switching.\nYou can do this in tokio as well, using task::block_in_place. If I change your code to use that instead of tokio::fs, it gets a lot closer to the go numbers. Note that using block_in_place is not without caveats, and it only works on the multi-threaded runtime, not the single-threaded one. That\u0026rsquo;s why it\u0026rsquo;s not used in the implementation of tokio::fs.\nOn my Linux desktop:\ngoroutines: 3.22234675s total, 3.222346ms avg per iteration\nrust_threads: 16.980509645s total, 16.980509ms avg per iteration\nrust_tokio: 9.56997204s total, 9.569972ms avg per iteration\nrust_tokio_block_in_place: 3.578928749s total, 3.578928ms avg per iteration\n对比文章\nGoroutines are more lightweight and efficient than operating-system threads. As a result, a program can spawn more total goroutines than threads. Goroutines also start and clean themselves up faster than threads due to less system overhead.\nThe big advantage of traditional threading (like that of Rust) over the goroutine model is that no runtime is required. Each Go executable is compiled with a small runtime which manages goroutines, while Rust avoids that extra fluff in the binary.\n附：实例对比\nio比较\n让tokio调度更快\nThe run queue must support both multiple producers and multiple consumers. The commonly used algorithm is an intrusive linked list(侵入性的链表). Intrusive implies that the task structure includes a pointer to the next task in the run queue instead of wrapping the task with a linked list node. This way, allocations are avoided for push and pop operations. It is possible to use a lock-free push operation but popping requires^1 a mutex to coordinate consumers.\nThis scheduler model has a downside. All processors contend on the head of the queue(contend: 竞争). For general-purpose thread pools, this usually is not a deal breaker. The amount of time processors spend executing the task far outweighs the amount of time spent popping the task from the run queue. When tasks execute for a long period of time, queue contention is reduced. However, Rust\u0026rsquo;s asynchronous tasks are expected to take very little time executing when popped from the run queue. In this scenario, the overhead from contending on the queue becomes significant.\nrust async await\n在函数调用时插入调度点，rust通过yield来插入，实现一个函数多次返回。\n"},{"id":34,"href":"/posts/2022/02/go_runtime_chan/","title":"go runtime chan","section":"02","content":"src/runtime/chan.go:\n// Invariants: // At least one of c.sendq and c.recvq is empty, // except for the case of an unbuffered channel with a single goroutine // blocked on it for both sending and receiving using a select statement, // in which case the length of c.sendq and c.recvq is limited only by the // size of the select statement. // // For buffered channels, also: // c.qcount \u0026gt; 0 implies that c.recvq is empty. // c.qcount \u0026lt; c.dataqsiz implies that c.sendq is empty. // 在文件开头，说明了几个不变量： // c.sendq和c.recvq中至少有一个是空的， // 除非，一个无缓冲管道在一个goroutine里阻塞了，这个管道的发送和接收都使用了一个select语句，这时 // c.sendq和c.recvq的长度被select语句限制。 // // 对于缓冲管道，同样地： // c.qcount \u0026gt; 0 表明c.recvq是空的。 // c.qcount \u0026lt; c.dataqsiz 表明c.sendq是空的。 // 实际的chan类型 type hchan struct { qcount uint // total data in the queue - 队列里的数据总数量 dataqsiz uint // size of the circular queue - 循环队列的大小，make时传进来的值 buf unsafe.Pointer // points to an array of dataqsiz elements - dataqsiz元素组成的数组的指针 elemsize uint16 // 元素大小 closed uint32 // 是否关闭 elemtype *_type // element type - 元素类型 sendx uint // send index - 发送索引 recvx uint // receive index - 接收索引 recvq waitq // list of recv waiters - 等待接收者列表，表明这个管道的接收者；一个链表，里面的每个元素代表一个g； sendq waitq // list of send waiters - 等待发送者列表，编码这个管道的发送者 // lock protects all fields in hchan, as well as several // fields in sudogs blocked on this channel. // // Do not change another G\u0026#39;s status while holding this lock // (in particular, do not ready a G), as this can deadlock // with stack shrinking. lock mutex // 保护chan里的所有字段，以及阻塞在本管道里的sudog；当持有这个锁时，不要改变其它G的状态，因为在栈收缩时可能引起死锁。 } type waitq struct { first *sudog last *sudog } // sudog represents a g in a wait list, such as for sending/receiving // on a channel. - 代表了一个在等待列表的g // // sudog is necessary because the g ↔ synchronization object relation // is many-to-many. A g can be on many wait lists, so there may be // many sudogs for one g; and many gs may be waiting on the same // synchronization object, so there may be many sudogs for one object. // - sudog是必须的，因为g和同步对象关系是多对多。一个g可以在多个等待列表里，因此一个g对应有多个sudog； // 多个g可以等待同一个同步对象，因此一个对象会对应多个sudog。 // // sudogs are allocated from a special pool. Use acquireSudog and // releaseSudog to allocate and free them. // - sudog从一个特殊池子里分配，使用acquireSudog分配和releaseSudog释放它们。 type sudog struct { // The following fields are protected by the hchan.lock of the // channel this sudog is blocking on. shrinkstack depends on // this for sudogs involved in channel ops. // - 以下字段由hchan.lock来保护。 g *g // 代表的g next *sudog // 链表中的下一个 prev *sudog // 链表中的上一个 elem unsafe.Pointer // data element (may point to stack) - 数据元素，可能是指向栈的指针 // The following fields are never accessed concurrently. // For channels, waitlink is only accessed by g. // For semaphores, all fields (including the ones above) // are only accessed when holding a semaRoot lock. // - 以下字段永远不会被并发访问。 // 对于管道，waitlink只会被g访问。 // 对于信号量，所有字段（包括上面的）只有在持有semaRoot锁时才能被访问 acquiretime int64 // 获取时间 releasetime int64 // 释放时间 ticket uint32 // 票据 // isSelect indicates g is participating in a select, so // g.selectDone must be CAS\u0026#39;d to win the wake-up race. isSelect bool // 表明g是否参与到了一个select里，从而使得g.selectDone必须CAS地去赢得唤醒竞赛 // success indicates whether communication over channel c // succeeded. It is true if the goroutine was awoken because a // value was delivered over channel c, and false if awoken // because c was closed. success bool // 表明管道的通信是否成功了，如果goroutine因为一个值被管道传送到来而唤醒即为成功 parent *sudog // semaRoot binary tree - 根信号量二叉树 waitlink *sudog // g.waiting list or semaRoot - g的等待列表或semaRoot waittail *sudog // semaRoot c *hchan // channel - 所属管道 } // 新建 func makechan(t *chantype, size int) *hchan { elem := t.elem // compiler checks this but be safe. if elem.size \u0026gt;= 1\u0026lt;\u0026lt;16 { // 管道的元素大小不能太大 throw(\u0026#34;makechan: invalid channel element type\u0026#34;) } // const hchanSize uintptr = 96 if hchanSize%maxAlign != 0 || elem.align \u0026gt; maxAlign { // 对齐检查 throw(\u0026#34;makechan: bad alignment\u0026#34;) } // 元素大小乘以管道大小，计算出来所需内存大小 mem, overflow := math.MulUintptr(elem.size, uintptr(size)) if overflow || mem \u0026gt; maxAlloc-hchanSize || size \u0026lt; 0 { panic(plainError(\u0026#34;makechan: size out of range\u0026#34;)) } // Hchan does not contain pointers interesting for GC when elements stored in buf do not contain pointers. // buf points into the same allocation, elemtype is persistent. // SudoG\u0026#39;s are referenced from their owning thread so they can\u0026#39;t be collected. // TODO(dvyukov,rlh): Rethink when collector can move allocated objects. var c *hchan switch { case mem == 0: // Queue or element size is zero. c = (*hchan)(mallocgc(hchanSize, nil, true)) // Race detector uses this location for synchronization. c.buf = c.raceaddr() case elem.ptrdata == 0: // Elements do not contain pointers. -- 元素没有包含指针 // Allocate hchan and buf in one call. c = (*hchan)(mallocgc(hchanSize+mem, nil, true)) c.buf = add(unsafe.Pointer(c), hchanSize) default: // Elements contain pointers. -- 元素包含指针 c = new(hchan) c.buf = mallocgc(mem, elem, true) } c.elemsize = uint16(elem.size) c.elemtype = elem c.dataqsiz = uint(size) lockInit(\u0026amp;c.lock, lockRankHchan) // 初始化锁 if debugChan { print(\u0026#34;makechan: chan=\u0026#34;, c, \u0026#34;; elemsize=\u0026#34;, elem.size, \u0026#34;; dataqsiz=\u0026#34;, size, \u0026#34;\\n\u0026#34;) } return c } // 发送 func sendDirect(t *_type, sg *sudog, src unsafe.Pointer) { // src is on our stack, dst is a slot on another stack. // - src是在我们的栈上，dst是另一个栈上的槽 // Once we read sg.elem out of sg, it will no longer // be updated if the destination\u0026#39;s stack gets copied (shrunk). // So make sure that no preemption points can happen between read \u0026amp; use. dst := sg.elem typeBitsBulkBarrier(t, uintptr(dst), uintptr(src), t.size) // No need for cgo write barrier checks because dst is always // Go memory. memmove(dst, src, t.size) // 移动src到dst } // 接收 -- 请看源码 // 关闭 func closechan(c *hchan) { if c == nil { panic(plainError(\u0026#34;close of nil channel\u0026#34;)) } lock(\u0026amp;c.lock) if c.closed != 0 { // 已关闭的chan，如果再次关闭会panic unlock(\u0026amp;c.lock) panic(plainError(\u0026#34;close of closed channel\u0026#34;)) } if raceenabled { callerpc := getcallerpc() racewritepc(c.raceaddr(), callerpc, abi.FuncPCABIInternal(closechan)) racerelease(c.raceaddr()) } c.closed = 1 // 设为关闭 var glist gList // 先释放接收者，再释放发送者 // release all readers for { sg := c.recvq.dequeue() // 逐个出队sudog if sg == nil { break } if sg.elem != nil { typedmemclr(c.elemtype, sg.elem) // 清理元素 sg.elem = nil } if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) // 把关联的g存到glist里 } // release all writers (they will panic) for { sg := c.sendq.dequeue() if sg == nil { break } sg.elem = nil if sg.releasetime != 0 { sg.releasetime = cputicks() } gp := sg.g gp.param = unsafe.Pointer(sg) sg.success = false if raceenabled { raceacquireg(gp, c.raceaddr()) } glist.push(gp) } unlock(\u0026amp;c.lock) // Ready all Gs now that we\u0026#39;ve dropped the channel lock. for !glist.empty() { gp := glist.pop() // 逐个处理g gp.schedlink = 0 goready(gp, 3) // 因为我们已经释放了这些g所关联的chan，所以让这些g进入ready状态，准备运行 -- Mark gp ready to run. } } src/runtime/type.go:\n// Needs to be in sync with ../cmd/link/internal/ld/decodesym.go:/^func.commonsize, // ../cmd/compile/internal/reflectdata/reflect.go:/^func.dcommontype and // ../reflect/type.go:/^type.rtype. // ../internal/reflectlite/type.go:/^type.rtype. // // 这个类型必须与链接器、编译器、反射等地方的类型保持同步 type _type struct { size uintptr // 大小 ptrdata uintptr // size of memory prefix holding all pointers - 持有所有指针的内存前缀大小 hash uint32 // 哈希值 tflag tflag // 类型标记 align uint8 // 对齐 fieldAlign uint8 // 字段对齐 kind uint8 // 种类 // function for comparing objects of this type // (ptr to object A, ptr to object B) -\u0026gt; ==? equal func(unsafe.Pointer, unsafe.Pointer) bool // 比较本类型的两个对象的指针的方法 // gcdata stores the GC type data for the garbage collector. // If the KindGCProg bit is set in kind, gcdata is a GC program. // Otherwise it is a ptrmask bitmap. See mbitmap.go for details. gcdata *byte // 存储了垃圾收集器所需的GC类型数据 str nameOff // 名称偏移 ptrToThis typeOff // 类型偏移 } "},{"id":35,"href":"/posts/2022/02/go_work/","title":"go work","section":"02","content":"go1.18将要推出workspace模式，此举是为了方便在本地开发多个不同module时的依赖管理。\n命令说明：\n$ go help work Go workspace provides access to operations on workspaces. Note that support for workspaces is built into many other commands, not just \u0026#39;go work\u0026#39;. See \u0026#39;go help modules\u0026#39; for information about Go\\\u0026#39;s module system of which workspaces are a part. A workspace is specified by a go.work file that specifies a set of module directories with the \u0026#34;use\u0026#34; directive. These modules are used as root modules by the go command for builds and related operations. A workspace that does not specify modules to be used cannot be used to do builds from local modules. go.work files are line-oriented. Each line holds a single directive, made up of a keyword followed by arguments. For example: go 1.18 use ../foo/bar use ./baz replace example.com/foo v1.2.3 =\u0026gt; example.com/bar v1.4.5 The leading keyword can be factored out of adjacent lines to create a block, like in Go imports. use ( ../foo/bar ./baz ) The use directive specifies a module to be included in the workspace\\\u0026#39;s set of main modules. The argument to the use directive is the directory containing the module\\\u0026#39;s go.mod file. The go directive specifies the version of Go the file was written at. It is possible there may be future changes in the semantics of workspaces that could be controlled by this version, but for now the version specified has no effect. The replace directive has the same syntax as the replace directive in a go.mod file and takes precedence over replaces in go.mod files. It is primarily intended to override conflicting replaces in different workspace modules. To determine whether the go command is operating in workspace mode, use the \u0026#34;go env GOWORK\u0026#34; command. This will specify the workspace file being used. Usage: go work \u0026lt;command\u0026gt; [arguments] The commands are: edit edit go.work from tools or scripts init initialize workspace file sync sync workspace build list to modules use add modules to workspace file Use \u0026#34;go help work \u0026lt;command\u0026gt;\u0026#34; for more information about a command. 使用use指令指定包含在workspace里的module集。use指令后紧接着的是包含了模块的go.mod文件的目录\u0026ndash;相对go.work的目录。\nuse指定的模块被go命令用作根模块，执行构建等操作。\nreplace指令与go.mod里的用法一样。它会覆盖在workspace里不同的模块之间的冲突replace。\n比如，分别有模块bar, baz:\n它们的go.mod分别是：\ngo 1.18 replace foo v0.0.1 =\u0026gt; ./foo go 1.18 replace foo v0.0.1 =\u0026gt; foo v0.0.2 可以看到，它们replace了不同的foo。\ngo 1.18 use ( ./bar ./baz ) replace foo v0.0.1 =\u0026gt; ../foo 在go.work里统一了对于foo的replace，均指向到了../foo。\n不过，虽然多了这个workspace模式，依然无法解决module版本依赖问题\u0026ndash;模块路径和模块版本问题。\n"},{"id":36,"href":"/posts/2022/02/distractions/","title":"杂念","section":"02","content":" 情绪绑定 # 先把一样好（好看、好听、好闻）的东西抛出来，收集大众的积极情绪，进而把大家的情绪控制。\n当这样东西喜，你就跟着喜；当这样东西悲，你就跟着悲；当这样东西静，你就跟着静。当这样东西动，你却看不到了。\n信仰缺失的年代，把自己交付给这样的东西，只为换到一丝“慰挤”。\n精神上的追求太难找到共鸣了，不如转而追求物质上的欢喜。每天吃吃喝喝，打打闹闹，不以物喜，不以己悲，不是挺好。\n歌好听，那就听，何必在意歌手爱天怼地。如果真的这么较真，最好听歌前做好背景调查，如果不慎那歌手竟信息不详，那只好叫耳朵过滤掉了。若实在忍不住，也不妨在确实之前先恩施一番，以传我宽大之名。当然，如有丝言片语，只要未到石锤之境，自然轻松忽略。毕竟，真假难辨，不如不辩。\n万一真的发现了黑历史，这时就要斟酌一番了，继续爱如谦，抑或恨如龙，搞不好就被别人发现你居然喜欢“黑”歌手，承担巨大的社会压力，就得不偿失了。\n但是，害怕很难成事，只会坏事。如果只因为怕，那如何能算英雄，或者竟连个孤勇者都算不上，实在于心难安。那何不拉拢一批共同情绪的人，把那位别人先打黑。\n嘿，只需证明别人是错的，何苦花费心思证明自己是对呢！\n嗯，情绪输出总算有着落了，难受的只要是别人，自己就永远开心了，谁管别人是亲是疏，是喜是恶呢。只要不管不顾，虎牛之力也拿我没辙。对别人施暴，哪怕隔着个屏幕，也能爽到嗨。\n别人这时就难受了：我好心劝你们远离毒瘤，居然不识抬举，还要拉帮结派来搞我。真的是越想越气，越气越想。奈何对方人多势众，单拳难敌四手。\n自诩孤高者，自然不屑于群斗，但被逼到墙角了，也不得不群起。但标准越高，规模自然越小，苦费心思，依然难以匹敌，最后只好在猪圈方圈里丢三骂四了。\n聪明人居然不懂不聪明人的想法，为什么敢自认聪明呢？\n懂的话，大抵不会自称聪明人，而要转称愚人了吧。不聪明人也不真的不聪明，只是知道往身上贴上聪明人标签，更多时候只捞得个劳苦功低、得不偿失，活得还不如马屁精。\n说到马屁精，我就猜到马屁是香的，或至少在喜爱之人闻来别有一番风味。\n马屁精自然是冤枉的，不过说了几句某人爱听的话，或者不小心成了习惯\u0026ndash;见某人说某话，别人就来指责他，并打上马屁精标签，在圈里不断丢三骂四。只是不对你这样说话，你就这么生气，别人真的是坏。\n谁怪你不是某人呢？你若竟是某人，想听几句某话，那还不难。只怕你成了某人，你还嫌少呢！\n马屁精也不全是敌人，是非精、八卦精等“朋友”是大大的有。而且，精的本事也不能小，至少要在亦敌亦友的关系转变中拿捏得准确无误。不然闹出“人门前弄是非，精面前摆事实”的笑话来，就颜面无存了。\n精，未成人之前，或竟不做人，选择做精，自然是如老鼠过街，人人喊打。\n既然是精，那就必须没有情绪，笑脸迎臭脸自然是家常便饭。但只要熬出头，拥有一星半点某人之像，好生活自然而至，竟也开始享受到了某话。\n路漫漫兮，修就是了。怎么修的，你就别管了。好好的丢三骂四还不够，还敢来管修的事，怕不是吃饱了思起淫欲来。\n精在那里，你不骂，你敢往这边看，你怕不是想吃大过年不想吃的饭了。就不怕，我饭都不给你吃，把你饿成精。\n原来精是饿出来的！\n"},{"id":37,"href":"/posts/2022/01/rust_safe/","title":"Rust与安全","section":"01","content":"有一些东西，做了一些事情。\n有什么东西，做了什么呢？\n有文件、结构体、特征、类型，调用了函数、方法，读了文件/读了body，算了结果，写了文件/答了请求。\nIO or 计算。\n或者说，更强调IO，还是计算。\n内存安全 # 并发安全 # "},{"id":38,"href":"/posts/2022/01/wasmtime/","title":"wasm运行时wasmtime","section":"01","content":" 源码 # # 下载 git clone git@github.com:bytecodealliance/wasmtime.git # 子模块 git submodule update --init --recursive # 安装 cargo build 如果忘了拉子模块，vscode的rust-analyzer会报错，导致智能提示等功能失效。\n不过整个初始化过程还是有点长，等了好久才能正常使用。\n阅读 # 从build.rs开始，首先映入眼帘的是use anyhow::Context;：\n/// Provides the `context` method for `Result`. /// /// This trait is sealed and cannot be implemented for types outside of /// `anyhow`. 这是一个为其它类型（anyhow::Result）引入context方法的特征啊，多么伟大，在anyhow包外面的类型就不要想着去实现它了，你们高攀不起的。\n再看anyhow::Context的定义：\n// lib.rs:598 pub trait Context\u0026lt;T, E\u0026gt;: context::private::Sealed { // 继承了Sealed，那它又是怎么样的、做什么的呢？ /// Wrap the error value with additional context. -- 给error值包装上下文信息 fn context\u0026lt;C\u0026gt;(self, context: C) -\u0026gt; Result\u0026lt;T, Error\u0026gt; where C: Display + Send + Sync + \u0026#39;static; // 能展示，并发安全，全局可见的类型值 /// Wrap the error value with additional context that is evaluated lazily /// only once an error does occur. -- 通过传入一个FnOnce的函数来延迟获取上下文信息 fn with_context\u0026lt;C, F\u0026gt;(self, f: F) -\u0026gt; Result\u0026lt;T, Error\u0026gt; where C: Display + Send + Sync + \u0026#39;static, F: FnOnce() -\u0026gt; C; } // context.rs:170 pub(crate) mod private { // pub(crate)表明这个mod只能在本crate里被使用 use super::*; // 使用父mod的东西 pub trait Sealed {} // 特征里没有方法 impl\u0026lt;T, E\u0026gt; Sealed for Result\u0026lt;T, E\u0026gt; where E: ext::StdError {} // 为Result实现Sealed impl\u0026lt;T\u0026gt; Sealed for Option\u0026lt;T\u0026gt; {} // 为Option实现Sealed } 主要逻辑 # 做了哪些事情呢？\n"},{"id":39,"href":"/posts/2022/01/container_encrypt/","title":"容器镜像加密","section":"01","content":"如果我在创建镜像时把源码也打包了进去，要怎么防止别人通过这个镜像把源码给窃取了呢？\n加密\n镜像加密\n源码加密：在COPY源码进去之前先加密；这种适合服务器不是自己的，并且在局域网里的（接过医院系统的应该都懂吧）；留这样一份加密源码也只是在方便有bug时可以快速修复的同时，还可以稍微保护一下源码；\n先使用zip压缩源码：`zip -q -r code.zip ./code`； 再使用gpg加密：`gpg --yes --batch --passphrase=123 -c ebpf.zip`； -- 通过`--yes --batch --passphrase`三个选项避免键盘交互，最后生成`ebpf.zip.gpg`。 后续进入容器后，使用gpg解密：`gpg -o ebpf2.zip -d ebpf.zip.gpg`； 再使用unzip解压：`unzip -d ebpf2 ebpf2.zip`。 在镜像构建后，还要防止docker history -H cb0b42c0cb03 --no-trunc=true查看镜像构建历史时，泄露秘钥等信息。\u0026ndash; 可使用多阶段构建：在前一阶段使用密钥加密源码，后一阶段复制加密源码，从而避免密钥泄露。因为一般只需要把后一阶段构建出来的镜像分发出去就好了，而查看后一阶段构建出来的镜像的构建历史，是看不到密钥信息的（查看前一阶段的构建历史才会看到）。\ndockerfile COPY before mkdir will get a no such file or directory error # error:\n```dockerfile # \u0026hellip;\nRUN mkdir -p /abc\nCOPY \u0026ndash;from=builder /opt/efg /abc/efg ```\n没有指定创建/abc/efg目录，会导致后续想读取该目录内容时报错：no such file or directory\nsuccess:\n```dockerfile # \u0026hellip;\nRUN mkdir -p /abc RUN mkdir -p /abc/efg\nCOPY \u0026ndash;from=builder /opt/efg /abc/efg ```\n必须指定创建/abc/efg目录，并且要以可能出现的最长路径来创建。\nfile exist in container but can\u0026rsquo;t read by go\n终于知道了，搞了一天的镜像，原来问题出在了docker-compose配置里挂载了那个路径，把COPY进去的文件覆盖了，所以一直找不到文件--配置的本地目录里没有东西~~\n走捷径，取巧 # 而忘了正路\n"},{"id":40,"href":"/posts/2022/01/smart_contract/","title":"智能合约","section":"01","content":" 智能合约 # 智能合约wiki\n（英语：Smart contract）是一种特殊协议，在区块链内制定合约时使用，当中内含了代码函数 (Function)，亦能与其他合约进行交互、做决策、存储资料及发送以太币等功能。智能合约主要提供验证及执行合约内所订立的条件。智能合约允许在没有第三方的情况下进行可信交易。这些交易可追踪且不可逆转。\n安全问题 # 智能合约是“执行合约条款的计算机交易协议”。区块链上的所有用户都可以看到基于区块链的智能合约。但是，这会导致包括安全漏洞在内的所有漏洞都可见，并且可能无法迅速修复。\n这样的攻击难以迅速解决，例如：\n2016年6月The DAOEther的漏洞造成损失5000万美元，而开发者试图达成共识的解决方案。DAO的程序在黑客删除资金之前有一段时间的延迟。以太坊软件的一个硬分叉在时限到期之前完成了攻击者的资金回收工作。\n以太坊智能合约中的问题包括合约编程Solidity、编译器错误、以太坊虚拟机错误、对区块链网络的攻击、程序错误的不变性以及其他尚无文档记录的攻击。\n2018年4月22日， BeautyChain智能合约出现重大漏洞，黑客通过此漏洞无限生成代币，导致 BitEclipse (BEC)的价值接近归零。同月25日，SmartMesh出现疑似重大安全漏洞，宣布暂停所有SMT交易和转账直至另行通知，导致损失约1.4亿美金。28日，EOS被指可能存在BEC代币合约类似的整数溢出漏洞，但没消息详细说明。5月24日， BAI交易存在大量异常问题， 损失金额未知。8月22日， GODGAME 合约被黑客入侵，GOD智能合约上的以太坊总数归零。\n合约开发、测试和部署 # eth智能合约文档\nvending machine(自动售货机): money + snack selection = snack dispensed, 给钱并选择小吃，小吃就会出来 \u0026ndash; 是给刚好的钱，还是过量的钱，过量了在发放小吃的同时退钱呢？\n合约长这样：\n// 表明使用的sol版本 pragma solidity 0.8.7; // Solidity 合约类似于面向对象语言中的类。合约中有用于数据持久化的状态变量，和可以修改状态变量的函数。 调用另一个合约实例的函数时，会执行一个 EVM 函数调用，这个操作会切换执行时的上下文，这样，前一个合约的状态变量就不能访问了。 contract VendingMachine { // Declare state variables of the contract address public owner; // owner变量 mapping (address =\u0026gt; uint) public cupcakeBalances; // cupcakeBalances变量 // 创建合约时，合约的构造函数会执行一次。构造函数是可选的。只允许有一个构造函数，这意味着不支持重载。 // When \u0026#39;VendingMachine\u0026#39; contract is deployed: // 1. set the deploying address as the owner of the contract // 2. set the deployed smart contract\u0026#39;s cupcake balance to 100 constructor() { owner = msg.sender; // 设置部署本合约的地址为合约所有者 // address(this)是将this转型为地址吗？ // this不是代表合约对象吗，还能转为address？ cupcakeBalances[address(this)] = 100; // 设置蛋糕余量 } // Allow the owner to increase the smart contract\u0026#39;s cupcake balance function refill(uint amount) public { // public表示方法可导出 require(msg.sender == owner, \u0026#34;Only the owner can refill.\u0026#34;); // 如果前面的条件不成立，则报错，后面为内容；此处要求消息的发送者必须是本合约所有者 cupcakeBalances[address(this)] += amount; // 补充蛋糕 } // Allow anyone to purchase cupcakes function purchase(uint amount) public payable { // payable表示方法含有支付逻辑 require(msg.value \u0026gt;= amount * 1 ether, \u0026#34;You must pay at least 1 ETH per cupcake\u0026#34;); // 此处要求每个蛋糕最少支付一个eth require(cupcakeBalances[address(this)] \u0026gt;= amount, \u0026#34;Not enough cupcakes in stock to complete this purchase\u0026#34;); // 此处要求蛋糕余量不小于需要的数量 cupcakeBalances[address(this)] -= amount; // 本合约所有者减少蛋糕 cupcakeBalances[msg.sender] += amount; // 消息发送者添加蛋糕 } } address(this)\nthis refers to the instance of the contract where the call is made (you can have multiple instances of the same contract). \u0026ndash; 调用发生时合约的实例\naddress(this) refers to the address of the instance of the contract where the call is being made. \u0026ndash; 调用发生的地方的合约的实例的地址\nmsg.sender refers to the address where the contract is being called from.\nTherefore, address(this) and msg.sender are two unique addresses, the first referring to the address of the contract instance and the second referring to the address where the contract call originated from.\nthis: 实例;\naddress(this): 实例的地址;\nmsg.sender: 消息发送者，最初的合约调用者。\n看上面的合约，msg是哪里来的，它里面有些什么东西呢？消息发送者买了蛋糕之后，还能再卖出去吗？\nmsg是一个 全局变量\nFor instance, msg.sender is always the address where the current (external) function call came from.\nFor instance, if a function call came from a user or smart contract with the address 0xdfad6918408496be36eaf400ed886d93d8a6c180 then msg.sender equals 0xdfad6918408496be36eaf400ed886d93d8a6c180.\nmsg.data — The complete calldata which is a non-modifiable, non-persistent area where function arguments are stored and behave mostly like memory\nmsg.gas — Returns the available gas remaining for a current transaction (you can learn more about gas in Ethereum here). The function gasleft was previously known as msg.gas, which was deprecated in version 0.4.21 and removed in version 0.5.0.\nmsg.sig — The first four bytes of the calldata for a function that specifies the function to be called (i.e., it’s function identifier), 函数标识\nmsg.value — The amount of wei sent with a message to a contract (wei is a denomination of ETH), 1 ETH = 10^18 wei\n更多全局变量和函数\nThe special variables and functions are always available globally and are mainly used to provide information about the blockchain (i.e., transactions, contract info, address info, error handling, math and crypto functions).\nBlock and Transaction Properties\nABI Encoding and Decoding Functions\nMembers of bytes\nError Handling\nMathematical and Cryptographic Functions\nMembers of Address Types\nContract Related\nType Information\n一些工具库\ntruffle - A tool for developing smart contracts. Crafted with the finest cacaos.\nWaffle - A framework for advanced smart contract development and testing (based on ethers.js).\nSolidity-Coverage - Alternative solidity code coverage tool.\nhevm - Implementation of the EVM made specifically for unit testing and debugging smart contracts.\nWhiteblock Genesis - An end-to-end development sandbox and testing platform for blockchain.\nOpenZeppelin Test Environment(已归档) - Blazing fast smart contract testing. One-line setup for an awesome testing experience.\nOpenZeppelin Test Helpers - Assertion library for Ethereum smart contract testing. Make sure your contracts behave as expected!\n实战 # 安装 ETH钱包MetaMask(firefox插件)\n新建账户，会提示输入密码，然后生成成功后，会有一堆助记词，需要记录好：\njeans term salt true cereal hobby cheese awesome link nice never choose 钱包默认连接的是主网，因为主网要花钱买币，所以我们选择测试网。在主网那里点击设置打开Show test networks配置。\n获得地址：0x758c40f09207f9e6F72A8C24029Be865D28eF219\neth rinkeby测试网水龙头\n为上述地址去水龙头领取币。\n需要先把上述地址发到推特、脸书、谷家任一地方，然后再使用对应帖子的地址(如：)来获取。\n如果报错nsufficient funds for gas * price + value，可尝试使用 另外的网站直接使用地址获取。\n拿到之后，在metamask查看余额。\neth rinkeby测试网浏览器\n在浏览器上可以查找到上述的 转账记录\n参照这个游戏示例\n编译、部署合约\nTODO:\nevm # 代码\nstack based\nregister based\nwasm # 切换到ewasm的背景和好处\nwasm工具集\nsolidity # contract\nNFT # NFT wiki\n非同质化代币（英语：Non-Fungible Token，简称：NFT），是一种被称为区块链数字账本上的数据单位，每个代币可以代表一个独特的数字资料，作为虚拟商品所有权的电子认证或证书。由于其不能互换，非同质化代币可以代表数字文件，如画作、声音、视频、游戏中的项目或其他形式的创意作品。虽然文件（作品）本身是可以无限复制的，但代表它们的代币在其底层区块链上被追踪，并为买家提供所有权证明。诸如以太币、比特币等加密货币都有自己的代币标准以定义对NFT的使用。\n非同质化代币一种存储在区块链（数位账本）上的数据单位，它可以代表艺术品等独一无二的数字物品。其是一种加密代币，但与比特币等加密货币不同，其不可互换。一个非同质化代币是透过上传一个文件，如艺术品，到非同质化代币拍卖市场。这将创建一个记录在数字账本上的文件副本作为非同质化代币，它可以用加密货币购买和转售。虽然艺术家可以出售代表作品的非同质化代币，但艺术家仍然可以保留作品的著作权，并创造更多的同一作品的非同质化代币。非同质化代币的买家并不能获得对作品的独家访问权，买家也不能获得对原始数字文件的独占。将某一作品作为非同质化代币上传的人不必证明他们是原创艺术家，在许多争议案例中，在未经创作者许可的情况下，艺术品被盗用于非同质化代币。\neth nft\n一种将任何独特物品表现为以太坊资产的方式。 NFT 为内容创建人赋予了比以往更多的权力。 由以太坊区块链上的智能合约提供支持。 NFT 是我们用以代表独特物品所有权的代币。 NFT 让我们把诸如艺术品、收藏品、甚至房地产等物品代币化。 他们一次只有一个正式主人，并且受到以太坊区块链的保护 - 没有人可以修改所有权记录或者根据现有的 NFT 复制粘贴一份新的。\nNFT 代表非同质化代币。非同质化是一个经济术语，您可以用它来描述家具、歌曲文件或您的电脑等物品。这些东西不能与其他物品互换，因为它们具有独特属性。\n另一方面，同质化物品可以互换，这取决于它们的价值而非独特属性。 例如，ETH 或美元具有同质化属性，因为 1 ETH/1 USD 可以兑换成另外的 1 ETH/1 USD。\n当他们(数字产品作者)出售内容时，资金直接转给他们。如果新所有者随后出售 NFT，原创建人(数字产品作者)甚至可以自动收到版税。这在每次出售时都有保证，因为创建人的地址是代币元数据的一部分 - 元数据无法修改。\n"},{"id":41,"href":"/posts/2022/01/learn_go_fast/","title":"Go快速入门","section":"01","content":" 源码 # // 所有代码都需要放到包里 package color // 导入其它包 import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;time\u0026#34; ) // 枚举 type Color int // 常量 const ( Red Color = 1 // 红 Blue Color = 2 // 蓝 Green Color = 3 // 绿 ) // 函数 func NewCar( name string, rate int, ) *Car { return \u0026amp;Car{ name: name, rate: rate, } } // 类型 type Car struct { // 类型字段 name string // 首字母小写，非导出，只能包内使用 rate int } // 类型方法 func (car *Car) String() string { // 首字母大写，导出，可供其它包使用 return \u0026#34;[Car] name: \u0026#34; + car.name + \u0026#34;, rate: \u0026#34; + strconv.Itoa(car.rate) + \u0026#34;.\u0026#34; } func (car *Car) Run( ctx context.Context, // 使用ctx实现超时控制 ) { // 定时器，每隔rate秒执行一次 ticker := time.NewTicker(time.Duration(car.rate) * time.Second) defer ticker.Stop() // defer语句，在方法退出前执行，做收尾工作 // for range ticker.C { // 循环，遍历chan // fmt.Printf(\u0026#34;%s\\n\u0026#34;, car) // } for { select { case \u0026lt;-ticker.C: { // 代码块，让逻辑更聚合，更清晰 timesMutex.Lock() count := 1 if v, ok := times[car.name]; ok { count = v + 1 } times[car.name] = count timesMutex.Unlock() } fmt.Printf(\u0026#34;%s\\n\u0026#34;, car) case \u0026lt;-ctx.Done(): return } } } // 接口 type Runner interface { Run(ctx context.Context) } // 变量 var ( // 确保*Car实现了Runner接口 _ Runner = (*Car)(nil) timesMutex = new(sync.RWMutex) // 读写锁，唯一写，多个读，读时无写 times = make(map[string]int, 2) // 记录Car Run的次数；在声明时初始化，并配置容量 ) 测试 # package color import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;time\u0026#34; ) func TestCar(t *testing.T) { // 超时控制 ctx, cancel := context.WithTimeout(context.Background(), time.Second*10) defer cancel() // 并发执行 wg := new(sync.WaitGroup) for _, car := range []Runner{ // 遍历切片 NewCar(\u0026#34;lanbo\u0026#34;, 2), NewCar(\u0026#34;boshi\u0026#34;, 3), } { wg.Add(1) // 记录一个 go func(car Runner) { defer wg.Done() // 完成一个 t.Run(car.(*Car).name, func(t *testing.T) { // 对接口断言，获得具体类型 car.Run(ctx) }) }(car) } // 等上面均完成 wg.Wait() timesMutex.RLock() fmt.Printf(\u0026#34;times: %+v\\n\u0026#34;, times) timesMutex.RUnlock() } 执行 # 编译：go build\n执行：go test -v；可以尝试添加-race标志检测代码是否存在数据竞争\n"},{"id":42,"href":"/posts/2022/01/consensus/","title":"consensus","section":"01","content":"在中文里，共表示共同（至少两个人？一个人行不行？），识表示认识，组合一起成为共识，共同的认识，引申出共同的想法、共同的行为。\n在英语里，con是一个词根\u0026ndash;表示\u0026quot;共同\u0026quot;，sensus表示感觉，加在一起组成consensus。\n人类社会的发展催生了交易，交易的前提是双方达成共识，比如油换盐，比如钱换粮。如果你不承认我的油，不愿意与我交易，那就没办法了。\n人与人之间的共识是非常难以达成的，不像歌里唱的：我说一，你说一。很多时候，我说一，他也承诺他会说一，但他没说\u0026ndash;可能因为一些事忘了说，可能因为他突然不想说了，也有可能他被胁迫了不能说。反正就是不一而足的情况导致了意见/行为不一。\n在日常生活中，特别是集市上，往往都是一手交钱、一手交货，交易完成就完成了，如果后面出现了问题\u0026ndash;比如货不对版、钱有真伪，那就是另外的问题了。\n那如果我们分别在不同的地方，没法面对面交易呢；又或者交易的东西不方便马上拿到面前来交易呢；又或者交易之后发现货不对版不想要了呢？\n这时候，为了解决这些问题，某种机构应运而生。结合现在网购流行的社会，大家不难发现有哪些这类的机构。\n目前的社会除了网购流行之外，是不是机器也很流行呢。那机器又是什么呢？机器能做什么，从而在这个社会如此流行呢？机器又能不能充当某类机构来完成某些事呢？\n共识要素 # 某件事，事的主体，事的具体。比如购物，买卖双方、以钱易物。\n机器共识 # 拜占庭将军问题 # wiki\n拜占庭将军问题（Byzantine Generals Problem），是由莱斯利·兰波特在其同名论文中提出的分布式对等网络通信容错问题。\n在分布式计算中，不同的计算机通过通讯交换信息达成共识而按照同一套协作策略行动。但有时候，系统中的成员计算机可能出错而发送错误的信息，用于传递信息的通讯网络也可能导致信息损坏，使得网络中不同的成员关于全体协作的策略得出不同结论，从而破坏系统一致性。拜占庭将军问题被认为是容错性问题中最难的问题类型之一。\n关键词：分布式对等、通信容错、不同计算机通过通讯交换信息从而达成共识、共识达成失败会导致系统一致性被破坏。\n问题描述：\n一组拜占庭将军分别各率领一支军队共同围困一座城市。\n为了简化问题，将各支军队的行动策略限定为进攻或撤离两种。\n因为部分军队进攻部分军队撤离可能会造成灾难性后果，因此各位将军必须通过投票来达成一致策略，即所有军队一起进攻或所有军队一起撤离。\n因为各位将军分处城市不同方向，他们只能通过信使互相联系。\n在投票过程中每位将军都将自己投票给进攻还是撤退的信息通过信使分别通知其他所有将军，这样一来每位将军根据自己的投票和其他所有将军送来的信息就可以知道共同的投票结果而决定行动策略。\n面临问题：\n系统的问题在于，可能将军中出现叛徒，他们不仅可能向较为糟糕的策略投票，还可能选择性地发送投票信息。\u0026ndash; 出现叛徒，半真半假，选择性投票，（一人投两票） \u0026ndash; 控制投票时间，只要不在其他人都投完之后再投，他就没法知道别人投的什么票；一人投一票，投票之后不能再投；\n假设有9位将军投票，其中1名叛徒。8名忠诚的将军中出现了4人投进攻，4人投撤离的情况。这时候叛徒可能故意给4名投进攻的将领送信表示投票进攻，而给4名投撤离的将领送信表示投撤离。这样一来在4名投进攻的将领看来，投票结果是5人投进攻，从而发起进攻；而在4名投撤离的将军看来则是5人投撤离。这样各支军队的一致协同就遭到了破坏。\n由于将军之间需要通过信使通讯，叛变将军可能通过伪造信件来以其他将军的身份发送假投票。而即使在保证所有将军忠诚的情况下，也不能排除信使被敌人截杀，甚至被敌人间谍替换等情况。因此很难通过保证人员可靠性及通讯可靠性来解决问题。\n人可能是假的，信可能是假，空气都可能是假的；\n假使那些忠诚（或是没有出错）的将军仍然能通过多数决定来决定他们的战略，便称达到了拜占庭容错。在此，票都会有一个默认值，若消息（票）没有被收到，则使用此默认值来投票。\n应用：\n在点对点式数字货币系统比特币里，比特币网络的运作是平行的（parallel）。各节点与终端都运算著区块链来达成工作量证明（PoW）。工作量证明的链接是解决比特币系统中拜占庭问题的关键，避免有问题的节点（即前文提到的“反叛的将军”）破坏数字货币系统里交易帐的正确性，是对整个系统的运行状态有着重要的意义。\n在一些飞行器（如波音777）的系统中也有使用拜占庭容错。而且由于是即时系统，容错的功能也要能尽快回复，比如即使系统中有错误发生，容错系统也只能做出一微秒以内的延迟。\n一些航天飞机的飞行系统甚至将容错功能放到整个系统的设计之中。\n拜占庭容错机制是将收到的消息（或是收到的消息的签名）转交到其他的接收者。这类机制都假设它们转交的消息都可能念有拜占庭问题。在高度安全要求的系统中，这些假设甚至要求证明错误能在一个合理的等级下被排除。当然，要证明这点，首先遇到的问题就是如何有效的找出所有可能的、应能被容错的错误。这时候会试着在系统中加入错误插入器。\neth共识 # Beacon # Beacon：信标\neth2将要升级的共识机制，即将使用的基于eth1和PoS算法的共识。\n信标链不支持叔块了。\n信标链和经典链在校验header时的不同：\n(a) The following fields are expected to be constants:\ndifficulty is expected to be 0 \u0026ndash; 难度固定为0 nonce is expected to be 0 \u0026ndash; 随机数固定为0 unclehash is expected to be Hash(emptyHeader) to be the desired constants \u0026ndash; 叔块哈希固定为空值 (b) the timestamp is not verified anymore (c) the extradata is limited to 32 bytes\n切换点：TerminalTotalDifficulty is the amount of total difficulty reached by the network that triggers the consensus upgrade.\neth2升级\n引入质押\n计算当前块的basefee:\nIf the parent gasUsed is the same as the target, the baseFee remains unchanged.\nIf the parent block used more gas than its target, the baseFee should increase.\nOtherwise if the parent block used less gas than its target, the baseFee should decrease.\n其中，target：parentGasTarget = parent.GasLimit / params.ElasticityMultiplier，params.ElasticityMultiplier是常量，值为2.\n具体计算过程在consensus/misc/eip1559.go的CalcBaseFee函数里。\nPoW # consensus/ethash\n未来15秒以内的块都算是正常的块，每个块最多2个叔块。\n校验叔块时，获取最近6个高度的块信息，作为检验叔块是否合法的依据。\n1.如何挖出一个新块？\nFinalizeAndAssemble\n// FinalizeAndAssemble implements consensus.Engine, accumulating the block and // uncle rewards, setting the final state and assembling the block. func (ethash *Ethash) FinalizeAndAssemble( chain consensus.ChainHeaderReader, header *types.Header, state *state.StateDB, txs []*types.Transaction, uncles []*types.Header, receipts []*types.Receipt, ) ( *types.Block, error, ) 2.如何将这个块上链？\n// Seal generates a new sealing request for the given input block and pushes // the result into the given channel. // // Note, the method returns immediately and will send the result async. More // than one result may also be returned depending on the consensus algorithm. // // Seal implements consensus.Engine, attempting to find a nonce that satisfies // the block\u0026#39;s difficulty requirements. func (ethash *Ethash) Seal( chain consensus.ChainHeaderReader, block *types.Block, results chan\u0026lt;- *types.Block, stop \u0026lt;-chan struct{}, ) error // mine is the actual proof-of-work miner that searches for a nonce starting from // seed that results in correct final block difficulty. func (ethash *Ethash) mine( block *types.Block, id int, seed uint64, abort chan struct{}, found chan *types.Block, ) // hashimotoFull aggregates data from the full dataset (using the full in-memory // dataset) in order to produce our final value for a particular header hash and // nonce. func hashimotoFull( dataset []uint32, hash []byte, nonce uint64, ) ( digest []byte, result []byte, ) 先获得一个随机数，然后递增该随机数，直到计算出符合要求的结果。\u0026ndash; 除结果外，还有一个digest。\n最后将该随机数和digest保存到块的header里。\nfunc (w *worker) resultLoop() { defer w.wg.Done() for { select { case block := \u0026lt;-w.resultCh: // Short circuit when receiving empty result. if block == nil { continue } // Short circuit when receiving duplicate result caused by resubmitting. if w.chain.HasBlock(block.Hash(), block.NumberU64()) { continue } var ( sealhash = w.engine.SealHash(block.Header()) hash = block.Hash() ) w.pendingMu.RLock() task, exist := w.pendingTasks[sealhash] w.pendingMu.RUnlock() if !exist { log.Error(\u0026#34;Block found but no relative pending task\u0026#34;, \u0026#34;number\u0026#34;, block.Number(), \u0026#34;sealhash\u0026#34;, sealhash, \u0026#34;hash\u0026#34;, hash) continue } // Different block could share same sealhash, deep copy here to prevent write-write conflict. var ( receipts = make([]*types.Receipt, len(task.receipts)) logs []*types.Log ) for i, taskReceipt := range task.receipts { receipt := new(types.Receipt) receipts[i] = receipt *receipt = *taskReceipt // add block location fields receipt.BlockHash = hash receipt.BlockNumber = block.Number() receipt.TransactionIndex = uint(i) // Update the block hash in all logs since it is now available and not when the // receipt/log of individual transactions were created. receipt.Logs = make([]*types.Log, len(taskReceipt.Logs)) for i, taskLog := range taskReceipt.Logs { log := new(types.Log) receipt.Logs[i] = log *log = *taskLog log.BlockHash = hash } logs = append(logs, receipt.Logs...) } // ===== 提交块，保存状态到数据库 ===== // Commit block and state to database. _, err := w.chain.WriteBlockAndSetHead(block, receipts, logs, task.state, true) if err != nil { log.Error(\u0026#34;Failed writing block to chain\u0026#34;, \u0026#34;err\u0026#34;, err) continue } log.Info(\u0026#34;Successfully sealed new block\u0026#34;, \u0026#34;number\u0026#34;, block.Number(), \u0026#34;sealhash\u0026#34;, sealhash, \u0026#34;hash\u0026#34;, hash, \u0026#34;elapsed\u0026#34;, common.PrettyDuration(time.Since(task.createdAt))) // Broadcast the block and announce chain insertion event w.mux.Post(core.NewMinedBlockEvent{Block: block}) // Insert the block into the set of pending ones to resultLoop for confirmations w.unconfirmed.Insert(block.NumberU64(), block.Hash()) case \u0026lt;-w.exitCh: return } } } PoA # consensus/clique\nfilecoin # 在某段时间里存储着某些内容。\n需要证明存储了内容，并且存储了一段时间。\nPoST\n关键过程：P1, P2, C1 C2\n密封接口定义\ntype Sealer interface { SealPreCommit1(ctx context.Context, sector SectorRef, ticket abi.SealRandomness, pieces []abi.PieceInfo) (PreCommit1Out, error) SealPreCommit2(ctx context.Context, sector SectorRef, pc1o PreCommit1Out) (SectorCids, error) SealCommit1(ctx context.Context, sector SectorRef, ticket abi.SealRandomness, seed abi.InteractiveSealRandomness, pieces []abi.PieceInfo, cids SectorCids) (Commit1Out, error) SealCommit2(ctx context.Context, sector SectorRef, c1o Commit1Out) (Proof, error) FinalizeSector(ctx context.Context, sector SectorRef, keepUnsealed []Range) error // ReleaseUnsealed marks parts of the unsealed sector file as safe to drop // (called by the fsm on restart, allows storage to keep no persistent // state about unsealed fast-retrieval copies) ReleaseUnsealed(ctx context.Context, sector SectorRef, safeToFree []Range) error ReleaseSectorKey(ctx context.Context, sector SectorRef) error ReleaseReplicaUpgrade(ctx context.Context, sector SectorRef) error // Removes all data associated with the specified sector Remove(ctx context.Context, sector SectorRef) error // Generate snap deals replica update ReplicaUpdate(ctx context.Context, sector SectorRef, pieces []abi.PieceInfo) (ReplicaUpdateOut, error) // Prove that snap deals replica was done correctly ProveReplicaUpdate1(ctx context.Context, sector SectorRef, sectorKey, newSealed, newUnsealed cid.Cid) (ReplicaVanillaProofs, error) ProveReplicaUpdate2(ctx context.Context, sector SectorRef, sectorKey, newSealed, newUnsealed cid.Cid, vanillaProofs ReplicaVanillaProofs) (ReplicaUpdateProof, error) // GenerateSectorKeyFromData computes sector key given unsealed data and updated replica GenerateSectorKeyFromData(ctx context.Context, sector SectorRef, unsealed cid.Cid) error } 密封接口实现\ntype Manager struct { ls stores.LocalStorage storage *stores.Remote localStore *stores.Local remoteHnd *stores.FetchHandler index stores.SectorIndex sched *scheduler storage.Prover workLk sync.Mutex work *statestore.StateStore callToWork map[storiface.CallID]WorkID // used when we get an early return and there\u0026#39;s no callToWork mapping callRes map[storiface.CallID]chan result results map[WorkID]result waitRes map[WorkID]chan struct{} } // Manager实现了以下两个接口 var ( _ storage.Sealer = (*Manager)(nil) _ SectorManager = (*Manager)(nil) ) 有限状态机FSM\ntype Sealing struct { Api SealingAPI DealInfo *CurrentDealInfoManager feeCfg config.MinerFeeConfig events Events startupWait sync.WaitGroup maddr address.Address sealer sectorstorage.SectorManager // 上述Manager实现了SectorManager接口 sectors *statemachine.StateGroup sc SectorIDCounter verif ffiwrapper.Verifier pcp PreCommitPolicy inputLk sync.Mutex openSectors map[abi.SectorID]*openSector sectorTimers map[abi.SectorID]*time.Timer pendingPieces map[cid.Cid]*pendingPiece assignedPieces map[abi.SectorID][]cid.Cid creating *abi.SectorNumber // used to prevent a race where we could create a new sector more than once upgradeLk sync.Mutex toUpgrade map[abi.SectorNumber]struct{} notifee SectorStateNotifee addrSel AddrSel stats SectorStats terminator *TerminateBatcher precommiter *PreCommitBatcher commiter *CommitBatcher getConfig GetSealingConfigFunc } // 有限状态机规则 // // 一个map，key是状态，value是一个函数，函数接受一系列事件和当前的扇区信息，对扇区执行指定操作，最后返回 var fsmPlanners = map[SectorState]func(events []statemachine.Event, state *SectorInfo) (uint64, error) { // ... } // Sealing实现了go-statemachine包里的StateHandler接口 func (m *Sealing) Plan(events []statemachine.Event, user interface{}) (interface{}, uint64, error) // 根据上面定义的有限状态转换规则执行 func (m *Sealing) plan(events []statemachine.Event, state *SectorInfo) (func(statemachine.Context, SectorInfo) error, uint64, error) { // ... } go-statemachine\ntype StateHandler interface { // returns Plan(events []Event, user interface{}) (interface{}, uint64, error) } // Send sends an event to machine identified by `id`. // `evt` is going to be passed into StateHandler.Planner, in the events[].User param // // If a state machine with the specified id doesn\u0026#39;t exits, it\u0026#39;s created, and it\u0026#39;s // state is set to zero-value of stateType provided in group constructor // // 每个id对应一个状态机 func (s *StateGroup) Send(id interface{}, evt interface{}) (err error) // StateGroup 返回StateMachine func (s *StateGroup) loadOrCreate(name interface{}, userState interface{}) (*StateMachine, error) { // ... res := \u0026amp;StateMachine{ planner: s.hnd.Plan, eventsIn: make(chan Event), name: name, st: s.sts.Get(name), stateType: s.stateType, stageDone: make(chan struct{}), closing: make(chan struct{}), closed: make(chan struct{}), } go res.run() // 启动状态机 return res, nil } go-statestore\n// mutator func(*T) error // // 这里的mutator函数在StateMachine.run里执行，传入的是planner，将会执行状态机函数 func (st *StoredState) Mutate(mutator interface{}) error { return st.mutate(cborMutator(mutator)) } // 以名称查找状态，找到后执行mutator，如果有修改，保存回去 func (st *StoredState) mutate(mutator func([]byte) ([]byte, error)) error { has, err := st.ds.Has(context.TODO(), st.name) if err != nil { return err } if !has { return xerrors.Errorf(\u0026#34;No state for %s\u0026#34;, st.name) } cur, err := st.ds.Get(context.TODO(), st.name) if err != nil { return err } mutated, err := mutator(cur) if err != nil { return err } if bytes.Equal(mutated, cur) { return nil } return st.ds.Put(context.TODO(), st.name, mutated) } // 包装方法，将函数以另外的形式包装 func cborMutator(mutator interface{}) func([]byte) ([]byte, error) { rmut := reflect.ValueOf(mutator) return func(in []byte) ([]byte, error) { state := reflect.New(rmut.Type().In(0).Elem()) err := cborutil.ReadCborRPC(bytes.NewReader(in), state.Interface()) if err != nil { return nil, err } out := rmut.Call([]reflect.Value{state}) if err := out[0].Interface(); err != nil { return nil, err.(error) } return cborutil.Dump(state.Interface()) } } lotus是如何通过cgo调用rust库的呢？ # c-go绑定库生成工具\n此库作为cgo绑定代码生成工具\nautomatically creating c-go bindings for a given set of C headers and the manifest file.\nc-rust: generating C bindings from Rust code 用来生成rust代码的c绑定库\ncargo install \u0026ndash;force cbindgen\ncbindgen \u0026ndash;config cbindgen.toml \u0026ndash;lang c \u0026ndash;crate my_rust_library \u0026ndash;output my_header.h\nvalgrind: 检测c/c++内存泄漏的工具\nValgrind 可以用来检测程序是否有非法使用内存的问题，例如访问未初始化的内存、访问数组时越界、忘记释放动态内存等问题。\n报错： valgrind: the \u0026lsquo;impossible\u0026rsquo; happened: Unsupported arch_prctl option\n需要安装最新的valgrind： manual compile the latest version of valgrind fix the problems\nffi: go-c-rust\n此库作为子模块包含到lotus项目里\n在rust目录里，有一个名为filcrypto的crate。\n会构建出来三个文件：filcrypto.h, libfilcrypto.a, filcrypto.pc\npc文件: pkg-config的配置文件, 把众多头文件和库文件的位置指出来\n通过filcrypto.yml文件的配置(指定头文件等)来使用c-for-go工具生成cgo绑定: go run github.com/xlab/c-for-go --nostamp filcrypto.yml\nrust-filecoin-proofs-api: the official public API into the proofs library\nrust-fil-proofs # 共识库： rust-fil-proofs\nStorage Proofs (storage-proofs) A library for constructing storage proofs – including non-circuit proofs, corresponding SNARK circuits, and a method of combining them.\nStorage Proofs Core (storage-proofs-core) A set of common primitives used throughout the other storage-proofs sub-crates, including crypto, merkle tree, hashing and gadget interfaces.\nStorage Proofs PoRep (storage-proofs-porep) storage-proofs-porep is intended to serve as a reference implementation for Proof-of-Replication (PoRep), while also performing the heavy lifting for filecoin-proofs.\nPrimary Components:\nPoR (Proof-of-Retrievability: Merkle inclusion proof)\nDrgPoRep (Depth Robust Graph Proof-of-Replication)\nStackedDrgPoRep\nStorage Proofs PoSt (storage-proofs-post) storage-proofs-post is intended to serve as a reference implementation for Proof-of-Space-time (PoSt), for filecoin-proofs.\nPrimary Components:\nPoSt (Proof-of-Spacetime)\nFilecoin Proofs (filecoin-proofs) A wrapper around storage-proofs, providing an FFI-exported API callable from C (and in practice called by lotus via cgo). Filecoin-specific values of setup parameters are included here.\n"},{"id":43,"href":"/posts/2022/01/red_black_tree/","title":"红黑树","section":"01","content":"树，保持高效在于平衡，高度低。\n红黑树如何做到的呢？\n定义 # wiki # 红黑树（英语：Red–black tree）是一种自平衡二叉查找树，是在计算机科学中用到的一种数据结构，典型用途是实现关联数组。它在1972年由鲁道夫·贝尔发明，被称为\u0026quot;对称二叉B树\u0026quot;，它现代的名字源于Leo J. Guibas和罗伯特·塞奇威克于1978年写的一篇论文。红黑树的结构复杂，但它的操作有着良好的最坏情况运行时间，并且在实践中高效：它可以在O(log n)时间内完成查找、插入和删除，这里的n是树中元素的数目。\n性质 # 红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色。在二叉查找树强制一般要求以外，对于任何有效的红黑树我们增加了如下的额外要求：\n节点是红色或黑色。 根是黑色。 所有叶子都是黑色（叶子是NIL节点）。 每个红色节点必须有两个黑色的子节点。（从每个叶子到根的所有路径上不能有两个连续的红色节点。） 从**任一节点到其每个叶子**的所有简单路径都包含**相同数目的黑色节点**。 一句话概况：或红或黑，首尾皆黑，红子必黑，任一点至所有尾含黑同数。\n为确保任一点至所有尾含黑同数，路径中必须插入红点，而在哪个位置插呢（必须考虑红子必黑原则）？\n这些约束确保了红黑树的关键特性：从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。结果是这个树大致上是平衡的。因为操作比如插入、删除和查找某个值的最坏情况时间都要求与树的高度成比例，这个在高度上的理论上限允许红黑树在最坏情况下都是高效的，而不同于普通的二叉查找树。\n要知道为什么这些性质确保了这个结果，注意到性质4导致了路径不能有两个毗连的红色节点就足够了。最短的可能路径都是黑色节点，最长的可能路径有交替的红色和黑色节点。因为根据性质5所有最长的路径都有相同数目的黑色节点，这就表明了没有路径能多于任何其他路径的两倍长。\n在很多树数据结构的表示中，一个节点有可能只有一个子节点，而叶子节点包含数据。用这种范例表示红黑树是可能的，但是这会改变一些性质并使算法复杂。为此，本文中我们使用\u0026quot;nil叶子\u0026quot;或\u0026quot;空（null）叶子\u0026quot;，如上图所示，它不包含数据而只充当树在此结束的指示。这些节点在绘图中经常被省略，导致了这些树好像同上述原则相矛盾，而实际上不是这样。与此有关的结论是所有节点都有两个子节点，尽管其中的一个或两个可能是空叶子。\n实现 # 操作 # 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的只读操作与普通二叉查找树上的只读操作相同。然而，在红黑树上进行插入操作和删除操作会导致不再符合红黑树的性质。恢复红黑树的性质需要少量（O(log n)）的颜色变更（实际是非常快速的）和不超过三次树旋转（对于插入操作是两次）。虽然插入和删除很复杂，但操作时间仍可以保持为O(log n)次。\n我们首先以二叉查找树的方法增加节点并标记它为红色。（如果设为黑色，就会导致根到叶子的路径上有一条路上，多一个额外的黑节点，这个是很难调整的。但是设为红色节点后，可能会导致出现两个连续红色节点的冲突，那么可以通过**颜色调换（color flips）和 树旋转**来调整。） 树旋转 # 对二叉树的一种操作，不影响元素的顺序，但会改变树的结构，将一个节点上移、一个节点下移。树旋转会改变树的形状，因此常被用来将较小的子树下移、较大的子树上移，从而降低树的高度、提升许多树操作的效率。\n对一棵树进行旋转时，这棵树的根节点是被旋转的两棵子树的父节点，称为旋转时的根（英语：root）；如果节点在旋转后会成为新的父节点，则该节点为旋转时的转轴（英语：pivot）。\n上图中，树的右旋操作以 Q 为根、P 为转轴，会将树顺时针旋转。相应的逆操作为左旋，会以 Q 为转轴，将树逆时针旋转。\n理解树旋转过程的关键，在于理解其中不变的约束。旋转操作不会导致叶节点顺序的改变（可以理解为旋转操作前后，树的中序遍历结果是一致的），旋转过程中也始终受二叉搜索树的主要性质约束：右子节点比父节点大、左子节点比父节点小。尤其需要注意的是，进行右旋转时，旋转前根的左节点的右节点（例如上图中以 Q 为根的 B 节点）会变成根的左节点，根本身则在旋转后会变成新的根的右节点，而在这一过程中，整棵树一直遵守着前面提到的几个约束。相反的左旋转操作亦然。\n如果将根记为 Root、转轴记为 Pivot、子节点中与旋转方向相同的一侧记为 RS（旋转侧，英语：Rotation Side）、旋转对侧记为 OS（英语：Opposite Side），则上图中 Q 节点的 RS 为 C、OS 为 P，将其右旋转的伪代码为：\nPivot = Root.OS Root.OS = Pivot.RS Pivot.RS = Root Root = Pivot 该操作为常数时间复杂度。\n代码 # package redblacktree import \u0026#34;fmt\u0026#34; type Color int const ( Red Color = 0 Black Color = 1 ) func (color Color) output() string { switch color { case Red: return \u0026#34;RED\u0026#34; case Black: return \u0026#34;BLACK\u0026#34; default: return \u0026#34;\u0026#34; } } type Node struct { value int color Color leftTree, rightTree, parent *Node } // Grandparent 爷 func (node *Node) Grandparent() *Node { if node.parent == nil { return nil } return node.parent.parent } // Uncle 叔伯 func (node *Node) Uncle() *Node { if node.Grandparent() == nil { return nil } if node.parent == node.Grandparent().rightTree { return node.Grandparent().leftTree } else { return node.Grandparent().rightTree } } // Sibling 兄弟 func (node *Node) Sibling() *Node { if node.parent == nil { return nil } if node.parent.leftTree == node { return node.parent.rightTree } else { return node.parent.leftTree } } type RBT struct { root, NIL *Node } // 右翻转 // 涉及节点：本节点、父节点的左子节点、右节点、根节点、爷节点 // 移动方向： func (t *RBT) rotateRight(node *Node) { gp := node.Grandparent() fa := node.parent rt := node.rightTree fa.leftTree = rt if rt != t.NIL { rt.parent = fa } node.rightTree = fa fa.parent = node if t.root == fa { t.root = rt } node.parent = gp if gp != nil { if gp.leftTree == fa { gp.leftTree = node } else { gp.rightTree = node } } } func (t *RBT) rotateLeft(node *Node) { if node.parent == nil { t.root = node return } gp := node.Grandparent() fa := node.parent lt := node.leftTree fa.rightTree = lt if lt != t.NIL { lt.parent = fa } node.leftTree = fa fa.parent = node if t.root == fa { t.root = node } node.parent = gp if gp != nil { if gp.leftTree == fa { gp.leftTree = node } else { gp.rightTree = node } } } func (t *RBT) inorder(node *Node, level int) { level++ var prefix string for i := 1; i \u0026lt; level; i++ { prefix += \u0026#34; \u0026#34; } if node == t.NIL { fmt.Printf(\u0026#34;%s-NIL(%s)\\n\u0026#34;, prefix, node.color.output()) return } if node.leftTree != nil { t.inorder(node.leftTree, level) } fmt.Printf(\u0026#34;%s-%d(%s)\\n\u0026#34;, prefix, node.value, node.color.output()) if node.rightTree != nil { t.inorder(node.rightTree, level) } } func (t *RBT) getSmallestChild(node *Node) *Node { if node.leftTree == t.NIL { return node } return t.getSmallestChild(node.leftTree) } func (t *RBT) GetMaxChild(node *Node) *Node { if node.rightTree == nil { return node } return t.GetMaxChild(node.rightTree) } func (t *RBT) deleteChild(node *Node, data int) bool { if node.value \u0026gt; data { if node.leftTree == t.NIL { return false } return t.deleteChild(node.leftTree, data) } else if node.value \u0026lt; data { if node.rightTree == t.NIL { return false } return t.deleteChild(node.rightTree, data) } else if node.value == data { if node.rightTree == t.NIL { t.deleteOneChild(node) return true } smallest := t.getSmallestChild(node.rightTree) // swap(p-\u0026gt;value, smallest-\u0026gt;value) node.value, smallest.value = smallest.value, node.value t.deleteOneChild(smallest) return true } return false } func (t *RBT) deleteOneChild(node *Node) { var child *Node if node.leftTree == t.NIL { child = node.rightTree } else { child = node.leftTree } if node.parent == nil \u0026amp;\u0026amp; node.leftTree == t.NIL \u0026amp;\u0026amp; node.rightTree == t.NIL { node = nil t.root = node return } if node.parent == nil { child.parent = nil t.root = child t.root.color = Black return } if node.parent.leftTree == node { node.parent.leftTree = child } else { node.parent.rightTree = child } child.parent = node.parent if node.color == Black { if child.color == Red { child.color = Black } else { t.deleteCase(child) } } } func (t *RBT) deleteCase(node *Node) { if node.parent == nil { node.color = Black return } if node.Sibling().color == Red { node.parent.color = Red node.Sibling().color = Black if node == node.parent.leftTree { t.rotateLeft(node.parent) } else { t.rotateRight(node.parent) } } if node.parent.color == Black \u0026amp;\u0026amp; node.Sibling().color == Black \u0026amp;\u0026amp; node.Sibling().leftTree.color == Black \u0026amp;\u0026amp; node.Sibling().rightTree.color == Black { node.Sibling().color = Red t.deleteCase(node.parent) } else if node.parent.color == Red \u0026amp;\u0026amp; node.Sibling().color == Black \u0026amp;\u0026amp; node.Sibling().leftTree.color == Black \u0026amp;\u0026amp; node.Sibling().rightTree.color == Black { node.Sibling().color = Red node.parent.color = Black } else { if node.Sibling().color == Black { if node == node.parent.leftTree \u0026amp;\u0026amp; node.Sibling().leftTree.color == Red \u0026amp;\u0026amp; node.Sibling().rightTree.color == Black { node.Sibling().color = Red node.Sibling().leftTree.color = Black t.rotateRight(node.Sibling().leftTree) } else if node == node.parent.rightTree \u0026amp;\u0026amp; node.Sibling().leftTree.color == Black \u0026amp;\u0026amp; node.Sibling().rightTree.color == Red { node.Sibling().color = Red node.Sibling().rightTree.color = Black t.rotateLeft(node.Sibling().rightTree) } } node.Sibling().color = node.parent.color node.parent.color = Black if node == node.parent.leftTree { node.Sibling().rightTree.color = Black t.rotateLeft(node.Sibling()) } else { node.Sibling().leftTree.color = Black t.rotateRight(node.Sibling()) } } } func (t *RBT) insert(node *Node, data int) { if node.value \u0026gt;= data { if node.leftTree != nil \u0026amp;\u0026amp; node.leftTree != t.NIL { t.insert(node.leftTree, data) } else { tmp := new(Node) tmp.value = data tmp.leftTree = t.NIL tmp.rightTree = t.NIL tmp.parent = node node.leftTree = tmp t.insertCase(tmp) } } else { if node.rightTree != nil \u0026amp;\u0026amp; node.rightTree != t.NIL { t.insert(node.rightTree, data) } else { tmp := new(Node) tmp.value = data tmp.leftTree = t.NIL tmp.rightTree = t.NIL tmp.parent = node node.rightTree = tmp t.insertCase(tmp) } } } func (t *RBT) insertCase(node *Node) { if node.parent == nil { t.root = node node.color = Black return } fmt.Printf(\u0026#34;insertCase: node: %+v, parent: %+v\\n\u0026#34;, node, node.parent) // t.inorder(t.root) if node.parent.color == Red { if node.Uncle() != nil \u0026amp;\u0026amp; node.Uncle().color == Red { node.parent.color = Black node.Uncle().color = Black node.Grandparent().color = Red t.insertCase(node.Grandparent()) } else { if node.parent.rightTree == node \u0026amp;\u0026amp; node.Grandparent().leftTree == node.parent { t.rotateLeft(node) node.color = Black node.parent.color = Red t.rotateRight(node) } else if node.parent.leftTree == node \u0026amp;\u0026amp; node.Grandparent().rightTree == node.parent { t.rotateRight(node) node.color = Black node.parent.color = Red t.rotateLeft(node) } else if node.parent.leftTree == node \u0026amp;\u0026amp; node.Grandparent().leftTree == node.parent { node.parent.color = Black node.Grandparent().color = Red t.rotateRight(node.parent) } else if node.parent.rightTree == node \u0026amp;\u0026amp; node.Grandparent().rightTree == node.parent { node.parent.color = Black node.Grandparent().color = Red t.rotateLeft(node.parent) } } } } func (t *RBT) DeleteTree(node *Node) { if node == nil || node == t.NIL { return } t.DeleteTree(node.leftTree) t.DeleteTree(node.rightTree) } func (t *RBT) search(node *Node, data int) *Node { if node == nil { return nil } if node.value \u0026gt; data { if node.leftTree == nil { return nil } return t.search(node.leftTree, data) } else if node.value \u0026lt; data { if node.rightTree == nil { return nil } return t.search(node.rightTree, data) } else { return node } } func (t *RBT) Inorder() { if t.root == nil { return } t.inorder(t.root, 0) fmt.Println(\u0026#34;\u0026#34;) } func (t *RBT) Search(data int) (*Node, bool) { if t.root == nil { return nil, false } node := t.search(t.root, data) return node, node != nil } func (t *RBT) Insert(data int) { if t.root == nil { t.root = new(Node) t.root.color = Black t.root.leftTree = t.NIL t.root.rightTree = t.NIL t.root.value = data } else { t.insert(t.root, data) } } func (t *RBT) Delete(data int) bool { return t.deleteChild(t.root, data) } func NewRBT() *RBT { return \u0026amp;RBT{ root: nil, NIL: \u0026amp;Node{color: Black}, } } 分析 # 树皆有根，根连干，干连枝，枝连叶，盘根错节。通过红黑树的形式来管理这颗树，让树的营养均衡，从而保持长久的生命力。\n命运扭成一个死结，怎么办？不如分散为独立事件，各自处理。分合之间，分久必合，合久必分。集权者只顾为己争权夺利，越集中越凶险，故分；诸侯王枉顾生死不辩是非互相倾轧，越分散越苦痛，故合。是合，是分，由谁定呢？什么时候定呢？感觉（分久必合，合久必分）这句话更多是作者的一种感慨，中间有太多无奈和哀伤。\n达成共识，才能动工。社会是这样，皆因大部分人都认可这样。要想改变，从观念开始。只有达成新的共识，才能改变。至少要让有能力动手的达成共识。\n如果都在一棵树上，树倒猢狲散，那么大家都会极力促成共识的达成吧。不过现实往往不只一颗树，并且每棵树还各自不一样，所以要想达成共识非常困难。如果各自有意愿往共识达成努力，也还能多交流、沟通，以图共识。万一各怀异心，就无法一致了。此时，付出更多的一方反而受伤越多、损失越重。\n"},{"id":44,"href":"/posts/2022/01/rust_commonly_used_crate/","title":"Rust常用库","section":"01","content":" crossbeam # crossbeam: Tools for concurrent programming in Rust.\nAtomics\nData structures\nMemory management: epoch\nThread synchronization: channel, Parker, ShardedLock, WaitGroup\nUtilities\nchannel example # use crossbeam_channel::unbounded; let (s, r) = unbounded(); s.send(\u0026#34;Hello, world!\u0026#34;).unwrap(); assert_eq!(r.recv(), Ok(\u0026#34;Hello, world!\u0026#34;)); unbounded(无限) channel发送时不用等接收端就绪。\n另外还有bounded channel可在新建时指定容量，后续发送的消息数不能超过该数据 \u0026ndash; 除非中间有消息被取走了\n当bounded channel容量设为0时，发送前必须等接收端就绪，一般可用于线程间等待。\n更多介绍\n与标准库的sync::mpsc对比\nepoch # Pin 做了什么？\ncrossbeam在实现无锁并发结构时，采用了基于代的内存回收方式1，这种算法的内存管理开销和数据对象的数量无关，只和线程的数量相关，因此在 以上模型中可以表现出更好的一致性和可预测性。不过Rust中的所有权系统已经保证了内存安全，那为什么还需要做额外的内存回收呢？这个问题的关键点 就在要实现无锁并发结构。如果使用标准库中的Arc自然就不会有内存回收的问题，但对Arc进行读写是需要锁的。\ncrossbeam-channel文章\ndigest # This crate provides traits which describe functionality of cryptographic hash functions and Message Authentication algorithms.\n加密哈希函数和消息认证算法。\nsha2raw # 聚焦在固定大小块的sha256实现。\nrand # 随机数生成\nrayon # Rayon: A data parallelism library for Rust 数据并行，很容易就能转换一系列计算到并行。保证无数据竞争。\nuse rayon::prelude::*; fn sum_of_squares(input: \u0026amp;[i32]) -\u0026gt; i32 { // input.iter() input.par_iter() // \u0026lt;-- iter -\u0026gt; par_iter .map(|\u0026amp;i| i * i) .sum() } Parallel iterators小心决定如何分解数据到任务里；它会动态调整以获得最大性能。\nserde \u0026amp; serde_json # serde\n高效的、通用的序列化和反序列化Rust数据结构框架。\nuse serde::{Serialize, Deserialize}; #[derive(Serialize, Deserialize, Debug)] struct Point { x: i32, y: i32, } fn main() { let point = Point { x: 1, y: 2 }; // Convert the Point to a JSON string. let serialized = serde_json::to_string(\u0026amp;point).unwrap(); // Prints serialized = {\u0026#34;x\u0026#34;:1,\u0026#34;y\u0026#34;:2} println!(\u0026#34;serialized = {}\u0026#34;, serialized); // Convert the JSON string back to a Point. let deserialized: Point = serde_json::from_str(\u0026amp;serialized).unwrap(); // Prints deserialized = Point { x: 1, y: 2 } println!(\u0026#34;deserialized = {:?}\u0026#34;, deserialized); } 为啥serde_json不用导入也能用呢？\nbellperson # a crate for building zk-SNARK circuits\nzk-SNARK: 零知识简洁的非交互式知识论证，一种新颖的零知识密码学形式。是一种证明结构，在这种结构中，人们可以证明拥有某些信息，例如一个秘密秘钥，而无需透漏该信息，并且之间没有任何交互证明者和验证者。\n零知识证明，允许一方（证明者）向另一方（验证者）证明一个陈述是真实的，而不会透漏超出陈述本身有效性的任何信息。例如，给定一个随机数的哈希值，证明者可以说服验证者确实存在一个具有该哈希值的数字，而无需透漏它是什么。\n证明者不仅可以说服验证者该数字存在，而且他们实际上知道这样一个数字。\u0026ndash; 验证者不知道具体的数字值，但是知道它存在。\n“简洁”的零知识证明可以在几毫秒内得到验证，即使是关于非常大的程序的语句，证明长度也只有几百字节。\n在第一个零知识协议中，证明者和验证者必须来回通信多轮，\n但在“非交互式”结构中，证明由从证明者发送到验证者的单个消息组成。目前，生成非交互式且足够短以发布到区块链的零知识证明的最有效的已知方法是具有初始设置阶段，该阶段生成在证明者和验证者之间共享的公共参考字符串。我们将这个公共引用字符串称为系统的公共参数。\nZcash是zk-SNARKs的第一个广泛应用，Zcash强大的隐私保证源于这样一个事实，即Zcash中的屏蔽交易可以在区块链上完全加密，但仍然可以通过zk-SNARK证明在网络的共识规则下验证其有效性。\n参照\nlog # 日志门面库\n所谓门面，其实就是它定义了一套统一的日志trait API， 抽象出来日志的常规操作，具体的日志库实现它定义的API。\n介绍文章\nLog trait是核心，它定义了三个方法：\nfn enabled(\u0026amp;self, metadata: \u0026amp;Metadata) -\u0026gt; bool: 返回这条log是否允许输出日志, 具体的日志库可以根据Metadata中的日志级别来判断\nfn log(\u0026amp;self, record: \u0026amp;Record): 记录这条日志，这里日志使用Record来表示这条日志\nfn flush(\u0026amp;self): flush缓存的日志\nanyhow # 一个基于trait对象错误类型的更容易惯用的错误处理库\nuse Result\u0026lt;T, anyhow::Error\u0026gt; or anyhow::Result\u0026lt;T\u0026gt;\nWithin the function, use ? to easily propagate any error that implements the std::error::Error trait.\n\u0026ndash; 在函数里，使用?传播任何实现了Error trait的错误\nuse anyhow::Result; fn get_cluster_info() -\u0026gt; Result\u0026lt;ClusterMap\u0026gt; { let config = std::fs::read_to_string(\u0026#34;cluster.json\u0026#34;)?; let map: ClusterMap = serde_json::from_str(\u0026amp;config)?; Ok(map) } thiserror # thiserror是方便大家为自定义的错误使用宏实现std::error::Error而设计的。\nthiserror \u0026amp; anyhow 文章\nnum_cpus # 确定当前系统上可用的CPU数\nlet cpus = num_cpus::get(); 可以根据获取到的CPU数值来设置rayon::Threadpool。\nhex # hex: 编码和解码16进制字符串\nlet hex_string = hex::encode(\u0026#34;Hello world!\u0026#34;); println!(\u0026#34;{}\u0026#34;, hex_string); // Prints \u0026#34;48656c6c6f20776f726c6421\u0026#34; 内部使用了serde库。\nbincode # 使用一个小二进制序列来编码和解码\n把一个对象转为字节序列\nbyteorder # 字节序：大端或小端\n提供了方便的方法，在大端或小端情况下编解码数字。\nlazy_static # 延迟初始化static常量\nRust 静态项是一种“全局变量”。它们类似于常量，但静态项不内联使用。这意味着每个值只对应一个实例， 并且在内存中只有一个固定的地址。\n静态类型活在程序的整个生命周期，只有在程序退出的时候静态项才会调用drop。\n静态类型是可变的， 你可以使用 mut 关键字声明可变性。\n此外，任何存储在 static 的类型都必须是 Sync。\n常量和静态常量都要求给他们一个值。并且他们可能只被赋予一个值，这个值是一个常数表达式。\n很多情况下，我们希望延迟初始化静态量，只有在第一次访问的时候，或者在某个特定的时候才初始化它，那么就可以使用lazy_static。\nlazy_static提供了一个宏lazy_static!，使用这个宏把你的静态变量“包裹”起来就可以实现延迟初始化了。\n实际上这个宏会帮助你生成一个特定的struct,这个struct的deref方法(trait Deref)提供了延迟初始化的能力，它也提供了initialize方法，你也可以在代码中主动地调用它进行初始化。\n更多\nlibc # 绑定到平台的系统库的FFI\npairing # 成对友好的曲线\nblstrs # BLS12-381成对椭圆曲线算法实现\n"},{"id":45,"href":"/posts/2022/01/cache/","title":"缓存和数据库如何保持一致","section":"01","content":" 缓存读 # 从缓存读，如果读到了，直接返回；如果读不到，继续去数据库读（singleflight），读到后，更新缓存，返回结果。\n缓存写 # 为什么是删缓存，而不是更新缓存呢？\n主要是怕两个并发的写操作导致脏数据。\n删除缓存和更新磁盘谁先谁后呢？\n1.如果先删除缓存，再更新磁盘时的问题：\n数据发生了变更，先删除了缓存，然后要去修改数据库，此时还没修改。 \u0026ndash; 删了缓存，未完成数据库修改 另一个请求过来，去读缓存，发现缓存空了，去查询数据库，查到了修改前的旧数据，放到了缓存中。 \u0026ndash; 因为上面的请求里修改数据库的部分还未完成 随后数据变更的程序完成了数据库的修改。\u0026ndash; 这时才完成，可缓存已经填充了之前的旧值了 来到这，数据库和缓存中的数据就不一样了。\n2.先更新磁盘，再删除缓存的问题：\n先更新数据库，再删除缓存，如果数据库更新了，但是缓存删除失败了，那么缓存中的数据还是旧数据，出现数据不一致\n先删除缓存，再更新数据库。如果数据库更新失败了，那么数据库中是旧数据，缓存中是空的，那么数据不会不一致。\n比如，一个是读操作，但是没有命中缓存，然后就到数据库中取数据，此时来了一个写操作，写完数据库后，让缓存失效，然后，之前的那个读操作再把老的数据放进去，所以，会造成脏数据。\n但，这个case理论上会出现，不过，实际上出现的概率可能非常低，因为这个条件需要发生在读缓存时缓存失效，而且并发着有一个写操作。而实际上数据库的写操作会比读操作慢得多，而且还要锁表，而读操作必需在写操作前进入数据库操作，而又要晚于写操作更新缓存，所有的这些条件都具备的概率基本并不大。\n所以，这也就是Quora上的那个答案里说的，要么通过2PC或是Paxos协议保证一致性，要么就是拼命的降低并发时脏数据的概率，而Facebook使用了这个降低概率的玩法，因为2PC太慢，而Paxos太复杂。当然，最好还是为缓存设置上过期时间。\n参照\n代码 # package cache // 缓存，一般先将数据从磁盘读出来写到内存里，供用户高速访问，减少读磁盘 -- 快取 // 另有缓冲，将数据先写到内存里，待装满后一次性写入磁盘，可以少写很多次 -- 缓冲 // // 不难看出，无论快取还是缓冲，都涉及到内存和磁盘的读写。 // // 首先，对于缓存，目前使用较多的中间件是redis、memcached等，当然也有自己在程序中内置map充当缓存的。 // 那么，下面来看下如何在内存和磁盘之间同步数据： type Cache interface { // exp表示当前时间后的exp秒后过期，传0则无过期 Set(key, value string, exp int) error Del(key string) error Get(key string) (value string, err error) } type Store interface { Create(key, value string, exp int) error Delete(key string) error Update(key, value string, exp int) error Get(key string) (vlaue string, err error) } // 用户 有增删改查四个操作，在操作时，对应的缓存和磁盘如何变化呢？ type Client struct { cache Cache store Store } func NewClient( cache Cache, store Store, ) *Client { return \u0026amp;Client{ cache: cache, store: store, } } const ( defExp = 300 ) // Add 先写磁盘还是缓存呢？ func (client *Client) Add(key, value string) { // 会不会已经在Store里存在了呢？ // 先从Store Get一次？ // 一般来说，key都是唯一的： // 此时，必须请求一次Store，确认数据不存在；如果此时数据存在，直接返回错误 if v, err := client.store.Get(key); err == nil \u0026amp;\u0026amp; v != \u0026#34;\u0026#34; { return } // 缓存里会不会也有呢？ // 先从Cache里读一次？ // 如果能通过业务检查，正常来说，缓存里是没有的； // 写磁盘 client.store.Create(key, value, defExp) // 1. 写缓存 // client.cache.Set(key, value, defExp) // 2. 不写，等获取时从磁盘取 } func (client *Client) Mod(key, value string) { // 更新磁盘 client.store.Update(key, value, defExp) // 1. 更新缓存 // client.cache.Set(key, value, defExp) // 2. 不更新，删掉缓存，等获取时从磁盘取 -- Cache Aside Pattern(旁路缓存方案): 一个 lazy 计算的思想，不要每次都重新做复杂的计算，而是让它到需要被使用的时候再重新计算 client.cache.Del(key) } func (client *Client) Del(key string) { // 从磁盘删除 client.store.Delete(key) // 1. 从缓存删除 client.cache.Del(key) } func (client *Client) Get(key string) (string, error) { // 从Cache获取 v, err := client.cache.Get(key) if err != nil { return \u0026#34;\u0026#34;, err } if v == \u0026#34;\u0026#34; { // 以SingleFlight方式从Store读: // https://pkg.go.dev/golang.org/x/sync/singleflight // 这个库的主要作用就是将一组相同的请求合并成一个请求，实际上只会去请求一次，然后对所有的请求返回相同的结果。 // 在一个请求的时间周期内实际上只会向底层的数据库发起一次请求大大减少对数据库的压力。 { valueFromStore, err := client.store.Get(key) if err != nil { return \u0026#34;\u0026#34;, err } v = valueFromStore } // 设置Cache client.cache.Set(key, v, defExp) } return v, nil } "},{"id":46,"href":"/posts/2021/12/ebpf/","title":"ebpf","section":"12","content":" ebpf: 扩展伯克利包过滤器。\n下面的内容主要来源于 译文。\n用处 # 目前，主要有两大组触发器。\n第一组用于处理网络数据包和管理网络流量。它们是 XDP、流量控制事件及其他几个事件。\n以下情况需要用到这些事件：\n创建简单但非常有效的防火墙。Cloudflare 和 Facebook 等公司使用 BPF 程序来过滤掉大量的寄生流量，并打击最大规模的 DDoS 攻击。由于处理发生在数据包生命的最早阶段，直接在内核中进行（BPF 程序的处理有时甚至可以直接推送到网卡中进行），因此可以通过这种方式处理巨量的流量。这些事情过去都是在专门的网络硬件上完成的。\n创建更智能、更有针对性、但性能更好的防火墙——这些防火墙可以检查通过的流量是否符合公司的规则、是否存在漏洞模式等。例如，Facebook 在内部进行这种审计，而一些项目则对外销售这类产品。\n创建智能负载均衡器。最突出的例子就是 Cilium 项目，它最常被用作 K8s 集群中的网格网络。Cilium 对流量进行管理、均衡、重定向和分析。所有这些都是在内核运行的小型 BPF 程序的帮助下完成的，以响应这个或那个与网络数据包或套接字相关的事件。\n这是第一组与网络问题相关并能够影响网络通信行为的触发器。第二组则与更普遍的可观察性相关；在大多数情况下，这组的程序无法影响任何事件，而只能“观察”。这才是我更感兴趣的。\n这组的触发器有如下几个：\nperf 事件（perf events）——与性能和 perf Linux 分析器相关的事件：硬件处理器计数器、中断处理、小 / 大内存异常拦截等等。例如，我们可以设置一个处理程序，每当内核需要从 swap 读取内存页时，该处理程序就会运行。例如，想象有这样一个实用程序，它显示了当前所有使用 swap 的程序。\n跟踪点（tracepoints）——内核源代码中的静态（由开发人员定义）位置，通过附加到这些位置，你可以从中提取静态信息（开发人员先前准备的信息）。在这种情况下，静态似乎是一件坏事，因为我说过，日志的缺点之一就是它们只包含了程序员最初放在那里的内容。从某种意义上说，这是正确的，但跟踪点有三个重要的优势：\n有相当多的跟踪点散落在内核中最有趣的地方\n当它们不“开启”时，它们不使用任何资源\n它们是 API 的一部分，它们是稳定的，不会改变。这非常重要，因为我们将提到的其他触发器缺少稳定的 API。\n例如，假设有一个关于显示的实用程序，内核出于某种原因没有给它时间执行。你坐着纳闷为什么它这么慢，而 pprof 却没有显示任何什么有趣的东西。\nUSDT——与跟踪点相同，但是它适用于用户空间的程序。也就是说，作为程序员，你可以将这些位置添加到你的程序中。并且许多大型且知名的程序和编程语言都已经采用了这些跟踪方法：例如 MySQL、或者 PHP 和 Python 语言。通常，它们的默认设置为“关闭”，如果要打开它们，需要使用 enable-dtrace 参数或类似的参数来重新构建解释器。是的，我们还可以在 Go 中注册这种类跟踪。你可能已经识别出参数名称中的单词 DTrace。关键在于，这些类型的静态跟踪是由 Solaris) 操作系统中诞生的同名系统所推广的。例如，想象一下，何时创建新线程、何时启动 GC 或与特定语言或系统相关的其他内容，我们都能够知道是怎样的一种场景。\n这是另一种魔法开始的地方：\nFtrace 触发器为我们提供了在内核的任何函数开始时运行 BPF 程序的选项。这是完全动态的。这意味着内核将在你选择的任何内核函数或者在所有内核函数开始执行之前，开始执行之前调用你的 BPF 函数。你可以连接到所有内核函数，并在输出时获取所有调用的有吸引力的可视化效果。\nkprobes/uprobes 提供的功能与 ftrace 几乎相同，但在内核和用户空间中执行函数时，你可以选择将其附加到任何位置上。如果在函数的中间，变量上有一个“if”，并且能为这个变量建立一个值的直方图，那就不是问题。\nkretprobes/uretprobes——这里的一切都类似于前面的触发器，但是它们可以在内核函数或用户空间中的函数返回时触发。这类触发器便于查看函数的返回内容以及测量执行所需的时间。例如，你可以找出“fork”系统调用返回的 PID。\n我再重复一遍，所有这些最奇妙之处在于，当我们的 BPF 程序为了响应这些触发器而被调用之后，我们可以很好地“环顾四周”：读取函数的参数，记录时间，读取变量，读取全局变量，进行堆栈跟踪，保存一些内容以备后用，将数据发送到用户空间进行处理，和 / 或从用户空间获取数据或一些其他控制命令以进行过滤。简直不可思议！\n使用 # 先用man bpf看下它是怎么被定义的：\nNAME bpf - perform a command on an extended BPF map or program -- 在bpf map或程序里执行一个命令 SYNOPSIS #include \u0026lt;linux/bpf.h\u0026gt; int bpf(int cmd, union bpf_attr *attr, unsigned int size); -- bpf_attr里有些什么呢？ DESCRIPTION The bpf() system call performs a range of operations related to extended Berkeley Packet Filters. Extended BPF (or eBPF) is similar to the original (\u0026#34;classic\u0026#34;) BPF (cBPF) used to filter network packets. For both cBPF and eBPF programs, the kernel statically ana‐ lyzes the programs before loading them, in order to ensure that they cannot harm the run‐ ning system. -- 在程序被加载之前分析它，确保它们不会伤害到运行中的系统。 eBPF extends cBPF in multiple ways, including the ability to call a fixed set of in-ker‐ nel helper functions (via the BPF_CALL opcode extension provided by eBPF) and access shared data structures such as eBPF maps. -- ebpf在很多方面扩展了cbpf，包括可以调用固定的钩子函数的能力，可以访问共享的数据结构（如：ebpf maps）。 Extended BPF Design/Architecture eBPF maps are a generic data structure for storage of different data types. Data types are generally treated as binary blobs, so a user just specifies the size of the key and the size of the value at map-creation time. In other words, a key/value for a given map can have an arbitrary structure. A user process can create multiple maps (with key/value-pairs being opaque bytes of data) and access them via file descriptors. Different eBPF programs can access the same maps in parallel. It\u0026#39;s up to the user process and eBPF program to decide what they store in‐ side maps. -- 一个用户进程可以创建多个maps，然后通过文件描述符访问它们。不同的ebpf程序可以并行访问同一个maps。由用户进程和ebpf程序决定存储内容。 There\u0026#39;s one special map type, called a program array. This type of map stores file de‐ scriptors referring to other eBPF programs. When a lookup in the map is performed, the program flow is redirected in-place to the beginning of another eBPF program and does not return back to the calling program. The level of nesting has a fixed limit of 32, so that infinite loops cannot be crafted. At run time, the program file descriptors stored in the map can be modified, so program functionality can be altered based on specific re‐ quirements. All programs referred to in a program-array map must have been previously loaded into the kernel via bpf(). If a map lookup fails, the current program continues its execution. See BPF_MAP_TYPE_PROG_ARRAY below for further details. -- 有一类特殊的map类型，称为程序数组。这种类型的map存储指向其它ebpf程序的文件描述符。当在map里执行lookup时，程序流被重定向到另外的ebpf程序的开头，并且不会返回到当前的ebpf程序（调走之后就不回来了）。内嵌的最大层数限制为32，因此不会出现无限循环。在运行时，程序储存在map的文件描述符可以被修改，因此可以根据特定要求更改程序功能。在这种程序数组map里的程序必须在之前已经用bpf()加载了进来。如果lookup失败了，当前程序会继续执行。 Generally, eBPF programs are loaded by the user process and automatically unloaded when the process exits. In some cases, for example, tc-bpf(8), the program will continue to stay alive inside the kernel even after the process that loaded the program exits. In that case, the tc subsystem holds a reference to the eBPF program after the file descrip‐ tor has been closed by the user-space program. Thus, whether a specific program contin‐ ues to live inside the kernel depends on how it is further attached to a given kernel subsystem after it was loaded via bpf(). -- 一般地，ebpf程序被用户进程加载，并随用户进程离开而自动卸载。不过有些特别的例子，比如：tc-bpf，它在加载它的程序退出之后还会继续存活。tc子系统会持有该ebpf程序的引用。 Each eBPF program is a set of instructions that is safe to run until its completion. An in-kernel verifier statically determines that the eBPF program terminates and is safe to execute. During verification, the kernel increments reference counts for each of the maps that the eBPF program uses, so that the attached maps can\u0026#39;t be removed until the program is unloaded. -- 每个ebpf程序都是一个指令集合，安全地执行直到完成。在程序验证期间，内核增加ebpf使用的每个map的引用计数，使得map不会被移除直到程序被卸载。 eBPF programs can be attached to different events. These events can be the arrival of network packets, tracing events, classification events by network queueing disciplines (for eBPF programs attached to a tc(8) classifier), and other types that may be added in the future. A new event triggers execution of the eBPF program, which may store informa‐ tion about the event in eBPF maps. Beyond storing data, eBPF programs may call a fixed set of in-kernel helper functions. -- ebpf程序可以附加到不同的事件上。这些事件可以是网络包到达，事件追踪，按网络排队规则对事件进行分类，和其它未来将被加进来的事件。一个新的事件触发ebpf程序的执行，可以存储事件的信息到ebpf maps里。除了存储数据之外，ebpf程序可以调用一系列固定的内核钩子函数。 // union 多选一 union bpf_attr { struct { /* Used by BPF_MAP_CREATE */ __u32 map_type; __u32 key_size; /* size of key in bytes */ __u32 value_size; /* size of value in bytes */ __u32 max_entries; /* maximum number of entries in a map */ }; struct { /* Used by BPF_MAP_*_ELEM and BPF_MAP_GET_NEXT_KEY commands */ __u32 map_fd; __aligned_u64 key; union { __aligned_u64 value; __aligned_u64 next_key; }; __u64 flags; }; struct { /* Used by BPF_PROG_LOAD */ __u32 prog_type; __u32 insn_cnt; __aligned_u64 insns; /* \u0026#39;const struct bpf_insn *\u0026#39; */ __aligned_u64 license; /* \u0026#39;const char *\u0026#39; */ __u32 log_level; /* verbosity level of verifier */ __u32 log_size; /* size of user buffer */ __aligned_u64 log_buf; /* user supplied \u0026#39;char *\u0026#39; buffer */ __u32 kern_version; /* checked when prog_type=kprobe (since Linux 4.1) */ }; } __attribute__((aligned(8))); 一个 BPF 程序，如果它通过验证，就会被加载到内核中。在那里，它将被 JIT 编译器编译成机器码，并在内核模式下运行，这时附加的触发器将会被激活。\nLOAD -\u0026gt; READ -\u0026gt; WRITE 循环缓冲区：内核写入，用户空间程序可以从中读取\nBCC, bpftrace\nGo # 目前，唯一能够编译成 BPF 机器可以理解的格式的编译器是 Clang。另一种流行的编译器 GСС仍然没有 BPF 后端。而能够编译成 BPF 的编程语言，只有 C 语言的一个非常受限的版本。\n然而，BPF 程序还有一个在用户空间中的第二部分。这部分可以用 Go 来编写。\nBCC 允许你用 Python 编写这一部分，而 Python 是该工具的主要语言。同时，在主库中，BCC 还支持 Lua 和 C++，并且在辅库中，它还支持 Go。\n除了 iovisor/gobpf 之外，我还发现了其他三个最新的项目，它们允许你在 Go 中编写用户空间（userland）部分。\nhttps://github.com/golang/net/tree/master/bpf https://github.com/dropbox/goebpf https://github.com/cilium/ebpf https://github.com/andrewkroh/go-ebpf cilium/ebpf # eBPF is a pure Go library that provides utilities for loading, compiling, and debugging eBPF programs. It has minimal external dependencies and is intended to be used in long running processes.\neBPF是纯Go库，提供了加载、编译、调试eBPF程序的工具。它只有最小外部依赖，并且适合在长期运行的程序中使用。\n尝试执行示例：\n统计sys_execve系统调用的调用次数 go run -exec sudo ./kprobe go: downloading github.com/cilium/ebpf v0.7.1-0.20211126075831-9ead52e53c13 go: downloading golang.org/x/sys v0.0.0-20211001092434-39dca1131b70 [sudo] jd 的密码： 2021/12/24 14:38:52 Waiting for events.. 2021/12/24 14:38:53 sys_execve called 0 times 2021/12/24 14:38:54 sys_execve called 0 times 2021/12/24 14:38:55 sys_execve called 0 times 2021/12/24 14:38:56 sys_execve called 0 times 2021/12/24 14:38:57 sys_execve called 0 times 2021/12/24 14:38:58 sys_execve called 0 times 2021/12/24 14:38:59 sys_execve called 0 times 2021/12/24 14:39:00 sys_execve called 0 times 2021/12/24 14:39:01 sys_execve called 12 times 2021/12/24 14:39:02 sys_execve called 12 times 2021/12/24 14:39:03 sys_execve called 12 times 2021/12/24 14:39:04 sys_execve called 12 times 2021/12/24 14:39:05 sys_execve called 12 times 2021/12/24 14:39:06 sys_execve called 12 times 2021/12/24 14:39:07 sys_execve called 12 times 2021/12/24 14:39:08 sys_execve called 12 times 2021/12/24 14:39:09 sys_execve called 12 times 2021/12/24 14:39:10 sys_execve called 12 times 2021/12/24 14:39:11 sys_execve called 24 times 2021/12/24 14:39:12 sys_execve called 24 times 2021/12/24 14:39:13 sys_execve called 24 times 2021/12/24 14:39:14 sys_execve called 24 times 2021/12/24 14:39:15 sys_execve called 24 times 2021/12/24 14:39:16 sys_execve called 24 times 2021/12/24 14:39:17 sys_execve called 24 times 2021/12/24 14:39:18 sys_execve called 24 times 2021/12/24 14:39:19 sys_execve called 24 times // 允许当前进程为eBPF资源锁住内存 rlimit.RemoveMemlock() // 加载预编译程序，一般是编译c代码生成的o文件的字节内容 objs := bpfObjects{} loadBpfObjects(\u0026amp;objs, nil) defer objs.Close() // Open a Kprobe at the entry point of the kernel function and attach the // pre-compiled program. Each time the kernel function enters, the program // will increment the execution counter by 1. The read loop below polls this // map value once per second. kp, _ := link.Kprobe(fn, objs.KprobeExecve) defer kp.Close() // 在执行Kprobe方法时，会将信息写入到objs的KprobeMap里，后续在用户程序即可通过它来查看所需信息 var value uint64 objs.KprobeMap.Lookup(mapKey, \u0026amp;value) // 根据mapKey将值读取到value变量 效果 # 可以从一个正在运行的程序中获得几乎所有的信息，而无需停止或更改它。\neBPF 带来的好处是无与伦比的。\n首先，从长期看，eBPF 这项新功能会减少未来的 feature creeping normality。 因为用户或开发者希望内核实现的功能，以后不需要再通过改内核的方式来实现了。 只需要一段 eBPF 代码，实时动态加载到内核就行了。\n其次，因为 eBPF，内核也不会再引入那些影响 fast path 的蹩脚甚至 hardcode 代码 ，从而也避免了性能的下降。\n第三，eBPF 还使得内核完全可编程，安全地可编程（fully and safely programmable ），用户编写的 eBPF 程序不会导致内核 crash。另外，eBPF 设计用来解决真实世界 中的线上问题，而且我们现在仍然在坚守这个初衷。\n更多 # k8s and ebpf\nebpf\n"},{"id":47,"href":"/posts/2021/12/time_wenzi/","title":"时间和文字","section":"12","content":"带领，今天突然用到这个“带”字时，觉得它不是我印象中的“带”字，这是为什么呢？\n很重的一种陌生感迎面而来，这真的是曾经伴随我历经千测万考的字吗？\n这种突然觉得某个曾经很熟悉的字很陌生的感觉，真的很奇怪。\n"},{"id":48,"href":"/posts/2021/12/etcd/","title":"etcd","section":"12","content":" etcd # raft # 介绍 # 由多个节点组成的集群维护着一个可复制状态机的协议。通过复制日志来保持状态机的同步。 可理解的共识算法\n状态机以消息为输入。消息可以是一个本地定时器更新，或一条网络消息。输出一个3元结构：[]Messages, []LogEntries, NextState，分别是消息列表、日志条目列表、下个状态。同样状态的状态机，在相同输入时总是输出相同结果。\n插曲 # 人、联系、共识\n人生下来，触摸着这个世界的人和物，做着或有趣或无聊的事，建立起或浅或深的联系。\n当两个人面对面时，就某个想法达成一致或不一致，非常容易。\n如果两个人不是面对面呢？\n如果不只两个人，同坐在祠堂里呢？\n如果不止两个人，还分散在不同地点呢？\n那么，为什么要达成共识呢？\n因为有些事必须达成共识才能执行，比如，两个人双向奔赴。\n如果彼此异心，一个向东，一个往南，事情就办不成了。\n所以，共识是大伙成事的前提。\n共识，除了就某件事所要达成的结果，也要考虑所使用的方法。\n有可能是步步为营，走一步算一步，也就是每走一步再就下一步达成共识。\n也有可能是，一次性就接下来的几步均达成共识，然后各自执行。\nmessage type # // For description of different message types, see: // https://pkg.go.dev/go.etcd.io/etcd/raft/v3#hdr-MessageType type MessageType int32 const ( // 选举时使用； // 如果节点是一个follower或candidate，它在选举超时前没有收到任何心跳，它就回传递MsgHup消息给它自己的Step方法，然后成为（或保持）一个candidate从而开启一个新的选举 MsgHup MessageType = 0 // 一个内部类型，它向leader发送一个类型为“MsgHeartbeat”的心跳信号 // 如果节点是一个leader，raft里的tick函数将会是“tickHeartbeat”，触发leader周期性地发送“MsgHeartbeat”消息给它的followers MsgBeat MessageType = 1 // 提议往它的日志条目里追加数据； // 这是一个特别的类型，由follower反推提议给leader（正常是leader提议，follower执行）； // 发给leader的话，leader调用“appendEntry”方法追加条目到它的日志里，然后调用“bcastAppend”方法发送这些条目给它的远端节点； // 发给candidate的话，它们直接丢弃该消息 // 发给follower的话，follower会将消息存储到它们的信箱里。会把发送者的id一起存储，然后转发给leader。 MsgProp MessageType = 2 // 包含了要复制的日志条目 // leader调用“bcastAppend”（里面调用“sendAppend”），发送“一会要被复制的日志”消息； // 当candidate收到消息后，在它的Step方法里，它马上回退为follower，因为这条消息表明已经存在一个有效leader了。 // candidate和follower均会返回一条“MsgAppResp”类型消息以作响应。 MsgApp MessageType = 3 // 调用“handlerAppendEntries”方法 MsgAppResp MessageType = 4 // 请求集群中的节点给自己投票； // 当节点是follower或candidate，并且它们的Step方法收到了“MsgHup”消息，节点调用“campaign”方法去提议自己成为一个leader。一旦“campaign”方法被调用，节点成为candidate，并发送“MsgVote”给集群中的远端节点请求投票。 // 当leader或candidate的Step方法收到该消息，并且消息的Term比它们的Term小，“MsgVote”将被拒绝。 // 当leader或candidate收到的消息的Term要更大时，它会回退为follower。 // 当follower收到该消息，仅当发送者的最后的term比“MsgVote”的term要大，或发送者的最后term等于“MsgVote”的term（但发送者的最后提交index大于等于follower的）， MsgVote MessageType = 5 // 投票响应； // 当candidate收到后，它会统计选票，如果大于majority（quorum），它成为leader并调用“bcastAppend”。如果candidate收到大量的否决票，它将回退到follower MsgVoteResp MessageType = 6 // 请求安装一个快照消息； // 当一个节点刚成为leader，或者leader收到了“MsgProp”消息，它调用“bcastAppend”方法（里面再调用“sendAppend”）方法到每个follower。在“sendAppend”方法里，如果一个leader获取term或条目失败了，leader通过\u0026#34;MsgSnap\u0026#34;消息请求快照。 MsgSnap MessageType = 7 // leader发送心跳； // 当candidate收到“MsgHeartbeat”，并且消息的term比candidate的大，candidate回退到follower并且更新它的提交index为这次心跳里的值。然后candidate发送消息到它的信箱。 // 当消息发送到follower的Step方法，并且消息的term比follower的大，follower更新它的leader id MsgHeartbeat MessageType = 8 // 心跳响应； // leader收到后就知道有哪些follower响应了。 // 只有当leader的最后提交index比follower的Match index大时，leader执行“sendAppend”方法 MsgHeartbeatResp MessageType = 9 // 表明请求没有被交付； // 当“MsgUnreachable”被传送到leader的Step方法，leader发现follower无法到达，很有可能“MsgApp”都丢失了。当follower的进度状态为复制时，leader设置它回probe（哨兵） MsgUnreachable MessageType = 10 // 表明快照安装消息的结果 // 当一个follower拒绝了“MsgSnap”，这显示快照请求失败了--因为网络原因；**leader认为follower成为哨兵了**?(Then leader considers follower\u0026#39;s progress as probe.)； // 当“MsgSnap”没有被拒绝，它表明快照成功了，leader设置follower的进度为哨兵，并恢复它的日志复制 MsgSnapStatus MessageType = 11 MsgCheckQuorum MessageType = 12 MsgTransferLeader MessageType = 13 MsgTimeoutNow MessageType = 14 MsgReadIndex MessageType = 15 MsgReadIndexResp MessageType = 16 // \u0026#34;MsgPreVote\u0026#34;和“MsgPreVoteResp”用在可选的两阶段选举协议上； // 当Config.PreVote为true，将会进行一次预选举，除非预选举表明竞争节点会赢，否则没有节点会增加它们的term值。 // 这最小化了**一个发生了分区的节点重新加入到集群时**会带来的中断/干扰 MsgPreVote MessageType = 17 MsgPreVoteResp MessageType = 18 ) raft, Node and RawNode # type Node interface { // ... } func StartNode(...) Node { rn, err := NewRawNode(...) if err != nil { panic(err) } n := newNode(rn) go n.run() return \u0026amp;n } func NewRawNode(config *Config) (*RawNode, error) { r := newRaft(config) rn := \u0026amp;RawNode{ raft: r, } ... return rn, nil } type node struct { // impl Node interface ... rn *RawNode } func newNode(rn *RawNode) node { return node{ ... } } 实现 # 使用 # 存储 # bbolt\n传输 # grpc\n"},{"id":49,"href":"/posts/2021/12/vscode-go-module/","title":"vscode-go在go.mod在非根目录情况下失效的问题","section":"12","content":"问题如图：\n解决：\n添加配置：\n{ // ... \u0026#34;gopls\u0026#34;: { \u0026#34;experimentalWorkspaceModule\u0026#34;: true }, // ... } 等go 1.18的workspace模式推出之后，应该就不需要配置这个了。\n参考\n"},{"id":50,"href":"/posts/2021/12/mqtt/","title":"mqtt","section":"12","content":" 物联网消息标准 # 官网\nIt is designed as an extremely lightweight publish/subscribe messaging transport that is ideal for connecting remote devices with a small code footprint and minimal network bandwidth.\n极其轻量的发布/订阅消息传输，使用小量代码脚本和极小网络带宽来连接远程设备。\n轻量 高效 双向 大规模（百万设备） 可靠 支持不可靠网络 安全 多个mqtt客户端连接到broker(译为：中间商)，围绕topic来实现发布/订阅操作，某些客户端向topic发布消息，某些客户端订阅topic上的消息，当broker接收到某个topic上的消息时，它会将消息转发到订阅了该topic的客户端。\nmqtt 5.0\nQoS # Quality of Service\ncontrol traffic and ensure the performance of critical applications with limited network capacity\n控制交通，确保有限网络容量下的应用性能。\nQoS（Quality of Service，服务质量）指一个网络能够利用各种基础技术，为指定的网络通信提供更好的服务能力，是网络的一种安全机制， 是用来解决网络延迟和阻塞等问题的一种技术。QoS 的保证对于容量有限的网络来说是十分重要的，特别是对于流多媒体应用，例如 VoIP 和 IPTV 等，因为这些应用常常需要固定的传输率，对延时也比较敏感。\n当网络发生拥塞的时候，所有的数据流都有可能被丢弃；为满足用户对不同应用不同服务质量的要求，就需要网络能根据用户的要求分配和调度资源，对不同的数据流提供不同的服务质量：\n对实时性强且重要的数据报文优先处理；对于实时性不强的普通数据报文，提供较低的处理优先级，网络拥塞时甚至丢弃。QoS 应运而生。支持 QoS 功能的设备，能够提供传输品质服务；针对某种类别的数据流，可以为它赋予某个级别的传输优先级，来标识它的相对重要性，并使用设备所提供的各种优先级转发策略、拥塞避免等机制为这些数据流提供特殊的传输服务。配置了 QoS 的网络环境，增加了网络性能的可预知性，并能够有效地分配网络带宽，更加合理地利用网络资源。\n百科参考\nMQTT QoS # MQTT 设计了一套保证消息稳定传输的机制，包括消息应答、存储和重传。在这套机制下，提供了三种不同层次 QoS（Quality of Service）：\nQoS0，At most once，至多一次；\u0026ndash; AMO QoS1，At least once，至少一次；\u0026ndash; ALO QoS2，Exactly once，确保只有一次。 \u0026ndash; EO QoS 是消息的发送方（Sender）和接受方（Receiver）之间达成的一个协议：\nQoS0 代表，Sender 发送的一条消息，Receiver 最多能收到一次，也就是说 Sender 尽力向 Receiver 发送消息，如果发送失败，也就算了； QoS1 代表，Sender 发送的一条消息，Receiver 至少能收到一次，也就是说 Sender 向 Receiver 发送消息，如果发送失败，会继续重试，直到 Receiver 收到消息为止，但是因为重传的原因，Receiver 有可能会收到重复的消息；\u0026ndash; 处理消息的方法做到幂等，就算消息重复也不怕了 QoS2 代表，Sender 发送的一条消息，Receiver 确保能收到而且只收到一次，也就是说 Sender 尽力向 Receiver 发送消息，如果发送失败，会继续重试，直到 Receiver 收到消息为止，同时保证 Receiver 不会因为消息重传而收到重复的消息。 参考\nGo 库 # Go 实现的支持集群的高性能的 MQTT 库\n支持 MQTT 版本：3.1.1 go.mod # 看下它依赖了什么：\nmodule github.com/fhmq/hmq go 1.12 require ( github.com/Shopify/sarama v1.23.0 // Kafka的Go客户端 github.com/bitly/go-simplejson v0.5.0 github.com/bmizerany/assert v0.0.0-20160611221934-b7ed37b82869 // indirect github.com/eapache/queue v1.1.0 github.com/eclipse/paho.mqtt.golang v1.2.0 // 另一个mqtt的golang库 github.com/gin-gonic/gin v1.7.0 github.com/google/uuid v1.1.1 github.com/kr/pretty v0.1.0 // indirect github.com/modern-go/concurrent v0.0.0-20180306012644-bacd9c7ef1dd // indirect github.com/modern-go/reflect2 v1.0.1 // indirect github.com/patrickmn/go-cache v2.1.0+incompatible github.com/pkg/errors v0.8.1 // indirect github.com/segmentio/fasthash v0.0.0-20180216231524-a72b379d632e github.com/stretchr/testify v1.4.0 github.com/tidwall/gjson v1.9.3 go.uber.org/atomic v1.4.0 // indirect go.uber.org/multierr v1.1.0 // indirect go.uber.org/zap v1.10.0 golang.org/x/net v0.0.0-20190724013045-ca1201d0de80 gopkg.in/check.v1 v1.0.0-20180628173108-788fd7840127 // indirect gopkg.in/jcmturner/goidentity.v3 v3.0.0 // indirect Standard interface for holding authenticated identities and their attributes. ) 示例 # TODO:\n源码 # TODO:\n"},{"id":51,"href":"/posts/2021/12/redis_sds/","title":"redis sds","section":"12","content":" 简单动态字符串 # 结构：\nlen alloc flag buf 长度(已使用空间大小) 分配(总共空间大小：buf 的大小减 1 \u0026ndash; \u0026lsquo;\\0\u0026rsquo;字符占用了 1) 标记(sdshdr 的类型) 真正存储字符串的地方 文件：\nsds.h, sdsalloc.h, sds.c.\n定义：\ntypedef char *sds; 根据类型获取长度：\nstatic inline size_t sdslen(const sds s) { unsigned char flags = s[-1]; switch(flags\u0026amp;SDS_TYPE_MASK) { case SDS_TYPE_5: return SDS_TYPE_5_LEN(flags); case SDS_TYPE_8: return SDS_HDR(8,s)-\u0026gt;len; case SDS_TYPE_16: return SDS_HDR(16,s)-\u0026gt;len; case SDS_TYPE_32: return SDS_HDR(32,s)-\u0026gt;len; case SDS_TYPE_64: return SDS_HDR(64,s)-\u0026gt;len; } return 0; } 新建：\n/* Create a new sds string with the content specified by the \u0026#39;init\u0026#39; pointer * and \u0026#39;initlen\u0026#39;. * If NULL is used for \u0026#39;init\u0026#39; the string is initialized with zero bytes. * If SDS_NOINIT is used, the buffer is left uninitialized; * * The string is always null-termined (all the sds strings are, always) so * even if you create an sds string with: * * mystring = sdsnewlen(\u0026#34;abc\u0026#34;,3); * * You can print the string with printf() as there is an implicit \\0 at the * end of the string. However the string is binary safe and can contain * \\0 characters in the middle, as the length is stored in the sds header. */ // sds的头部存储了它的长度 sds _sdsnewlen(const void *init, size_t initlen, int trymalloc) { void *sh; // sds的header sds s; char type = sdsReqType(initlen); // 根据size大小返回类型 /* Empty strings are usually created in order to append. Use type 8 * since type 5 is not good at this. */ if (type == SDS_TYPE_5 \u0026amp;\u0026amp; initlen == 0) type = SDS_TYPE_8; int hdrlen = sdsHdrSize(type); // 根据类型返回header长度 unsigned char *fp; /* flags pointer. */ size_t usable; // 可用的内存大小 assert(initlen + hdrlen + 1 \u0026gt; initlen); /* Catch size_t overflow */ sh = trymalloc? s_trymalloc_usable(hdrlen+initlen+1, \u0026amp;usable) : s_malloc_usable(hdrlen+initlen+1, \u0026amp;usable); // 三元运算符，根据trymalloc的值选择用哪个alloc函数，分配后，还会标志可用内存大小 if (sh == NULL) return NULL; // 分配失败返回NULL if (init==SDS_NOINIT) init = NULL; else if (!init) memset(sh, 0, hdrlen+initlen+1); s = (char*)sh+hdrlen; // 将sh转为char*，赋值给最终字符串s fp = ((unsigned char*)s)-1; usable = usable-hdrlen-1; if (usable \u0026gt; sdsTypeMaxSize(type)) usable = sdsTypeMaxSize(type); switch(type) { // 根据类型决定对s做不同的sds hdr操作 case SDS_TYPE_5: { *fp = type | (initlen \u0026lt;\u0026lt; SDS_TYPE_BITS); break; } case SDS_TYPE_8: { SDS_HDR_VAR(8,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = usable; *fp = type; break; } case SDS_TYPE_16: { SDS_HDR_VAR(16,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = usable; *fp = type; break; } case SDS_TYPE_32: { SDS_HDR_VAR(32,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = usable; *fp = type; break; } case SDS_TYPE_64: { SDS_HDR_VAR(64,s); sh-\u0026gt;len = initlen; sh-\u0026gt;alloc = usable; *fp = type; break; } } if (initlen \u0026amp;\u0026amp; init) memcpy(s, init, initlen); // 复制initlen的init内容到s s[initlen] = \u0026#39;\\0\u0026#39;; return s; } 引用 1\n"},{"id":52,"href":"/posts/2021/12/k8s/","title":"k8s","section":"12","content":" What # docker 带来容器之风，以致容器多不胜数。如何编排和管理众多容器，使得它们同心协力办好事情，即成为了当下最大的课题。\n为此，k8s 应运而生。\n容器，通讯，存储，配置。\nWhy # 为编排和管理数量众多的容器。\nHow # Install # k8s: 集群搭建所需资源 # One or more machines running one of:\nUbuntu 16.04+\nDebian 9+\nCentOS 7+\nRed Hat Enterprise Linux (RHEL) 7+\nFedora 25+\nHypriotOS v1.0.1+\nFlatcar Container Linux (tested with 2512.3.0)\n2 GB or more of RAM per machine (any less will leave little room for your apps).\n2 CPUs or more.\nFull network connectivity between all machines in the cluster (public or private network is fine).\nUnique hostname, MAC address, and product_uuid for every node. See here for more details.\nCertain ports are open on your machines. See here for more details.\nSwap disabled. You MUST disable swap in order for the kubelet to work properly.\n参考官方文档\n本地机器起多个虚拟机搭建 # 使用 virtualBox 创建三台虚拟机 # 1.用 NAT 和 host only 网络模式\nvirtualBox 安装比较简单，不再介绍，GUI 工具用起来也很方便，这部分只介绍我认为需要提示的部分。\n内存推荐 2048M, CPU 推荐 2 个\n默认只有一个 NAT 适配器，添加一个 Host-Only Adapter。NAT 适配器是虚拟机用来访问互联网的，Host-Only 适配器是用来虚拟机之间通信的。\n以 Normal Start 方式启动虚拟机安装完系统以后，因为是 server 版镜像，所以没有图形界面，直接使用用户名密码登录即可。\n修改配置，enp0s8 使用静态 IP。配置请参考 SSH between Mac OS X host and Virtual Box guest。注意配置时将其中的网络接口名改成你自己的 Host-Only Adapter 对应的接口。\n一台虚拟机创建完成以后可以使用 clone 方法复制出两台节点出来，注意 clone 时为新机器的网卡重新初始化 MAC 地址。\n三台虚拟机的静态 IP 都配置好以后就可以使用 ssh 在本地主机的终端上操作三台虚机了。虚机使用 Headless Start 模式启动\n参照\n参照 2\n2.用桥接网络模式\nvm: 虚拟机上安装 k8s\n先添加 key：https_proxy=http://192.168.56.1:51837 curl -s -v https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -\n然后添加 source：\ncat \u0026lt;\u0026lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list deb https://apt.kubernetes.io/ kubernetes-xenial main EOF 最后更新：sudo apt -o Acquire::http::proxy=\u0026quot;http://192.168.56.1:51837\u0026quot; update\nkubeadm\n安装：sudo apt -o Acquire::https::proxy=\u0026quot;http://192.168.56.1:51837\u0026quot; install -y kubeadm\nkubelet\n安装：sudo apt -o Acquire::https::proxy=\u0026quot;http://192.168.56.1:51837\u0026quot; install -y kubelet\nkubectl\n安装：sudo apt -o Acquire::https::proxy=\u0026quot;http://192.168.56.1:51837\u0026quot; install -y kubectl\ndocker\n参照\n从上面的参照可以看到除了 docker 之外，还可以选择其它运行时。\nk8s: 三个工具\nkubeadm\n作用：用来初始化集群的指令。\n使用：\n在一台机器上执行kubeadm init，初始化集群，该机器作为集群 master；初始化成功后会返回\u0026lt;arguments-returned-from-init\u0026gt;，作为其它机器加入该集群的参数 。\n在另一台机器上执行kubeadm join \u0026lt;arguments-returned-from-init\u0026gt;。\n如果想添加更多机器，请重复kubeadm join指令。\nkubelet\n作用：在集群中的每个节点上用来启动 Pod 和容器等。\n在每个节点上运行的节点代理。它可以向 apiserver 注册节点。\nThe kubelet works in terms of a PodSpec. A PodSpec is a YAML or JSON object that describes a pod.\n\u0026ndash; kubelet 在一系列 pod 规范里工作。一个 pod 规范是一个描述 pod 的 yaml 或 json 对象。\nkubectl\n作用：用来与集群通信的命令行工具。\n创建资源，暴露服务。\n参照\nk8s: 初始化集群 # 关闭 swap 交换空间 # 执行命令：sudo swapoff -a，并将文件/etc/fstab里关于 swap 的行注释掉，然后重启机器\n为什么要关闭呢？\nissue 上的讨论 1\nissue 上的讨论 2\nhaving swap available has very strange and bad interactions with memory limits\nkubernetes 的想法是将实例紧密包装到尽可能接近 100％。 所有的部署应该与 CPU /内存限制固定在一起。 所以如果调度程序发送一个 pod 到一台机器，它不应该使用交换。 设计者不想交换，因为它会减慢速度。\n所以关闭 swap 主要是为了性能考虑。\n当然为了一些节省资源的场景，比如运行容器数量较多，可添加 kubelet 参数 \u0026ndash;fail-swap-on=false 来解决。\n初始化 # 先通过命令sudo kubeadm config print init-defaults \u0026gt; init-default.yaml生成默认配置文件。\n在生成的 yaml 配置文件里修改:\nadvertiseAddress: 192.168.9.43，其中的 ip 地址为ip a拿到的地址。\nnetworking: dnsDomain: cluster.local podSubnet: 10.46.128.0/21 # 这个 ip 将要用在安装成功后的 pod network 配置里。 serviceSubnet: 192.168.1.0/24\n然后在初始化命令使用该配置文件：sudo kubeadm init --config=init-default.yaml --v=5\n出现警告：\n[preflight] Running pre-flight checks\n[WARNING IsDockerSystemdCheck]: detected \u0026ldquo;cgroupfs\u0026rdquo; as the Docker cgroup driver. The recommended driver is \u0026ldquo;systemd\u0026rdquo;. Please follow the guide at https://kubernetes.io/docs/setup/cri/\n里面说到 cgroup 驱动用了 cgroupfs，而不是 systemd。可参照 官方文档修改设置。\n然后会到k8s.gcr.io获取镜像，这时又出现超时错误。应该是墙导致的，需要使用代理或 改用镜像站。\n镜像站也关掉了，怎么办？\n使用 docker 拉取镜像，然后修改 tag：\n先看所需镜像：sudo kubeadm config images list\nk8s.gcr.io/kube-apiserver:v1.20.3\nk8s.gcr.io/kube-controller-manager:v1.20.3\nk8s.gcr.io/kube-scheduler:v1.20.3\nk8s.gcr.io/kube-proxy:v1.20.3\nk8s.gcr.io/pause:3.2\nk8s.gcr.io/etcd:3.4.13-0\nk8s.gcr.io/coredns:1.7.0\n逐个从 docker hub 上搜到并获取镜像：sudo docker pull aiotceo/kube-apiserver:v1.20.3\nsudo docker pull aiotceo/kube-apiserver:v1.20.3\nsudo docker pull aiotceo/kube-controller-manager:v1.20.3\nsudo docker pull aiotceo/kube-scheduler:v1.20.3\nsudo docker pull aiotceo/kube-proxy:v1.20.3\nsudo docker pull aiotceo/pause:3.2\nsudo docker pull bitnami/etcd:3.4.13\nsudo docker pull aiotceo/coredns:1.7.0\n修改 tag：sudo docker tag aiotceo/kube-apiserver:v1.20.3 k8s.gcr.io/kube-apiserver:v1.20.3\n最后删除：sudo docker rmi aiotceo/kube-apiserver:v1.20.3\n[preflight] You can also perform this action in beforehand using \u0026lsquo;kubeadm config images pull\u0026rsquo;\n\u0026ndash; 拉取镜像也可以提前使用kubeadm config images pull完成。\nkubelet 未启动错误：\n[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory \u0026ldquo;/etc/kubernetes/manifests\u0026rdquo;. This can take up to 4m0s I0218 09:29:21.630514 98836 request.go:943] Got a Retry-After 1s response for attempt 1 to https://10.0.2.15:6443/healthz?timeout=10s \u0026gt; [kubelet-check] Initial timeout of 40s passed. I0218 09:29:43.755024 98836 request.go:943] Got a Retry-After 1s response for attempt 1 to https://10.0.2.15:6443/healthz?timeout=10s I0218 09:30:21.758311 98836 request.go:943] Got a Retry-After 1s response for attempt 1 to https://10.0.2.15:6443/healthz?timeout=10s I0218 09:32:24.612682 98836 request.go:943] Got a Retry-After 1s response for attempt 1 to https://10.0.2.15:6443/healthz?timeout=10s\nUnfortunately, an error has occurred: timed out waiting for the condition This error is likely caused by: - The kubelet is not running - The kubelet is unhealthy due to a misconfiguration of the node in some way (required cgroups disabled) If you are on a systemd-powered system, you can try to troubleshoot the error with the following commands: - \u0026#39;systemctl status kubelet\u0026#39; - \u0026#39;journalctl -xeu kubelet\u0026#39; Additionally, a control plane component may have crashed or exited when started by the container runtime. To troubleshoot, list all containers using your preferred container runtimes CLI. Here is one example how you may list all Kubernetes containers running in docker: - \u0026#39;docker ps -a | grep kube | grep -v pause\u0026#39; Once you have found the failing container, you can inspect its logs with: - \u0026#39;docker logs CONTAINERID\u0026#39; 原来是在关闭了 swap 后要重启\n初始化过程中报错了之后需要重置一下才行：sudo kubeadm reset --v=5\n否则会报错：\n[preflight] Some fatal errors occurred:\n[ERROR Port-10259]: Port 10259 is in use [ERROR Port-10257]: Port 10257 is in use [ERROR FileAvailable--etc-kubernetes-manifests-kube-apiserver.yaml]: /etc/kubernetes/manifests/kube-apiserver.yaml already exists [ERROR FileAvailable--etc-kubernetes-manifests-kube-controller-manager.yaml]: /etc/kubernetes/manifests/kube-controller-manager.yaml already exists [ERROR FileAvailable--etc-kubernetes-manifests-kube-scheduler.yaml]: /etc/kubernetes/manifests/kube-scheduler.yaml already exists [ERROR FileAvailable--etc-kubernetes-manifests-etcd.yaml]: /etc/kubernetes/manifests/etcd.yaml already exists [ERROR Port-10250]: Port 10250 is in use [preflight] If you know what you are doing, you can make a check non-fatal with `--ignore-preflight-errors=...` error execution phase preflight 查看kubelet日志：journalctl -xeu kubelet\nFailed to connect to 10.0.2.15 port 6443: Connection refused:\n除了防火墙和 swap，还要关闭 selinux\n查看防火墙状态：systemctl status firewalld\n临时关闭 selinux：\nsudo setenforce 0\n永久关闭：\n执行sestatus查看 selinux 状态，需要先安装工具sudo apt install policycoreutils\n查看后，再去编辑配置文件sudo vim /etc/selinux/config，改为SELINUX=disabled\n需要翻墙的情况下\n修改 docker 的 cgroup driver 为 systemd # 为了确保 docker 和 kubelet 的 cgroup driver 一样，需要将 docker 的 cgroup driver 改为 systemd。\n查看：sudo docker info，发现Cgroup Driver: cgroupfs\n修改：sudo vim /etc/docker/daemon.json，添加以下内容：\n{ \u0026#34;exec-opts\u0026#34;: [\u0026#34;native.cgroupdriver=systemd\u0026#34;] } 重启：sudo systemctl daemon-reload sudo systemctl restart docker\n再次查看 docker info，会看到Cgroup Driver: systemd\nkubectl # 执行sudo kubelet时出现错误：\nfailed to get the kubelet\u0026rsquo;s cgroup: cpu and memory cgroup hierarchy not unified. cpu: /user.slice, memory: /user.slice/user-1000.slice/session-1.scope. Kubelet system container metrics may be missing.\n难道是不能这样直接执行，需要用 systemctl 来执行：sudo systemctl start kubelet.service\n通过查看sudo cat /etc/systemd/system/kubelet.service.d/10-kubeadm.conf配置文件，发现里面有很多 env 设置。\n在/etc/systemd/system/kubelet.service.d/10-kubeadm.conf配置文件里添加--cgroup-driver=systemd配置。\n是不是虚拟机创建时选择的网卡错了（用了 NAT 和 host only），导致上面的这么多问题呢？\n换成 NAT network 或者桥接试下。\nWith bridged networking, Oracle VM VirtualBox uses a device driver on your host system that filters data from your physical network adapter. This driver is therefore called a net filter driver. This enables Oracle VM VirtualBox to intercept data from the physical network and inject data into it, effectively creating a new network interface in software. When a guest is using such a new software interface, it looks to the host system as though the guest were physically connected to the interface using a network cable. The host can send data to the guest through that interface and receive data from it. This means that you can set up routing or bridging between the guest and the rest of your network.\nvbox 官方文档关于网卡的介绍\n成功 # 成功后会有以下信息：\n其中需要注意部分信息是需要执行的命令，还有其它节点添加到集群时需要用到的信息。\n[addons] Applied essential addon: CoreDNS [addons] Applied essential addon: kube-proxy Your Kubernetes control-plane has initialized successfully! To start using your cluster, you need to run the following as a regular user: mkdir -p $HOME/.kube sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config sudo chown $(id -u):$(id -g) $HOME/.kube/config Alternatively, if you are the root user, you can run: export KUBECONFIG=/etc/kubernetes/admin.conf You should now deploy a pod network to the cluster. Run \u0026#34;kubectl apply -f [podnetwork].yaml\u0026#34; with one of the options listed at: https://kubernetes.io/docs/concepts/cluster-administration/addons/ Then you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.9.43:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:5660805073db31916952821a8751ca0ee0644ce4205f616805f8a7f175ff8b33 添加 pod network：\n下载配置文件：wget https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml\n编辑配置：修改\nnet-conf.json: |\n{ \u0026ldquo;Network\u0026rdquo;: \u0026ldquo;10.46.128.0/21\u0026rdquo;, # 这个地址要与 kubeadm 指定的配置文件里的 podSubnet 里的 ip 一致 \u0026ldquo;Backend\u0026rdquo;: { \u0026ldquo;Type\u0026rdquo;: \u0026ldquo;vxlan\u0026rdquo; } }\n最后执行命令: kubectl apply -f kube-flannel.yml\n最后，查看 pods 状态：kubectl get pods --all-namespaces\njd@jnode:~$ kubectl get pods --all-namespaces NAMESPACE NAME READY STATUS RESTARTS AGE kube-system coredns-74ff55c5b-f76bb 1/1 Running 0 5m52s kube-system coredns-74ff55c5b-frgkw 1/1 Running 0 5m52s kube-system etcd-jnode 1/1 Running 0 6m8s kube-system kube-apiserver-jnode 1/1 Running 0 6m8s kube-system kube-controller-manager-jnode 1/1 Running 0 6m8s kube-system kube-flannel-ds-xghcx 1/1 Running 0 4m4s kube-system kube-proxy-nnbbx 1/1 Running 0 5m52s kube-system kube-scheduler-jnode 1/1 Running 0 6m8s 全部正常运行，完成。\n错误 # k8s 的安装过程，可谓是一波三折。下面整理一下遇到的错误：\nError registering network: failed to acquire lease: node \u0026ldquo;nodeName\u0026rdquo; pod cidr not assigned 确保 Network 的值与 podSubnet 一致即可。\n添加 worker 节点 # 在初始化完成后的输出信息里有：\nThen you can join any number of worker nodes by running the following on each as root: kubeadm join 192.168.9.43:6443 --token abcdef.0123456789abcdef \\ --discovery-token-ca-cert-hash sha256:5660805073db31916952821a8751ca0ee0644ce4205f616805f8a7f175ff8b33 这个命令就是 worker 要加入集群时需要执行的命令。\n在执行上述命令之前，需要 重新生成 token 和 hash:\n# 重新生成新的token kubeadm token create kubeadm token list # 获取ca证书sha256编码hash值，拿到的hash值要记录下来 openssl x509 -pubkey -in /etc/kubernetes/pki/ca.crt | openssl rsa -pubin -outform der 2\u0026gt;/dev/null | openssl dgst -sha256 -hex | sed \u0026#39;s/^.* //\u0026#39; # 节点加入集群，token和hash值使用上面生成的 kubeadm join ip:6443 --token xxx --discovery-token-ca-cert-hash sha256:xxx 最后在主节点，执行：kubectl get nodes查看已加入的节点。\n重启之后要等一会才会正常：\n$ kubectl get nodes The connection to the server 192.168.9.43:6443 was refused - did you specify the right host or port? 如果没有执行export KUBECONFIG=/etc/kubernetes/admin.conf，那么在使用 kubectl 命令时就不能在前面加 sudo 了。\n在主节点成功看到 worker node 之后，还需要将主节点里的~/.kube/config文件复制到 worker node 上：\n# 在主节点上使用scp将配置文件复制到worker scp ~/.kube/config xx@xxx.xxx.xxx.xxx:~/.kube/config 否则会报错：\nkubectl describe node The connection to the server localhost:8080 was refused - did you specify the right host or port? 复制配置到 worker 后，在 worker 节点上执行kubectl describe node，就能看到节点信息。\n参照\nk8s: 初始化配置文件 # init-default.yaml # apiVersion: kubeadm.k8s.io/v1beta2 bootstrapTokens: - groups: - system:bootstrappers:kubeadm:default-node-token token: abcdef.0123456789abcdef ttl: 24h0m0s usages: - signing - authentication kind: InitConfiguration localAPIEndpoint: advertiseAddress: 192.168.9.43 # 本机的ip地址，可通过`ip a`获取 bindPort: 6443 nodeRegistration: criSocket: /var/run/dockershim.sock name: jnode taints: - effect: NoSchedule key: node-role.kubernetes.io/master --- apiServer: timeoutForControlPlane: 4m0s apiVersion: kubeadm.k8s.io/v1beta2 certificatesDir: /etc/kubernetes/pki clusterName: kubernetes controllerManager: {} dns: type: CoreDNS etcd: local: dataDir: /var/lib/etcd imageRepository: k8s.gcr.io kind: ClusterConfiguration kubernetesVersion: v1.20.0 networking: dnsDomain: cluster.local podSubnet: 10.46.128.0/21 # pod subnet值需要与kube-flannel.yml里的网络设置一致 serviceSubnet: 192.168.1.0/24 # 跟本机ip同一网段 scheduler: {} kube-flannel.yml # --- apiVersion: policy/v1beta1 kind: PodSecurityPolicy metadata: name: psp.flannel.unprivileged annotations: seccomp.security.alpha.kubernetes.io/allowedProfileNames: docker/default seccomp.security.alpha.kubernetes.io/defaultProfileName: docker/default apparmor.security.beta.kubernetes.io/allowedProfileNames: runtime/default apparmor.security.beta.kubernetes.io/defaultProfileName: runtime/default spec: privileged: false volumes: - configMap - secret - emptyDir - hostPath allowedHostPaths: - pathPrefix: \u0026#34;/etc/cni/net.d\u0026#34; - pathPrefix: \u0026#34;/etc/kube-flannel\u0026#34; - pathPrefix: \u0026#34;/run/flannel\u0026#34; readOnlyRootFilesystem: false # Users and groups runAsUser: rule: RunAsAny supplementalGroups: rule: RunAsAny fsGroup: rule: RunAsAny # Privilege Escalation allowPrivilegeEscalation: false defaultAllowPrivilegeEscalation: false # Capabilities allowedCapabilities: [\u0026#34;NET_ADMIN\u0026#34;, \u0026#34;NET_RAW\u0026#34;] defaultAddCapabilities: [] requiredDropCapabilities: [] # Host namespaces hostPID: false hostIPC: false hostNetwork: true hostPorts: - min: 0 max: 65535 # SELinux seLinux: # SELinux is unused in CaaSP rule: \u0026#34;RunAsAny\u0026#34; --- kind: ClusterRole apiVersion: rbac.authorization.k8s.io/v1 metadata: name: flannel rules: - apiGroups: [\u0026#34;extensions\u0026#34;] resources: [\u0026#34;podsecuritypolicies\u0026#34;] verbs: [\u0026#34;use\u0026#34;] resourceNames: [\u0026#34;psp.flannel.unprivileged\u0026#34;] - apiGroups: - \u0026#34;\u0026#34; resources: - pods verbs: - get - apiGroups: - \u0026#34;\u0026#34; resources: - nodes verbs: - list - watch - apiGroups: - \u0026#34;\u0026#34; resources: - nodes/status verbs: - patch --- kind: ClusterRoleBinding apiVersion: rbac.authorization.k8s.io/v1 metadata: name: flannel roleRef: apiGroup: rbac.authorization.k8s.io kind: ClusterRole name: flannel subjects: - kind: ServiceAccount name: flannel namespace: kube-system --- apiVersion: v1 kind: ServiceAccount metadata: name: flannel namespace: kube-system --- kind: ConfigMap apiVersion: v1 metadata: name: kube-flannel-cfg namespace: kube-system labels: tier: node app: flannel data: cni-conf.json: | { \u0026#34;name\u0026#34;: \u0026#34;cbr0\u0026#34;, \u0026#34;cniVersion\u0026#34;: \u0026#34;0.3.1\u0026#34;, \u0026#34;plugins\u0026#34;: [ { \u0026#34;type\u0026#34;: \u0026#34;flannel\u0026#34;, \u0026#34;delegate\u0026#34;: { \u0026#34;hairpinMode\u0026#34;: true, \u0026#34;isDefaultGateway\u0026#34;: true } }, { \u0026#34;type\u0026#34;: \u0026#34;portmap\u0026#34;, \u0026#34;capabilities\u0026#34;: { \u0026#34;portMappings\u0026#34;: true } } ] } net-conf.json: | { \u0026#34;Network\u0026#34;: \u0026#34;10.46.128.0/21\u0026#34;, # 与init-default.yaml配置文件里的podSubnet值一致 \u0026#34;Backend\u0026#34;: { \u0026#34;Type\u0026#34;: \u0026#34;vxlan\u0026#34; } } --- apiVersion: apps/v1 kind: DaemonSet metadata: name: kube-flannel-ds namespace: kube-system labels: tier: node app: flannel spec: selector: matchLabels: app: flannel template: metadata: labels: tier: node app: flannel spec: affinity: nodeAffinity: requiredDuringSchedulingIgnoredDuringExecution: nodeSelectorTerms: - matchExpressions: - key: kubernetes.io/os operator: In values: - linux hostNetwork: true priorityClassName: system-node-critical tolerations: - operator: Exists effect: NoSchedule serviceAccountName: flannel initContainers: - name: install-cni image: quay.io/coreos/flannel:v0.13.1-rc2 command: - cp args: - -f - /etc/kube-flannel/cni-conf.json - /etc/cni/net.d/10-flannel.conflist volumeMounts: - name: cni mountPath: /etc/cni/net.d - name: flannel-cfg mountPath: /etc/kube-flannel/ containers: - name: kube-flannel image: quay.io/coreos/flannel:v0.13.1-rc2 command: - /opt/bin/flanneld args: - --ip-masq - --kube-subnet-mgr resources: requests: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; limits: cpu: \u0026#34;100m\u0026#34; memory: \u0026#34;50Mi\u0026#34; securityContext: privileged: false capabilities: add: [\u0026#34;NET_ADMIN\u0026#34;, \u0026#34;NET_RAW\u0026#34;] env: - name: POD_NAME valueFrom: fieldRef: fieldPath: metadata.name - name: POD_NAMESPACE valueFrom: fieldRef: fieldPath: metadata.namespace volumeMounts: - name: run mountPath: /run/flannel - name: flannel-cfg mountPath: /etc/kube-flannel/ volumes: - name: run hostPath: path: /run/flannel - name: cni hostPath: path: /etc/cni/net.d - name: flannel-cfg configMap: name: kube-flannel-cfg kubeadm_join.sh # #!/bin/bash sudo kubeadm join ip:6443 --token wxjhuh.z9ru6bbz990m7v0i --discovery-token-ca-cert-hash sha256:8809f1cc27401d704faa104008a48034b51e8e5ef8f4a8f33f0e267db0124a2f 一些问题 # 1.k8s: reset 后出现 coredns 一直处于 ContainerCreating 状态\n解决方法 1\n2.k8s: connet to localhost:8080 failed\nkubeadm init 成功后，执行sudo kubectl apply -f kube-flannel.yml，出现错误：\nThe connection to the server localhost:8080 was refused - did you specify the right host or port? issue\n原来是因为没有执行export KUBECONFIG=/etc/kubernetes/admin.conf命令的时候使用 kubectl 是不能在前面加 sudo 的。\n所以，直接执行kubectl apply -f kube-flannel.yml就正常了。\n基于 wsl2 搭建 # 基于 wsl2 搭建\nDeploy # k8s: 部署应用之 deployment service pod\n问题 1 # 在创建 deployment 时，如果想从本地获取镜像，需要将 yaml 配置文件里的imagePullPolicy，镜像拉取机制，从Always改为IfNotPresent。\n问题 2 # 怎么让 pod 里的应用访问到非集群内部的本机数据库实例呢？\n通过新建一个 service，指定为type:ExternalName或Endpoints，并把想要访问的数据库实例信息写到配置上。\n参照 1\n参照 2\n参照 3\n参照 4\n参照 5\n解决：在本机的数据库貌似不能访问到，只好在另外的虚拟机上安装 db，然后配置该虚拟机的 ip 地址到 endpoint。\n使用 service 将应用暴露到公网 # # 针对deployment hello-world以NodePort方式、example-service名称、端口是port-value暴露应用到公网 kubectl expose deployment hello-world --type=NodePort --name=example-service -- port=port-value 通过公网访问时，需要先使用kubectl describe svc拿到 example-service 服务的 NodePort 值，再结合机器自身的 ip 地址，组成 ip:NodePort 值访问，如： http://192.168.9.16:32256/。\njd@wnode1:~/Project/jdnote$ kubectl describe svc Name: jdnote-server-service Namespace: default Labels: app=jdnote-server Annotations: \u0026lt;none\u0026gt; Selector: app=jdnote-server Type: NodePort IP Families: \u0026lt;none\u0026gt; IP: 192.168.1.198 IPs: 192.168.1.198 Port: \u0026lt;unset\u0026gt; 8890/TCP TargetPort: 8890/TCP NodePort: \u0026lt;unset\u0026gt; 32256/TCP # 这个值作为端口 Endpoints: 10.46.129.11:8890 Session Affinity: None External Traffic Policy: Cluster Events: \u0026lt;none\u0026gt; jd@wnode1:~/Project/jdnote$ ip a 1: lo: \u0026lt;LOOPBACK,UP,LOWER_UP\u0026gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000 link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00 inet 127.0.0.1/8 scope host lo valid_lft forever preferred_lft forever inet6 ::1/128 scope host valid_lft forever preferred_lft forever 2: enp0s3: \u0026lt;BROADCAST,MULTICAST,UP,LOWER_UP\u0026gt; mtu 1500 qdisc fq_codel state UP group default qlen 1000 link/ether 08:00:27:cf:aa:13 brd ff:ff:ff:ff:ff:ff inet 192.168.9.16/24 brd 192.168.9.255 scope global dynamic enp0s3 # 192.168.9.16作为ip valid_lft 9843sec preferred_lft 9843sec inet6 fe80::a00:27ff:fecf:aa13/64 scope link valid_lft forever preferred_lft forever 参照\n网络介绍\nk8s: ingress # k8s: ingress\n让外网能访问到 k8s 里的应用。\n单个服务：\napiVersion: networking.k8s.io/v1 kind: Ingress # kind必须指定为ingress metadata: name: minimal-ingress # 名称 annotations: # 注解 nginx.ingress.kubernetes.io/rewrite-target: / spec: rules: # 规则 - http: paths: # 路径 - path: /testpath pathType: Prefix backend: # 重定向到service service: name: test # 必须存在test service port: number: 80 # service的端口 多个服务：\napiVersion: networking.k8s.io/v1 kind: Ingress metadata: name: ingress-wildcard-host spec: rules: - host: \u0026#34;foo.bar.com\u0026#34; # 域名，表示该域名的流量将被转到配置的service http: paths: - pathType: Prefix path: \u0026#34;/bar\u0026#34; backend: service: name: service1 port: number: 80 - host: \u0026#34;*.foo.com\u0026#34; http: paths: - pathType: Prefix path: \u0026#34;/foo\u0026#34; backend: service: name: service2 port: number: 80 查看：kubectl describe ingress minimal-ingress\n可选 ingress 控制器\nIngress 只是 Kubernetes 中的一种配置信息；Ingress Controller 才是监听 80/443 端口，并根据 Ingress 上配置的路由信息执行 HTTP 路由转发的组件。\ntraefik 提供的 k8s 控制器\n使用 traefik\nlist-watch 模式 # 来源\n谈谈 List-Watch 的设计理念\n当设计优秀的一个异步消息的系统时，对消息机制有至少如下四点要求：\n消息可靠性\n消息实时性\n消息顺序性\n高性能\n首先消息必须是可靠的，list 和 watch 一起保证了消息的可靠性，避免因消息丢失而造成状态不一致场景。\n具体而言，list API 可以查询当前的资源及其对应的状态(即期望的状态)，客户端通过拿期望的状态和实际的状态进行对比，纠正状态不一致的资源。Watch API 和 apiserver 保持一个长链接，接收资源的状态变更事件并做相应处理。如果仅调用 watch API，若某个时间点连接中断，就有可能导致消息丢失，所以需要通过 list API 解决消息丢失的问题。从另一个角度出发，我们可以认为 list API 获取全量数据，watch API 获取增量数据。虽然仅仅通过轮询 list API，也能达到同步资源状态的效果，但是存在开销大，实时性不足的问题。\n消息必须是实时的，list-watch 机制下，每当 apiserver 的资源产生状态变更事件，都会将事件及时的推送给客户端，从而保证了消息的实时性。\n消息的顺序性也是非常重要的，在并发的场景下，客户端在短时间内可能会收到同一个资源的多个事件，对于关注最终一致性的 K8S 来说，它需要知道哪个是最近发生的事件，并保证资源的最终状态如同最近事件所表述的状态一样。K8S 在每个资源的事件中都带一个 resourceVersion 的标签，这个标签是递增的数字，所以当客户端并发处理同一个资源的事件时，它就可以对比 resourceVersion 来保证最终的状态和最新的事件所期望的状态保持一致。\nList-watch 还具有高性能的特点，虽然仅通过周期性调用 list API 也能达到资源最终一致性的效果，但是周期性频繁的轮询大大的增大了开销，增加 apiserver 的压力。而 watch 作为异步消息通知机制，复用一条长链接，保证实时性的同时也保证了性能。\n调试 # golang: dlv 调试 k8s 容器里的 go 进程\n使用容器 exec 进行调试 # 如果 容器镜像 包含调试程序(dlv, gdb)， 比如从 Linux 和 Windows 操作系统基础镜像构建的镜像，你可以使用 kubectl exec 命令 在特定的容器中运行一些命令：\nkubectl exec ${POD_NAME} -c ${CONTAINER_NAME} -- ${CMD} ${ARG1} ${ARG2} ... ${ARGN}\n说明： -c ${CONTAINER_NAME} 是可选择的。如果 Pod 中仅包含一个容器，就可以忽略它。\n例如，要查看正在运行的 Cassandra pod 中的日志，可以运行：\nkubectl exec cassandra -- cat /var/log/cassandra/system.log\n你可以在 kubectl exec 命令后面加上 -i 和 -t 来运行一个连接到你的终端的 Shell，比如：\nkubectl exec -it cassandra -- sh\n参照 1\n参照 2\n尝试 # $ kubectl exec -it skm-7fb6bd989c-kg9xj -n skm-system -- sh # 使用 kubectl 进入容器的 sh 界面 sh-4.4# dlv exec /root/Project/rancher/bin/rancher # exec 报错：版本太旧 Version of Delve is too old for this version of Go (maximum supported version 1.13, suppress this error with --check-go-version=false) sh-4.4# dlv attach /root/Project/rancher/bin/rancher # attach 需要指定 pid Invalid pid: /root/Project/rancher/bin/rancher sh-4.4# dlv attach 653 # 通过 ps aux 拿到 pid Type \u0026#39;help\u0026#39; for list of commands. (dlv) dlv 使用\n"},{"id":53,"href":"/posts/2021/12/ddia/","title":"数据密集型应用设计","section":"12","content":" 第一章 可靠性、可扩展性、可维护性 # 数据密集型应用和计算密集型应用\n现今很多应用程序都是 数据密集型（data-intensive） 的，而非 计算密集型（compute-intensive） 的。因此CPU很少成为这类应用的瓶颈，更大的问题通常来自数据量、数据复杂性、以及数据的变更速度。\n数据密集型应用通常由标准组件构建而成，标准组件提供了很多通用的功能；例如，许多应用程序都需要：\n存储数据，以便自己或其他应用程序之后能再次找到 （数据库（database））\n记住开销昂贵操作的结果，加快读取速度（缓存（cache））\n允许用户按关键字搜索数据，或以各种方式对数据进行过滤（搜索索引（search indexes））\n向其他进程发送消息，进行异步处理（流处理（stream processing））\n定期处理累积的大批量数据（批处理（batch processing））\n对应可选的组件在我映像中可以有：\n数据库：mysql, postgresql\n缓存: redis, memcached\n搜索索引: elastic search, sonic, redis search\n流处理: kafka, redis stream\n批处理: linux cron, golang timer\n使用较小的通用组件创建了一个全新的、专用的数据系统。\n如何衡量一个系统的好坏 # 设计数据系统或服务时可能会遇到很多棘手的问题，例如：当系统出问题时，如何确保数据的正确性和完整性？当部分系统退化降级时，如何为客户提供始终如一的良好性能？当负载增加时，如何扩容应对？什么样的 API 才是好的 API？\n可靠性（Reliability）\n系统在困境（adversity）（硬件故障、软件故障、人为错误）中仍可正常工作（正确完成功能，并能达到期望的性能水准）。\n故障通常定义为系统的一部分状态偏离其标准，而失效则是系统作为一个整体停止向用户提供服务。故障的概率不可能降到零，因此最好设计容错机制以防因故障而导致失效。\n硬件错误的解决：为了减少系统的故障率，第一反应通常都是增加单个硬件的冗余度，例如：磁盘可以组建 RAID，服务器可能有双路电源和热插拔 CPU，数据中心可能有电池和柴油发电机作为后备电源，某个组件挂掉时冗余组件可以立刻接管。\n软件错误的解决：仔细考虑系统中的假设和交互；彻底的测试；进程隔离；允许进程崩溃并重启；测量、监控并分析生产环境中的系统行为。\n人为错误的解决：\n可扩展性（Scalability）\n有合理的办法应对系统的增长（数据量、流量、复杂性）\n可维护性（Maintainability）\n许多不同的人（工程师、运维）在不同的生命周期，都能高效地在系统上工作（使系统保持现有行为，并适应新的应用场景）。\n从人的角度看：可靠就是能共困苦，同富贵；可扩展就是学习能力强，心胸广阔；可维护就是对人对己无偏见、无特例。\n2PC（两阶段提交） # 2PC，two-phase commit，两阶段提交。\n一种用于实现跨多个节点的原子事务提交的算法，即确保所有节点提交或所有节点中止。\n2PC 使用一个通常不会出现在单节点事务中的新组件：协调者（coordinator）（也称为事务管理器（transaction manager））。\n正常情况下，2PC 事务以应用在多个数据库节点上读写数据开始。我们称这些数据库节点为参与者（participants）。\n当应用准备提交时，协调者开始阶段 1 ：它发送一个准备（prepare）请求到每个节点，询问它们是否能够提交。然后协调者会跟踪参与者的响应：\n如果所有参与者都回答“是”，表示它们已经准备好提交，那么协调者在阶段 2 发出提交（commit）请求，然后提交真正发生。\n如果任意一个参与者回复了“否”，则协调者在阶段 2 中向所有节点发送中止（abort）请求。\n那如果在阶段 2 有事务提交失败了呢？\n在两阶段提交的情况下，准备(prepare 阶段)请求和提交(commit 阶段)请求当然也可以轻易丢失。 2PC 又有什么不同呢？\n第十一章 流处理 # 先回忆了批处理的特点：即输入是有界的，即已知和有限的大小，所以批处理知道它何时完成输入的读取。\n实际上，很多数据是无界限的，因为它随着时间的推移而逐渐到达：你的用户在昨天和今天产生了数据，明天他们将继续产生更多的数据。除非你停业，否则这个过程永远都不会结束，所以数据集从来就不会以任何有意义的方式“完成”。\n因此，批处理程序必须将数据人为地分成固定时间段的数据块，例如，在每天结束时处理一天的数据，或者在每小时结束时处理一小时的数据。\n日常批处理中的问题是，输入的变更只会在一天之后的输出中反映出来，这对于许多急躁的用户来说太慢了。为了减少延迟，我们可以更频繁地运行处理 —— 比如说，在每秒钟的末尾 —— 或者甚至更连续一些，完全抛开固定的时间切片，当事件发生时就立即进行处理，这就是流处理（stream processing）背后的想法。\n在本章中，我们将把事件流（event stream）视为一种数据管理机制：无界限，增量处理，与上一章中批量数据相对应。\n原则上讲，文件或数据库就足以连接生产者和消费者：生产者将其生成的每个事件写入数据存储，且每个消费者定期轮询数据存储，检查自上次运行以来新出现的事件。这实际上正是批处理在每天结束时处理当天数据时所做的事情。\n但当我们想要进行低延迟的连续处理时，如果数据存储不是为这种用途专门设计的，那么轮询开销就会很大。轮询的越频繁，能返回新事件的请求比例就越低，而额外开销也就越高。相比之下，最好能在新事件出现时直接通知消费者。\n数据库在传统上对这种通知机制支持的并不好，关系型数据库通常有 触发器（trigger） ，它们可以对变化作出反应（如，插入表中的一行），但是它们的功能非常有限，并且在数据库设计中有些后顾之忧。相应的是，已经开发了专门的工具来提供事件通知。\n两个问题：\n如果生产者发送消息的速度比消费者能够处理的速度快会发生什么？\n如果节点崩溃或暂时脱机，会发生什么情况？ —— 是否会有消息丢失？\n命令和事件 # 事件溯源的哲学是仔细区分事件（event）和命令（command）。\n当来自用户的请求刚到达时，它一开始是一个命令：在这个时间点上它仍然可能可能失败，比如，因为违反了一些完整性条件。应用必须首先验证它是否可以执行该命令。\n如果验证成功并且命令被接受，则它变为一个持久化且不可变的事件。\n在事件生成的时刻，它就成为了事实（fact）。即使客户稍后决定更改或取消预订，他们之前曾预定了某个特定座位的事实仍然成立，而更改或取消是之后添加的单独的事件。\n"},{"id":54,"href":"/posts/2021/12/burn_cpu_use_golang/","title":"burn cpu use golang","section":"12","content":" 虚假的 burn # package main func fakeBurn() { for { } } 真正的 burn # package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;runtime\u0026#34; \u0026#34;time\u0026#34; ) var ( numBurn int updateInterval int ) func cpuBurn() { for { for i := 0; i \u0026lt; 2147483647; i++ { } // Gosched yields the processor, allowing other goroutines to run. It does not suspend the current goroutine, so execution resumes automatically. // Gosched让当前goroutine让出处理器，从而使得其它goroutine可以运行。它不会挂起/暂停当前的goroutine，它会自动恢复执行。 runtime.Gosched() } } func init() { flag.IntVar(\u0026amp;numBurn, \u0026#34;n\u0026#34;, 0, \u0026#34;number of cores to burn (0 = all)\u0026#34;) flag.IntVar(\u0026amp;updateInterval, \u0026#34;u\u0026#34;, 10, \u0026#34;seconds between updates (0 = don\u0026#39;t update)\u0026#34;) flag.Parse() if numBurn \u0026lt;= 0 { numBurn = runtime.NumCPU() } } func main() { runtime.GOMAXPROCS(numBurn) fmt.Printf(\u0026#34;Burning %d CPUs/cores\\n\u0026#34;, numBurn) for i := 0; i \u0026lt; numBurn; i++ { go cpuBurn() } // 一直执行，区别是其中一个会定期打印，另一个不会打印 if updateInterval \u0026gt; 0 { t := time.Tick(time.Duration(updateInterval) * time.Second) for secs := updateInterval; ; secs += updateInterval { \u0026lt;-t fmt.Printf(\u0026#34;%d seconds\\n\u0026#34;, secs) } } else { select {} // wait forever } } "},{"id":55,"href":"/posts/2021/12/docker_compose_extra_host/","title":"docker compose使用extra host让容器访问主机服务","section":"12","content":" 首发于：简单博客\ndocker compose 如何访问主机服务 # docker compose 里面的容器怎么访问主机自身起的服务呢？\n20.10.0 版本在 linux 新增 host.docker.internal 支持： docker run -it --add-host=host.docker.internal:host-gateway alpine cat /etc/hosts\n127.0.0.1 localhost ::1 localhost ip6-localhost ip6-loopback fe00::0 ip6-localnet ff00::0 ip6-mcastprefix ff02::1 ip6-allnodes ff02::2 ip6-allrouters 172.17.0.1 host.docker.internal # --add-host的作用就是添加了这行到/etc/hosts 172.17.0.3 cb0565ceea26 相关提交\n这个 add-host 的意思是告诉容器，容器对域名 host.docker.internal 的访问都将转发到 host-gateway 去。\n也就是容器内部访问这个域名 host.docker.internal 时，就会访问到对应的主机上的 host-gateway 地址。\n从而达到容器访问主机上服务的效果。\n那么，这个 add-host 怎么用在 compose 上呢？\n在 build 里使用 extra_hosts\nversion: \u0026#34;2.3\u0026#34; # 因为某个bug的存在，只能用version2，不能用version3 services: tmp: build: context: . extra_hosts: # 配置extra_hosts - \u0026#34;host:IP\u0026#34; command: -kIL https://host tty: true stdin_open: true docker compose 配置中文说明\n参照\n测试：\ndocker-compose --version docker-compose version 1.29.2, build 5becea4c 新建一个服务，在主机上运行；\npackage main import ( \u0026#34;fmt\u0026#34; \u0026#34;net/http\u0026#34; ) func main() { handler := http.HandlerFunc(func(resp http.ResponseWriter, req *http.Request) { fmt.Println(\u0026#34;hi\u0026#34;) resp.Write([]byte(\u0026#34;hello\u0026#34;)) }) if err := http.ListenAndServe(\u0026#34;:8080\u0026#34;, handler); err != nil { panic(err) } } 新建 compose，里面也起一个服务，这个服务需要访问上述的主机服务；\nversion: \u0026#34;2.3\u0026#34; # version改为3.3也可以 services: server: image: curlimages/curl command: curl http://host.docker.internal:8080 extra_hosts: - \u0026#34;host.docker.internal:host-gateway\u0026#34; 在终端访问容器服务，容器服务访问主机服务，如果能正常执行，则表示完成。\n执行docker-compose up，能看到请求成功。\n代码\n"},{"id":56,"href":"/posts/2021/12/dbeaver/","title":"数据库管理工具之dbeaver","section":"12","content":" dbeaver: github\n下载页\n面向开发者、SQL 编程人员、数据库管理员和分析人员的免费的多平台数据库工具。 支持任何已有 JDBC 驱动的数据库（基本上是任何数据库）。商业版本还额外支持非 JDBC 数据源，比如：MongoDB, Cassandra, Couchbase, Redis, BigTable, DynamoDB 等。\n拥有的特性：元数据编辑、SQL 编辑、富文本编辑、ER 图、数据导出/导入/转译、SQL 执行计划等。 基于 Eclipse 平台。 使用插件架构，为以下数据库提供额外功能：MySQL/MariaDB, PostgreSQL, Greenplum, Oracle, DB2 LUW, Exasol, SQL Server, Sybase/SAP ASE, SQLite, Firebird, H2, HSQLDB, Derby, Teradata, Vertica, Netezza, Informix 等。\nFree multi-platform database tool for developers, SQL programmers, database administrators and analysts. Supports any database which has JDBC driver (which basically means - ANY database). Commercial versions also support non-JDBC datasources such as MongoDB, Cassandra, Couchbase, Redis, BigTable, DynamoDB, etc. You can find the list of all databases supported in commercial versions here.\nHas a lot of features including metadata editor, SQL editor, rich data editor, ERD, data export/import/migration, SQL execution plans, etc. Based on Eclipse platform. Uses plugins architecture and provides additional functionality for the following databases: MySQL/MariaDB, PostgreSQL, Greenplum, Oracle, DB2 LUW, Exasol, SQL Server, Sybase/SAP ASE, SQLite, Firebird, H2, HSQLDB, Derby, Teradata, Vertica, Netezza, Informix, etc.\n"},{"id":57,"href":"/posts/2021/12/domain/","title":"Domain-oriented development","section":"12","content":"面向领域开发。\n将业务复杂度和技术复杂度分开，逐个击破。\n分离领域，各司其职。\n降低复杂度，容易测试。\nDDD 尝试 # order.go:\npackage domain import ( \u0026#34;crypto/rand\u0026#34; \u0026#34;math/big\u0026#34; \u0026#34;github.com/pkg/errors\u0026#34; ) // 关键词：用户、店铺、商品、订单 // // 场景描述：店铺展示商品，其价格为P、库存为N，用户（余额为Y）看到商品觉得合适，于是下单购买B个； // 购买前，用户余额Y必须不小于P，商品库存N不小于B；购买后，用户余额减少P，库存减少B； // // 先不考虑并发情况，建立此时的领域模型 type User struct { name string // 名称 phone string // 电话 balance Money // 余额 } type Shop struct { name string // 名称 addr string // 地址 } type Product struct { name string // 名称 price Money // 价格 stock int // 库存 ownShop *Shop // 所属商铺 } type Order struct { name string // 名称 user *User // 用户 product *Product // 商品 } type Money int func NewUser(name, phone string, bal Money) *User { return \u0026amp;User{ name: name, phone: phone, balance: bal, } } func (u *User) Balance() Money { return u.balance } func (u *User) DeductBalance(amount Money) { if u.balance \u0026lt; amount { panic(\u0026#34;not enough money\u0026#34;) } u.balance -= amount } func NewShop(name, addr string) *Shop { return \u0026amp;Shop{ name: name, addr: addr, } } func NewProduct(name string, price Money, stock int, shop *Shop) *Product { return \u0026amp;Product{ name: name, price: price, stock: stock, ownShop: shop, } } func (p *Product) Stock() int { return p.stock } func (p *Product) DeductStock(c int) { if p.stock \u0026lt; c { panic(\u0026#34;not enough stock\u0026#34;) } p.stock -= c } // NewOrder 用户对商品下单c个 func NewOrder(user *User, product *Product, c int) *Order { name, err := GenerateRandomString(12) if err != nil { panic(err) } user.DeductBalance(product.price * Money(c)) product.DeductStock(c) return \u0026amp;Order{ name: name, user: user, product: product, } } func (o *Order) User() *User { return o.user } func (o *Order) Product() *Product { return o.product } // GenerateRandomString 随机字符串包含有数字和大小写字母 func GenerateRandomString(n int) (string, error) { const ( letters = \u0026#34;0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\u0026#34; ) return generate(n, letters) } func generate(n int, letters string) (string, error) { ret := make([]byte, n) for i := 0; i \u0026lt; n; i++ { num, err := rand.Int(rand.Reader, big.NewInt(int64(len(letters)))) if err != nil { return \u0026#34;\u0026#34;, errors.WithStack(err) } ret[i] = letters[num.Int64()] } return string(ret), nil } order_test.go:\npackage domain_test import ( \u0026#34;testing\u0026#34; \u0026#34;github.com/donnol/blog/demo/go/domain\u0026#34; ) func TestNewOrder(t *testing.T) { type args struct { user *domain.User product *domain.Product c int } tests := []struct { name string args args want *domain.Order }{ {name: \u0026#34;\u0026#34;, args: args{ user: domain.NewUser(\u0026#34;jd\u0026#34;, \u0026#34;123\u0026#34;, 10000), product: domain.NewProduct(\u0026#34;树莓派\u0026#34;, 1000, 10, domain.NewShop(\u0026#34;a shop\u0026#34;, \u0026#34;zhongshan\u0026#34;)), c: 1, }, want: nil}, } for _, tt := range tests { t.Run(tt.name, func(t *testing.T) { if got := domain.NewOrder( tt.args.user, tt.args.product, tt.args.c, ); got.User().Balance() != 9000 || got.Product().Stock() != 9 { t.Logf(\u0026#34;user: %+v, product: %+v\\n\u0026#34;, got.User(), got.Product()) t.Errorf(\u0026#34;NewOrder() = %v, want %v\u0026#34;, got, tt.want) } }) } } "},{"id":58,"href":"/posts/aboutme/about-me/","title":"关于我","section":"Posts","content":"听说读写想想干，吃喝玩乐洗洗睡。\n思前想后成伟绩，轻描淡写道至理。\n鹏程万里追无穷，法天象地铸有道。\n生老病死自当然，功名利禄也枉然\n"},{"id":59,"href":"/posts/2021/12/github_action_deploy_hugo_blog/","title":"github action deploy hugo blog","section":"12","content":" why # 为了将视线保持在文章上，减少构建和发布的时间占用。\nwhat # github action是GitHub推出的持续集成/持续部署工具，只需要在项目中添加workflow.yml配置文件，在其中配置好任务、工作、步骤等，即可在指定动作发生时自动触发编排好的动作。换言之，如果我们在我们的博客仓库里配置了自动将内容打包和发布的workflow.yml，那我们就可以把精力集中在文章的编写，然后轻轻地提交推送，即可完成博客地打包和发布，very easy and smooth。\nhow # 在github准备一个blog仓库，用于存放原始信息；再准备一个github page仓库，用于存放打包数据。\n其中github page仓库已开启page，可以通过github page设置的域名访问。\n我的blog仓库\n我的github page仓库\nworkflow # 这是我结合网络各位英豪所总结出来的一个workflow.yml配置文件\nname: blog # 做什么都好，别忘了先起个平凡（kuxuan）的名字 on: # 指定触发动作 push: # 动作是：git push branches: - main # 指定分支： main jobs: build-deploy: runs-on: ubuntu-latest # 基于ubuntu steps: - uses: actions/checkout@v2 # 切换分支：git checkout with: submodules: recursive # Fetch Hugo themes (true OR recursive) fetch-depth: 0 # Fetch all history for .GitInfo and .Lastmod - name: Setup Hugo # 博客所用的打包和部署工具 uses: peaceiris/actions-hugo@v2 with: hugo-version: latest - name: Build # 打包 run: hugo --minify --baseURL=https://donnol.github.io # 指定base url，确保构建出来的内容里的超链接都在它里面 - name: Deploy # 部署 uses: peaceiris/actions-gh-pages@v3 with: deploy_key: ${{ secrets.ACTIONS_DEPLOY_KEY }} # 这个key非常关键，一言两语很难讲清楚 external_repository: donnol/donnol.github.io # 我的github page所在的仓库 PUBLISH_BRANCH: main PUBLISH_DIR: ./public # 将本仓库的public目录下的内容提交到github page仓库 commit_message: ${{ github.event.head_commit.message }} # 提交信息 以铜为镜，可以正衣冠；以人为镜，可以明得失； 以史为镜，可以知兴替。\ndeploy key # 使用ssh-keygen生产一对非对称秘钥（包含有公钥、私钥）\n在github page(我这里是donnol/donnol.github.io)的仓库的setting里的deploy里添加公钥\n在blog仓库setting的secrets里添加私钥，注意命名必须是workflow里使用的名称(如上述：ACTIONS_DEPLOY_KEY)\nQ\u0026amp;A # 遇到问题不要惊慌，阿Q怕的是强者，如果你示弱，结果可想而知。\n当然，实在搞不懂，也可以在issue里提问，本人不负责任地想回就回。\n温馨提示 # 如果想知道更详细的信息，请自行搜索关键词，网络大神比比皆是，学习资料处处有售，生活实践时时待你。\n"},{"id":60,"href":"/posts/2021/07/linux-epoll/","title":"linux epoll","section":"07","content":" linux epoll # wiki\n手册\nwhy # what # Linux内核的可扩展I/O事件通知机制。\n于Linux 2.5.44首度登场，它设计目的旨在取代既有POSIX select(2)与poll(2)系统函数，让需要大量操作文件描述符的程序得以发挥更优异的性能（举例来说：旧有的系统函数所花费的时间复杂度为O(n)，epoll的时间复杂度O(log n)）。epoll 实现的功能与 poll 类似，都是监听多个文件描述符上的事件。\nhow # epoll 通过使用红黑树(RB-tree)搜索被监控的文件描述符(file descriptor)。\n在 epoll 实例上注册事件时，epoll 会将该事件添加到 epoll 实例的红黑树上并注册一个回调函数，当事件发生时会将事件添加到就绪链表中。\nint epoll_create(int size); 在内核中创建epoll实例并返回一个epoll文件描述符。\nint epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); 向 epfd 对应的内核epoll 实例添加、修改或删除对 fd 上事件 event 的监听。op 可以为 EPOLL_CTL_ADD, EPOLL_CTL_MOD, EPOLL_CTL_DEL 分别对应的是添加新的事件，修改文件描述符上监听的事件类型，从实例上删除一个事件。如果 event 的 events 属性设置了 EPOLLET flag，那么监听该事件的方式是边缘触发。\nint epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); 当 timeout 为 0 时，epoll_wait 永远会立即返回。而 timeout 为 -1 时，epoll_wait 会一直阻塞直到任一已注册的事件变为就绪。当 timeout 为一正整数时，epoll 会阻塞直到计时 timeout 毫秒终了或已注册的事件变为就绪。因为内核调度延迟，阻塞的时间可能会略微超过 timeout 毫秒。\n触发模式 # epoll提供边沿触发及状态触发模式。\n在边沿触发模式中，epoll_wait仅会在新的事件首次被加入epoll队列时返回；在状态触发模式下，epoll_wait在事件状态未变更前将不断被触发。状态触发模式是默认的模式。\n状态触发模式与边沿触发模式有读和写两种情况，我们先来考虑读的情况。假设我们注册了一个读事件到epoll实例上，epoll实例会通过epoll_wait返回值的形式通知我们哪些读事件已经就绪。简单地来说，在状态触发模式下，如果读事件未被处理，该事件对应的内核读缓冲器非空，则每次调用epoll_wait时返回的事件列表都会包含该事件，直到该事件对应的内核读缓冲器为空为止。而在边沿触发模式下，读事件就绪后只会通知一次，不会反复通知。\n然后我们再考虑写的情况。状态触发模式下，只要文件描述符对应的内核写缓冲器未满，就会一直通知可写事件。而在边沿触发模式下，内核写缓冲器由满变为未满后，只会通知一次可写事件。\n举例来说，倘若有一个已经于epoll注册之流水线接获资料，epoll_wait将返回，并发出资料读取的信号。现假设缓冲器的资料仅有部分被读取并处理，在level-triggered(状态触发)模式下，任何对epoll_wait之调用都将即刻返回，直到缓冲器中的资料全部被读取；然而，在edge-triggered(边缘触发)的情境下，epoll_wait仅会于再次接收到新资料(亦即，新资料被写入流水线)时返回。\n边沿触发模式 # 边沿触发模式使得程序有可能在用户态缓存 IO 状态。nginx 使用的是边沿触发模式。\n文件描述符有两种情况是推荐使用边沿触发模式的。\nread 或者 write 系统调用返回了 EAGAIN。 非阻塞的文件描述符。 可能的缺陷：\n如果 IO 空间很大，你要花很多时间才能把它一次读完，这可能会导致饥饿。举个例子，假设你在监听一个文件描述符列表，而某个文件描述符上有大量的输入（不间断的输入流），那么你在读完它的过程中就没空处理其他就绪的文件描述符。（因为边沿触发模式只会通知一次可读事件，所以你往往会想一次把它读完。）一种解决方案是，程序维护一个就绪队列，当 epoll 实例通知某文件描述符就绪时将它在就绪队列数据结构中标记为就绪，这样程序就会记得哪些文件描述符等待处理。Round-Robin 循环处理就绪队列中就绪的文件描述符即可。\n如果你缓存了所有事件，那么一种可能的情况是 A 事件的发生让程序关闭了另一个文件描述符 B。但是内核的 epoll 实例并不知道这件事，需要你从 epoll 删除掉。\n"},{"id":61,"href":"/posts/2021/01/proxy-between-layer/","title":"Go实现AOP","section":"01","content":" AOP # 面向切面编程（AOP: Aspect Oriented Program）。\n划分，重复，复用 # 我们知道，面向对象的特点是继承、多态和封装。而封装就要求将功能分散到不同的对象中去，这在软件设计中往往称为职责分配。实际上也就是说，让不同的类设计不同的方法。这样代码就分散到一个个的类中去了。这样做的好处是降低了代码的复杂程度，使类可重用。\n出现的问题：\n但是人们也发现，在分散代码的同时，也增加了代码的重复性。什么意思呢？比如说，我们在两个类中，可能都需要在每个方法中做日志。按面向对象的设计方法，我们就必须在两个类的方法中都加入日志的内容。也许他们是完全相同的，但就是因为面向对象的设计让类与类之间无法联系，而不能将这些重复的代码统一起来。\n想法1：\n也许有人会说，那好办啊，我们可以将这段代码写在一个独立的类独立的方法里，然后再在这两个类中调用。但是，这样一来，这两个类跟我们上面提到的独立的类就有耦合了，它的改变会影响这两个类。\n那么，有没有什么办法，能让我们在需要的时候，随意地加入代码呢？\n这种在运行时，动态地将代码切入到类的指定方法、指定位置上的编程思想就是面向切面的编程。\n一般而言，我们管切入到指定类指定方法的代码片段称为切面，而切入到哪些类、哪些方法则叫切入点。\n有了AOP，我们就可以把几个类共有的代码，抽取到一个切片中，等到需要时再切入对象中去，从而改变其原有的行为。\nOOP从横向上区分出一个个的类来，而AOP则从纵向上向对象中加入特定的代码。\n从技术上来说，AOP基本上是通过代理机制实现的。\nGo实现AOP \u0026ndash; 层间代理 # 假设有store，从数据库获取数据，其中有方法IUserStore.GetByID，传入id参数，返回用户信息:\ntype IUserStore interface { GetByID(ctx context.Context, id int) (User, error) } 另外有service，刚好有用户id并且需要拿到用户信息，于是依赖了上述IUserStore：\ntype IUserSrv interface { CheckUser(ctx context.Context, id int) error // 获取用户信息，然后检查用户某些属性 } type userImpl struct { userStore IUserStore } func (impl userImpl) CheckUser(ctx context.Context, id int) error { user, err := impl.userStore.GetByID(ctx, id) if err != nil { return err } // 使用user数据做一些操作 _ = user } 上面所描述的是一个最简单的情况，如果我们要在userImpl.CheckUser里对impl.userStore.GetByID方法调用添加耗时统计，依然十分简单。\nfunc (impl userImpl) CheckUser(ctx context.Context, id int) error { begin := time.Now() user, err := impl.userStore.GetByID(ctx, id) if err != nil { return err } fmt.Println(time.Since(begin)) // 统计耗时 // 使用user数据做一些操作 _ = user } 但是，如果方法里调用的类似impl.userStore.GetByID的方法非常之多，逻辑非常之复杂时，这样一个一个的添加，必然非常麻烦、非常累。\ntype userImpl struct { userStore IUserStore // 增加其它store roleStore IRoleStore } func (impl userImpl) CheckUser(ctx context.Context, id int) error { begin := time.Now() user, err := impl.userStore.GetByID(ctx, id) if err != nil { return err } fmt.Println(time.Since(begin)) // 统计耗时 // 使用user数据做一些操作 _ = user // 获取角色具体信息 { begin := time.Now() role, err := impl.roleStore.GetByID(ctx, user.RoleId) if err != nil { return err } _ = role fmt.Println(time.Since(begin)) // 统计耗时 } // 可能会有更多`Store` } 可以看到，当我们新增了roleStore之后，如果要分别统计不同Store的方法调用的耗时，将会非常麻烦。这时有人会说，那为什么不把耗时统计放到Store的方法实现里呢？或者使用一个方法来封装耗时统计：\nfunc WrapUsedTime[R any](f func() (R, error)) (R, error) { begin := time.Now() r, err := f() if err != nil { return r, err } fmt.Println(time.Since(begin)) // 统计耗时 return r, nil } 这样做，当然可以。但是，依然很繁琐，特别是在业务很复杂，调用的方法很多的时候。\n更重要的一点是，我们应该专注于业务逻辑的开发和测试，通用的东西应该交由框架来实现。这也是AOP(面向切面)思想的一个很重要的观点。\n其实，在接口开发时用的中间件，也是一种AOP实现，但是，中间件的函数签名是固定的，参数类型、参数个数、结果类型和结果个数都是需要事先确定的。但实际中的方法是各种各样的，类型和数量都不尽相同。所以，我们现在要做的是一个通用的AOP代理。\n// 比如，http包的HandlerFunc，它的签名就是这样的，两个参数，参数类型分别如下：ResponseWriter, *Request type HandlerFunc func(ResponseWriter, *Request) // 而我们面临的是： func GetById(id uint64) (User, error) func ListByTime(begin, end time.Time) ([]User, error) 当然，如果是自己项目的代码，统一约束函数签名也不是不行，但如果要在对第三方库的调用也加上这段逻辑呢？\n这时，如果有一个代理能帮我们拦截store的方法调用，在调用前后添加上耗时统计，势必能大大提升我们的工作效率。\n比如：\n// 将函数抽象为func(args []interface{}) []interface{}， // 用[]interface{}来装所有的参数和结果 func Around(f func(args []interface{}) []interface{}, args []interface{}) []interface{} { begin := time.Now() r := f(args) fmt.Println(time.Since(begin)) // 统计耗时 return r } 这只是一个简单的包装函数，怎么能将它与上面的接口联系到一起呢？\n接口，Mock，Around # // 使用mock和arounder对传入的provider进行包装，返回包装后的新的provider，新的provider在被调用时返回的对象与旧provider返回的对象同样实现了同一个接口；新provider返回的对象就是mock结构体的实例 func (impl *proxyImpl) around(provider any, mock any, arounder Arounder) any { if mock == nil { return provider } mockValue := reflect.ValueOf(mock) mockType := mockValue.Type() if mockType.Kind() != reflect.Ptr \u0026amp;\u0026amp; mockType.Elem().Kind() != reflect.Struct { return provider } // provider有参数，有返回值 pv := reflect.ValueOf(provider) pvt := pv.Type() if pvt.Kind() != reflect.Func { panic(\u0026#34;provider不是函数\u0026#34;) } // 使用新的类型一样的函数 // 在注入的时候会被调用 return reflect.MakeFunc(pvt, func(args []reflect.Value) []reflect.Value { result := pv.Call(args) if len(result) == 0 { return result } firstOut := result[0] firstOutType := firstOut.Type() if !mockType.Implements(firstOutType) { panic(fmt.Errorf(\u0026#34;mock not Implements interface\u0026#34;)) } // 根据返回值的类型(mock)生成新的类型，其中新类型的方法均加上钩子 // 注意：生成的不是接口，是实现了接口的类型 if firstOutType.Kind() == reflect.Interface { newValue := reflect.New(mockType.Elem()).Elem() newValueType := newValue.Type() // field设置 for i := 0; i \u0026lt; newValueType.NumField(); i++ { field := newValue.Field(i) fieldType := newValueType.Field(i) var name = fieldType.Name for _, suffix := range MockFieldNameSuffixes { name = strings.TrimSuffix(name, suffix) } method := firstOut.MethodByName(name) methodType, ok := firstOutType.MethodByName(name) if !ok { methodTag, ok := fieldType.Tag.Lookup(\u0026#34;method\u0026#34;) if !ok { panic(fmt.Errorf(\u0026#34;找不到名称对应的方法\u0026#34;)) } debug.Printf(\u0026#34;tag: %+v\\n\u0026#34;, methodTag) name = methodTag method = firstOut.MethodByName(name) methodType, ok = firstOutType.MethodByName(name) if !ok { panic(fmt.Errorf(\u0026#34;使用tag也找不到名称对应的方法\u0026#34;)) } } debug.Printf(\u0026#34;method: %+v\\n\u0026#34;, method) pctx := ProxyContext{ PkgPath: firstOutType.PkgPath(), InterfaceName: firstOutType.Name(), MethodName: methodType.Name, } debug.Printf(\u0026#34;pctx: %+v\\n\u0026#34;, pctx) // newMethod会在实际请求时被调用 // 当被调用时，newMethod内部就会调用绑定好的Arounder，然后将原函数method和参数args传入 // 在Around方法执行完后即可获得结果 newMethod := reflect.MakeFunc(methodType.Type, func(args []reflect.Value) []reflect.Value { var result []reflect.Value debug.Printf(\u0026#34;args: %+v\\n\u0026#34;, args) // Around是对整个结构的统一包装，如果需要对不同方法做不同处理，可以根据pctx里的方法名在Around接口的实现里做处理 result = arounder.Around(pctx, method, args) debug.Printf(\u0026#34;result: %+v\\n\u0026#34;, result) return result }) field.Set(newMethod) } result[0] = newValue.Addr().Convert(firstOutType) } return result }).Interface() } 可以看到，主要的方法是: around(provider interface{}, mock interface{}, arounder Arounder) interface{}，\n其中provider参数是类似NewXXX() IXXX的函数，\nmock是IXXX接口的一个实现，\n最后的Arounder是拥有方法Around(pctx ProxyContext, method reflect.Value, args []reflect.Value) []reflect.Value的接口。\n这里的示例 # 可以看到，mock结构是长这样的：\ntype UserSrvMock struct { CheckUserFunc func(ctx context.Context, id int) error // 通过配置CheckUserFunc字段的值来指定要附加的行为 } func (mock *UserSrvMock) CheckUser(ctx context.Context, id int) error { return mock.CheckUserFunc(ctx, id) } // UserSrvMock 实现了IUserSrv接口 var _ IUserSrv = (*UserSrvMock)(nil) 当然，这里需要一个 工具，用来根据接口生成相应的mock结构体。\n安装：go install github.com/donnol/tools/cmd/tbc@latest.\n使用：tbc mock -p=github.com/dominikbraun/graph --mode=offsite.\n上述命令会解析graph包，获取包里的公开接口，然后生成对应的Mock结构体，生成的代码保存在当前目录的mock.go文件里。\n代码生成替代反射 # 在上面描述的Around实现里，依赖了reflect包里的reflect.Value.Call方法：\nfunc (v Value) Call(in []Value) []Value 而这个方法的性能是比直接方法调用差的，因此，能不能用代码生成来替代它呢？\n再回过头来看一下，我们通过provider新建一个对象，这个对象带有我们需要使用的方法：\nfunc NewIUserSrv(userStore IUserStore) IUserSrv { return \u0026amp;userImpl{ userStore: userStore, } } 如果我们把provider改为：\nfunc NewIUserSrv(userStore IUserStore, withProxy bool) IUserSrv { base := \u0026amp;userImpl{ userStore: userStore, } if withProxy { // 控制是否使用proxy return getIUserSrvProxy(base) } return base } func getIUserSrvProxy(base IUserSrv) *UserSrvMock { return \u0026amp;UserSrvMock{ CheckUserFunc: func(ctx context.Context, id int) error { var r0 error // 这里不就可以添加逻辑了吗 r0 = base.CheckUser(ctx, id) // 这里不就可以添加逻辑了吗 return r0 }, } } 这样，不就可以在调用该方法前后添加逻辑了吗？\n如果接口的方法很多，并且添加的逻辑都一样，我们就需要考虑使用代码生成来提高开发效率了：\n// 生成getIUserSrvProxy函数 func getIUserSrvProxy(base IUserSrv) *UserSrvMock { return \u0026amp;UserSrvMock{ CheckUserFunc: func(ctx context.Context, id int) error { // 通用逻辑：耗时统计 _gen_begin := time.Now() var _gen_r0 error _gen_ctx := UserSrvMockCheckUserProxyContext // 生成Mock时一并生成 _gen_cf, _gen_ok := _gen_customCtxMap[_gen_ctx.Uniq()] // _gen_customCtxMap：全局map，存储用户自定义proxy if _gen_ok { // 收集参数 _gen_params := []any{} _gen_params = append(_gen_params, ctx) _gen_params = append(_gen_params, id) _gen_res := _gen_cf(_gen_ctx, base.CheckUser, _gen_params) // 结果断言 _gen_tmpr0, _gen_exist := _gen_res[0].(error) if _gen_exist { _gen_r0 = _gen_tmpr0 } } else { // 原始调用 _gen_r0 = base.CheckUser(ctx, id) } log.Printf(\u0026#34;[ctx: %s]used time: %v\\n\u0026#34;, _gen_ctx.Uniq(), time.Since(_gen_begin)) return _gen_r0 }, } } var ( userSrvMockCommonProxyContext = inject.ProxyContext{ PkgPath: \u0026#34;接口所在包路径，如：github.com/donnol/tools/inject\u0026#34;, InterfaceName: \u0026#34;接口名，如：IUserSrv\u0026#34;, } UserSrvMockCheckUserProxyContext = func() (pctx inject.ProxyContext) { pctx = userSrvMockCommonProxyContext pctx.MethodName = \u0026#34;CheckUser\u0026#34; // 方法名 return }() ) var ( _gen_customCtxMap = make(map[string]inject.CtxFunc) ) // 通过调用这个方法注册自定义proxy函数 func RegisterProxyMethod(pctx inject.ProxyContext, cf inject.CtxFunc) { _gen_customCtxMap[pctx.Uniq()] = cf } func main() { RegisterProxyMethod(UserSrvMockCheckUserProxyContext, func(ctx ProxyContext, method any, args []any) (res []any) { log.Printf(\u0026#34;custom call\u0026#34;) // 从any断言回具体的函数、参数 f := method.(func(ctx context.Context, id int) error) a0 := args[0].(context.Context) a1 := args[1].(id) // 调用 r1 := f(a0, a1) res = append(res, r1) return res }) } 最后，一个支持任意函数类型的、既能添加通用逻辑，又能添加定制逻辑的proxy就完成了。\n我们还留意到，在RegisterProxyMethod注入函数时，我们除了可以在函数调用前后新增逻辑，还可以把函数调用改为任意调用，比如接口调用。\n对于任意函数调用通过替换ast节点来添加Proxy # normal.go:\npackage proxy import ( \u0026#34;log\u0026#34; ) func A(ctx any, id int, args ...string) (string, error) { log.Printf(\u0026#34;arg, ctx: %v, id: %v, args: %+v\\n\u0026#34;, ctx, id, args) return \u0026#34;A\u0026#34;, nil } func C() { args := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;} r1, err := A(1, 1, args...) if err != nil { log.Printf(\u0026#34;err: %v\\n\u0026#34;, err) return } log.Printf(\u0026#34;r1: %v\\n\u0026#34;, r1) } 在上述代码中，C函数调用了A函数，那么，现在我想在这个调用前后添加耗时统计，该怎么办呢？\n// 添加耗时统计 func C() { begin := time.Now() args := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;} r1, err := A(1, 1, args...) if err != nil { log.Printf(\u0026#34;err: %v\\n\u0026#34;, err) return } log.Printf(\u0026#34;r1: %v\\n\u0026#34;, r1) log.Printf(\u0026#34;used time: %v\\n\u0026#34;, time.Since(begin)) } 如果，我能生成一个AProxy函数，里面包含有耗时统计等逻辑，再把C对A的调用改为对Aproxy的调用，是不是就非常方便了呢！\n# 执行命令，生成代码 tbc genproxy -p ./parser/testtype/proxy/ --func A gen_proxy.go:\npackage proxy import ( \u0026#34;log\u0026#34; \u0026#34;time\u0026#34; ) // 生成A的Proxy func AProxy(ctx any, id int, args ...string) (string, error) { begin := time.Now() var r0 string var r1 error r0, r1 = A(ctx, id, args...) log.Printf(\u0026#34;used time: %v\\n\u0026#34;, time.Since(begin)) return r0, r1 } normal.go:\npackage proxy import ( \u0026#34;log\u0026#34; ) func A(ctx any, id int, args ...string) (string, error) { log.Printf(\u0026#34;arg, ctx: %v, id: %v, args: %+v\\n\u0026#34;, ctx, id, args) return \u0026#34;A\u0026#34;, nil } func C() { args := []string{\u0026#34;a\u0026#34;, \u0026#34;b\u0026#34;, \u0026#34;c\u0026#34;, \u0026#34;d\u0026#34;} // 此处对A的调用就被替换为对AProxy的调用了 r1, err := AProxy(1, 1, args...) if err != nil { log.Printf(\u0026#34;err: %v\\n\u0026#34;, err) return } log.Printf(\u0026#34;r1: %v\\n\u0026#34;, r1) } 不过，这种方式会修改用户编写的源代码，使用时请注意。\n代码实现详见\n最后 # 把任意函数调用包起来，即可按需添加额外逻辑。\n函数、方法、接口 # 接口包含方法；\n方法变函数：把receiver放到函数的首个参数上；\n函数变方法：新建类型；\n函数变接口：无需新建类型，类型转换为单方法接口\u0026ndash;这是一个未实现的提案；\n例如，我们要给io.Writer添加计数功能：\n// 1 新建类型：这是目前支持的写法，相当多的模板代码 type countingWriter struct { w io.Writer n int64 } func (w *countingWriter) Write(p []byte) (n int, err error) { n, err = w.w.Write(p) w.n += int64(n) return n, err } func main() { cw := \u0026amp;countingWriter{w: os.Stdout} // write things to cw fmt.Println(cw.n, \u0026#34;bytes written\u0026#34;) } // 2 无需新建类型：这是提案想达到的效果 func main() { var N int64 // 直接将函数转型为接口 cw := io.Writer(func(p []byte) (n int, err error) { n, err = os.Stdout.Write(p) N += int64(n) return n, err }) // write things to cw fmt.Println(N, \u0026#34;bytes written\u0026#34;) } 如果这个提案最终被实现，那么我们可以认为任意函数都能被视为某个接口来使用，再结合上面基于接口的代理机制，可以做到对任意函数的代理。\n"},{"id":62,"href":"/posts/2021/01/hugo-blog/","title":"hugo搭建博客","section":"01","content":" 操作 # 安装hugo。\n使用hugo新建项目\n添加主题\n启动博客\n"},{"id":63,"href":"/posts/2020/12/go-ctx/","title":"go ctx","section":"12","content":" ctx # 1.why\ngoroutine号称百万之众，互相之间盘根错节，难以管理控制。为此，必须提供一种机制来管理控制它们。\n各自为战 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { // start first go func() { fmt.Println(1) }() // start second go func() { fmt.Println(2) }() time.Sleep(time.Second) } 万法归一 # package main import ( \u0026#34;fmt\u0026#34; \u0026#34;sync\u0026#34; ) func main() { wg := new(sync.WaitGroup) // start first wg.Add(1) go func() { defer wg.Done() fmt.Println(1) }() // start second wg.Add(1) go func() { defer wg.Done() fmt.Println(2) }() wg.Wait() } 可以看到使用waitgroup可以控制多个goroutine必须互相等待，直到最后一个完成才会全部完成。\n明修栈道暗度陈仓 # package main import ( \u0026#34;fmt\u0026#34; ) func main() { ch1 := make(chan int) ch2 := make(chan int) // start first go func() { fmt.Println(1) \u0026lt;-ch2 ch1 \u0026lt;- 1 }() ch3 := make(chan int) // start second go func() { fmt.Println(2) ch2 \u0026lt;- 2 \u0026lt;-ch1 // escape ch3 \u0026lt;- 3 }() n := \u0026lt;-ch3 fmt.Println(n) } 使用chan的话，可以实现goroutine之间的消息同步\n2.what\nPackage context defines the Context type, which carries deadlines, cancellation signals, and other request-scoped values across API boundaries and between processes.\n\u0026ndash; 提供标准库context，定义了Context类型，带有限期、取消信息和其它请求域里的跨API边界和进程间的值。\n3.how\npackage main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;time\u0026#34; ) func main() { var n time.Duration = 2 now := time.Now() ctx, cancel := context.WithDeadline(context.Background(), now.Add(time.Second*n)) _ = cancel fmt.Println(now) // start first go func(ctx context.Context) { select { case \u0026lt;-ctx.Done(): } fmt.Println(time.Now(), 1) }(ctx) // start second go func(ctx context.Context) { select { case \u0026lt;-ctx.Done(): } fmt.Println(time.Now(), 2) }(ctx) time.Sleep(time.Second * (n - 1)) fmt.Println(time.Now()) // 一秒钟之后取消的话，两个goroutine会在取消后马上执行；如果等到时间到期了，就会在两秒后执行； // cancel() // fmt.Println(time.Now()) time.Sleep(time.Second * (n + 1)) } 4.others\n"},{"id":64,"href":"/posts/2021/01/pstree/","title":"pstree进程树及说明","section":"01","content":" pstree进程树及说明 # "},{"id":65,"href":"/posts/2023/09/%E4%B8%BA%E4%BA%86%E4%BB%96%E6%98%AF%E8%87%AA%E5%B7%B1%E8%BD%AF%E5%BC%B1%E7%9A%84%E6%9C%80%E5%A4%A7%E5%80%9F%E5%8F%A3/","title":"为了他是自己软弱的最大借口","section":"09","content":"软弱如绵羊，却生造出老虎护幼崽的形象，只需一句“都是为了他”。\n"},{"id":66,"href":"/posts/2023/11/go_template_dot/","title":"Go Template Dot","section":"2023","content":"dot: 在模板里表示为.，表示当前作用域。\n{{range}}, {{if}}, {{with}}均有自己的作用域。\n{{if pipeline}}和{{with pipeline}}的区别是，前者不会修改.的值，而后者会。\nwith # with设置.的值：\n{{with pipeline}} T1 {{end}} {{with pipeline}} T1 {{else}} T0 {{end}} 当pipeline不为0值时，点.设置为pipeline运算的值，否则跳过。\n例如：\n{{with \u0026#34;hello\u0026#34;}} {{println .}} {{end}} 将输入hello，因为.被设置为了hello.\n"},{"id":67,"href":"/posts/2023/11/lllj/","title":"Lllj","section":"2023","content":"亮灯明途， 亮剑征服。 丽景慰人， 君芳抚世。\n"},{"id":68,"href":"/posts/2023/11/%E4%B9%B0%E8%B5%8C%E6%8A%A2/","title":"买赌抢","section":"2023","content":"分-\u0026gt;买-\u0026gt;赌-\u0026gt;抢\n"},{"id":69,"href":"/posts/2023/11/%E5%90%91%E5%BE%80/","title":"向往","section":"2023","content":" 向往 # 营造一个环境，演绎一段故事，打造一个向往。\n来使我消费。\n现实的边际效用低了，就用想象中的来补充。\n"},{"id":70,"href":"/posts/2023/11/%E5%B1%95%E5%BC%80%E5%AE%8F%E4%BB%A5%E6%96%B9%E4%BE%BF%E9%98%85%E8%AF%BB/","title":"展开宏以方便阅读","section":"2023","content":" 展开宏以方便阅读 # gcc -E macro.c -o macro_expand.c.\n-E Preprocess only; do not compile, assemble or link.\nmacro.c:\n#include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #define SUM(a, b) ((a) + (b)) #define SUB(a, b) ((a) - (b)) int main() { int a = 2; int b = 1; int c = 0; c = SUM(a, b) + SUB(a, b); printf(\u0026#34;%d\\n\u0026#34;, c); } 生成的macro_expand.c:\n// 生成的文件里包含了非常多内容，这里就不一一展示了，有兴趣的可以自己试一下 // 其中关键的部分： # 7 \u0026#34;macro.c\u0026#34; int main() { int a = 2; int b = 1; int c = 0; c = ((a) + (b)) + ((a) - (b)); printf(\u0026#34;%d\\n\u0026#34;, c); } "},{"id":71,"href":"/posts/2023/11/%E7%90%86%E6%83%B3%E5%92%8C%E7%8E%B0%E5%AE%9E/","title":"理想和现实","section":"2023","content":"做的时候从现实出发，没人手、没时间、没资源，但是必须限期做出来；\u0026ndash; 死也死出来\n评的时候从理想出发，这里应该、那里必须，依然还有好多要优化。\u0026ndash; 这点东西不够看\n"},{"id":72,"href":"/posts/2023/12/do/","title":"Do","section":"12","content":" 做 # 直到烦躁、厌倦。\n休息、转移。\n然后继续。\n"},{"id":73,"href":"/posts/2023/12/%E5%8F%8C%E6%A0%87/","title":"双标","section":"12","content":" 双标的进入 # 通过反问的方式来面对别人的质问。\n如果对方拒绝回答，只顾质问，就开始进入双标了。\n此时还讲道理，已无意义。\n发动情绪，更为明智。\n"},{"id":74,"href":"/posts/2023/12/%E5%8F%96%E4%B8%8E%E4%BA%A4/","title":"取与交","section":"12","content":"一人向他人索取\n一人向他人提交\n他人向他人索取\n他人向他人征收\n"},{"id":75,"href":"/posts/2023/12/%E6%83%85%E6%99%AF/","title":"情景","section":"12","content":"和煦的风，轻抚岸边的你。\n生怕你不知，又怕被别人知道。\n叫唤多少声，才能引起你注意。跳跃多少次，才能吸引你目光。\n呱，呱呱······\n"},{"id":76,"href":"/posts/2023/12/%E6%9A%96%E5%BA%8A%E5%92%8C%E6%B3%A1%E6%B5%B4%E7%BC%B8/","title":"暖床和泡浴缸","section":"12","content":" docker和vm # docker是暖床，把环境warmup后，就离开了；\nvm则是泡浴缸，得一直泡着。\n"},{"id":77,"href":"/posts/2023/12/%E6%9C%AA%E6%9D%A5/","title":"未来","section":"12","content":" 未来 # 未来会是怎样，会有什么？\n我如何在未来生存、发展？\n二极分化 # 财富、心智、观念。\n分化加深，则意味着断层；断层则意味着落差。\n不小心的俯视，看到了令人作呕的景象，急忙躲闪；\n不小心的仰望，目睹了令人艳羡的风景，急忙刹车。\n左边是自己一样的厌恶，右边是别人一样的匆忙。\n想停下来，却没有落脚之地。想飞起来，找不到可行航线。\n枯萎、败亡、凋零。\n终于有了新花，忍不住包裹、装饰、密封，最后依然破落。\n新花说：“我想感受世界”。却终于被“保护”在铜墙铁壁，等待枯萎。\n越珍贵，越保护；越保护，越顽固。\n活力 # 做己所想，志趣之友。事尽心，人尽礼。辩理，尽情。\n图文音画展俗世，琴棋诗画诉衷肠。\n"},{"id":78,"href":"/posts/2023/12/%E8%A7%84%E7%9F%A9%E7%9A%84%E8%AE%A2%E7%AB%8B%E5%92%8C%E6%89%A7%E8%A1%8C/","title":"规矩的订立和执行","section":"12","content":"规矩：\n名词 画圆形和方形的两种工具；比喻一定的标准、准则或惯例。 「要按 规矩办事」\n形容词 符合标准或常理；老实本分。\n何时订立、何时执行？\n何地订立、何地执行？\n何人订立、何人执行？\n如何订立、如何执行？\n"},{"id":79,"href":"/posts/2023/12/%E9%A9%B1%E8%99%8E%E5%90%9E%E7%8B%BC/","title":"驱虎吞狼","section":"12","content":"驱虎吞狼与驱狼吞虎\n什么能又驱虎，又驱狼呢？\n"},{"id":80,"href":"/posts/2024/01/gopls-hightlight-template/","title":"Gopls Hightlight Template","section":"2024","content":" Gopls高亮template # 配置 # { \u0026#34;gopls\u0026#34;: { \u0026#34;templateExtensions\u0026#34;: [ \u0026#34;tpl\u0026#34;, \u0026#34;tmpl\u0026#34;, ], \u0026#34;ui.semanticTokens\u0026#34;: true }, \u0026#34;files.associations\u0026#34;: { \u0026#34;*.tpl\u0026#34;: \u0026#34;gotmpl\u0026#34;, \u0026#34;*.tmpl\u0026#34;: \u0026#34;gotmpl\u0026#34; } // ... } 当文件扩展名为tpl, tmpl时，均会视为是符合Go的template文件。\n在编辑器里会有变量的高亮和智能提示。\n"},{"id":81,"href":"/posts/2024/01/vscode%E9%80%89%E4%B8%AD%E6%89%80%E6%9C%89%E5%8C%B9%E9%85%8D%E9%A1%B9/","title":"Vscode选中所有匹配项","section":"2024","content":" vscode选中所有匹配项 # 快捷键：ctrl+shift+l\n使用ctrl+f，找到匹配内容后，使用上述快捷键即可将所有匹配内容选中。 "},{"id":82,"href":"/posts/2024/01/wsl2_config/","title":"Wsl2 Config","section":"2024","content":" wsl2的一些配置 # 以下是在wsl虚拟机里面的配置\n配置 # $ cat /etc/wsl.conf [boot] systemd=true # 启用systemd [interop] appendWindowsPath = false [network] generateResolvConf = false # 关闭自动生成resolv.conf 更新resolv.conf # $ cat Script/generateResolvConf.sh #!/bin/sh echo \u0026#39;nameserver 192.168.8.44\u0026#39; \u0026gt; /etc/resolv.conf 以systemd service在开机时执行脚本：\n$ cat /etc/systemd/system/generateResolvConf.service [Unit] Description=Run generateResolvConf.sh to set dns of wsl2 at Startup [Service] ExecStart=/home/jd/Script/generateResolvConf.sh [Install] WantedBy=default.target 更新wslhost # wsl启动时，注册虚拟机ip到主机hosts：\n$ cat Script/wsl2host.sh #!/bin/bash HOSTS_FILE_WIN=\u0026#39;/mnt/c/Windows/System32/drivers/etc/hosts\u0026#39; TEMP_DIR_PATH=\u0026#39;~/tmp/dns\u0026#39; TEMP_FILE_PATH=${TEMP_DIR_PATH}\u0026#39;/dns_back\u0026#39; # inetIp=`ifconfig eth0 | grep -o \u0026#34;inet [0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]* netmask\u0026#34; | cut -f 2 -d \u0026#34; \u0026#34;` # 获取本机ip inetIp=`ip a | grep eth0 | grep -o \u0026#34;inet [0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]*\u0026#34; | cut -f 2 -d \u0026#34; \u0026#34;` nu=`cat -n ${HOSTS_FILE_WIN} | grep localwsl2 | awk \u0026#39;{print $1}\u0026#39;` # 获取已设置dns行号 dnsIp=`cat ${HOSTS_FILE_WIN} | grep -o \u0026#34;[0-9]*\\.[0-9]*\\.[0-9]*\\.[0-9]* localwsl2 #\u0026#34; | cut -f 1 -d \u0026#34; \u0026#34;` # 获取已设置dns ip echo \u0026#34;wsl\u0026#39;s ip is: ${inetIp}\u0026#34; echo \u0026#34;win\u0026#39;s dns line number is: ${nu}\u0026#34; echo \u0026#34;win\u0026#39;s dnsIp is: ${dnsIp}\u0026#34; if [ -z ${inetIp} ] then echo \u0026#39;inet ip is null, please check the command\u0026#39; fi set -e if [ ${nu} ] # 若已设置 then if [ -z ${dnsIp} ] || [ ${inetIp} != ${dnsIp} ] # 已设置dns不正确 then echo reset if [ ! -e ${TEMP_FILE_PATH} ] then echo \u0026#34;will mkdir ${TEMP_DIR_PATH} and file ${TEMP_FILE_PATH}\u0026#34; mkdir -p ${TEMP_DIR_PATH} \u0026amp;\u0026amp; touch ${TEMP_FILE_PATH} fi cp -f \u0026#34;${HOSTS_FILE_WIN}\u0026#34; \u0026#34;${TEMP_FILE_PATH}\u0026#34; sed -i \u0026#34;${nu}d\u0026#34; ${TEMP_FILE_PATH} # 删除对应行 echo \u0026#34;${inetIp} localwsl2 #wsl2 dns config\u0026#34; \u0026gt;\u0026gt; ${TEMP_FILE_PATH} # 重新设置 cat ${TEMP_FILE_PATH} \u0026gt; ${HOSTS_FILE_WIN} echo set success!!! fi else # 未设置 echo \u0026#34;will append localwsl2 ip:host to windows hosts\u0026#34; echo \u0026#34;${inetIp} localwsl2 #wsl2 dns config\u0026#34; \u0026gt;\u0026gt; ${HOSTS_FILE_WIN} # 直接设置 echo \u0026#34;finish append localwsl2 ip:host to windows hosts\u0026#34; fi 以systemd service在开机时执行wsl2host.sh脚本：\n$ cat /etc/systemd/system/wsl2host.service [Unit] Description=Run wsl2host.sh to set dns of wsl2 at Startup [Service] ExecStart=/home/jd/Script/wsl2host.sh [Install] WantedBy=default.target "},{"id":83,"href":"/posts/2024/01/%E5%88%BA%E7%A0%B4/","title":"刺破","section":"2024","content":" 刺破的过程 # 拥挤，互相推搡；\n往外走，发现气壁；\n尝试推，遭遇阻挠；\n用力打，鼻青脸肿；\n怎么办？陷入迷茫\u0026hellip;\n带路人，合力突刺。\n更多人，集齐元气！\n"},{"id":84,"href":"/posts/2024/01/%E5%A5%BD%E5%9D%8F/","title":"好坏","section":"2024","content":"如果世界真的有好坏，那么坏人的猖狂就来源于好人的软弱。\n"},{"id":85,"href":"/posts/2024/01/%E6%A8%A1%E5%9D%97%E5%8C%96%E5%92%8C%E6%9C%8D%E5%8A%A1%E5%8C%96/","title":"模块化和服务化","section":"2024","content":" 模块化和服务化 # 面向接口\n模块化 # type I interface { A() B() C() } 服务化 # GET /user POST /user PUT /user DELETE /user 在多人协作开发过程中，先定义接口，达到并行开发的目的。\n存在单人单服务的开发模式，也存在单人单模块的开发模式。\n存在多人单服务的开发模式，也存在多人单模块的开发模式。\n更存在存在多人多服务的开发模式，也存在多人多模块的开发模式。\n"},{"id":86,"href":"/posts/2024/01/%E7%AE%97%E6%95%B0/","title":"算数","section":"2024","content":" 算数 # 定义（数）\n计算（数）\n使用（数）\n期望和方差 # 定义 期望(Expectation)：度量一个随机变量取值的集中位置或平均水平。\n方差(Variance)：是表示随机变量取值的分散性的一个数字特征。\n怎么算？ 怎么用？ 方差越大，说明随机变量的取值分布越不均匀，变化性越强；方差越小，说明随机变量的取值越趋近于均值，即期望值。\n"},{"id":87,"href":"/posts/2024/01/%E8%BD%AC%E5%90%91/","title":"转向","section":"2024","content":"技术 -\u0026gt; 图文音画的技术 图文音画的技术 -\u0026gt; 内容\n"},{"id":88,"href":"/posts/2024/01/%E8%BD%AF%E5%BC%B1/","title":"软弱","section":"2024","content":" 软弱 # 容易被包装为心慈仁善，实则是放虎归山、助纣为虐。\n"},{"id":89,"href":"/posts/2024/02/%E5%A8%81%E6%9C%9B/","title":"威望","section":"2024","content":" 威望 # 权力、财富、名声。\n威望带来威亚。\n可以快速达成一致，也会阻碍想象和实践。\n"},{"id":90,"href":"/posts/2024/02/%E6%8E%92%E5%88%97%E7%BB%84%E5%90%88/","title":"排列组合","section":"2024","content":" 排列组合 # 可能出现的情况总数。\n排列：是指从给定个数的元素中取出指定个数的元素进行排序。\u0026ndash; n个中取m个，需要考虑排序：n!/(n-m)!\n组合：是指从给定个数的元素中仅仅取出指定个数的元素，不考虑排序。\u0026ndash; n个中取m个，不考虑排序：n!/m!*(n-m)!\n例如 # 3个球里取1个，有多少种排列呢？根据公式有：3*2*1/2*1 = 3，跟直觉一致。组合呢？根据公式有：3*2*1/1*2*1 = 3. 当取1个的时候，排列和组合是一样的，因为此时m! = 1.\n3个球里取2个，排列：3*2*1/(3-2) = 6; 组合：3*2*1/2*1*1 = 3. 此时，排列数比组合数多。\n如果用A、B、C分别表示3个球，则排列情况有：AB、AC、BC、BA、CA、CB；组合情况有：AB、AC、BC。\n当n和m都很大时，需要借助计算机来计算： package main func factorial(n int) (s int) { s = 1 for i := 1; i \u0026lt;= n; i++ { s *= i } return } func main() { s := factorial(10) / factorial(10-4) println(\u0026#34;10个取4个的排列\u0026#34;, s) // 10个取4个的排列 5040 p := factorial(10) / factorial(10-4) * factorial(4) println(\u0026#34;10个取4个的组合\u0026#34;, p) // 10个取4个的组合 120960 } 执行\n"},{"id":91,"href":"/posts/2024/02/%E7%89%A9%E6%9E%81%E5%BF%85%E5%8F%8D/","title":"物极必反","section":"2024","content":" 物极必反 # 追求极限的方法：\n以人的意志，忽略自然规律。\n尊重自然规律，科学寻找。\n尽情发挥想象力，实现时必须遵循规律。\n"},{"id":92,"href":"/posts/2024/03/%E4%B8%AD%E5%86%9B%E4%B9%8B%E5%BF%97/","title":"中军之志","section":"2024","content":" 中军之志 # mark\n"},{"id":93,"href":"/posts/2024/03/%E5%85%B1%E6%80%A7%E5%92%8C%E4%B8%AA%E6%80%A7/","title":"共性和个性","section":"2024","content":" 共性 # 人物属性，天生造就。\n个性 # 知行技能，后天培训。\n"},{"id":94,"href":"/posts/2024/03/%E5%89%A5%E5%89%8A%E7%9A%84%E4%B8%A4%E6%9E%81/","title":"剥削的两极","section":"2024","content":"贵族、无赖。\n"},{"id":95,"href":"/posts/2024/03/%E6%97%A2/","title":"既","section":"2024","content":"既不能早起，又不敢迟到。\n只好在扶梯上蹿下跳。\n活脱脱的兔子。\n"},{"id":96,"href":"/posts/2024/03/%E8%8B%B1%E9%9B%84%E5%B0%8F%E5%85%B5/","title":"英雄小兵","section":"2024","content":"自我意识的觉醒、自我行为的实现，即为英雄。\n反之则是小兵。\n"},{"id":97,"href":"/posts/2024/03/%E8%B6%85%E8%B5%B6/","title":"超赶","section":"2024","content":" 超赶 # 一来就提超赶，不就承认自己落后了吗？\n而且必须跟在别人屁股后面，屁颠屁颠的追赶。\n后面发现跟不合适，进而出来了弯道超车。\n再来就是遥遥领先了。\n既然领先了，为什么还是那么焦虑？\n因为又害怕被别人超赶了。\n所以竞争到底是为了什么，为了焦虑，还是为了享受。\n还是为了自己享受，让别人焦虑呢？\n"}]